# D6: Human-in-the-Loop Control Required

**Type**: Desirability
**Importance**: 10/10 (CRITICAL - Product requirement, elevated from 9/10)
**Evidence**: Opinion
**Status**: Updated for v2.0
**Version**: 2.0

---

## Hypothesis

**We believe** AI agent developers require human-in-the-loop approval for all agent changes that impact the production environment and will NOT adopt fully automated optimization (black-box), fearing unapproved modifications could break production systems. They need **AI Explainability** (show reasoning/steps) to trust recommendations.

**We'll know when** 18+ out of 20 interviewed developers state:
- Would NOT adopt fully automated optimization without human approval
- Require understanding of **WHY** changes are recommended (AI explainability)
- Specific concern about unapproved changes reaching production
- Rate "transparency and control" as 9+/10 importance
- Would use **MCP integration** to review/apply changes via coding agents

**Why it matters**: If true, human-in-the-loop + AI explainability are REQUIRED features (not optional) and differentiate us from auto-optimizer competitors. If false, we can ship faster without approval workflows.

---

## Links to Business Model

**Linked to:**
- **VPC v2.0**: Pain "Can't trust black-box auto-optimization (HIGH)"
- **VPC v2.0**: Pain Reliever "Transparent recommendations + AI explainability"
- **BMC v3.0**: Value Proposition #4 "Full Control (Human-in-the-Loop)"
- **BMC v3.0**: Value Proposition #4 "AI Explainability (show reasoning/steps)"
- **BMC v3.0**: Value Proposition #4 "MCP Integration (coding agents apply changes)"

---

## Current Evidence

**Evidence Level**: Opinion (workshop insight "can't trust black-box")

---

## Test Cards

**Related Tests**:
- [[1-customer-discovery-interviews-TEST-CARD]] (Multi-hypothesis customer interviews)

---

**Generated**: 2025-10-26 (v2.0 Strategic Refinement)
**Framework**: Testing Business Ideas - Desirability Hypothesis
