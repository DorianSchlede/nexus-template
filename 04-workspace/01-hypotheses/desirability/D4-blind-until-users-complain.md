# D4: Blind Until Users Complain

**Type**: Desirability
**Importance**: 8/10 (HIGH - Reputation risk)
**Evidence**: Opinion
**Status**: Updated for v2.0
**Version**: 2.0

---

## Hypothesis

**We believe** AI agent developers have no proactive detection for semantic agent failures (not related to easily visible API issues) and only discover issues when users complain, creating embarrassment, trust erosion, and reactive fire-fighting mode.

**We'll know when** 12+ out of 20 interviewed developers confirm:
- Discovered agent failure through user complaint (not monitoring) in last month
- Have observability tools (Langfuse/LangSmith) but no proactive **alerts**
- Specific story of embarrassing user-reported failure
- Would prioritize proactive alerts as top-3 desired feature
- Current monitoring is passive (dashboards) not active (alerts)

**Why it matters**: If true, "proactive alerts" (Hooks) is a strong differentiator from passive observability tools. If false, existing monitoring may be sufficient and we need to focus on other pains.

---

## Links to Business Model

**Linked to:**
- **VPC v2.0**: Pain "Blind to problems until users complain (HIGH)"
- **VPC v2.0**: Pain Reliever "Proactive issue detection"
- **BMC v3.0**: Value Proposition #3 "Proactive alerts catch issues before users"
- **BMC v3.0**: Customer Segment pain "Blind to problems until users complain (HIGH)"

---

## Current Evidence

**Evidence Level**: Opinion (workshop insight)

---

## Test Cards

**Related Tests**:
- [[1-customer-discovery-interviews-TEST-CARD]] (Multi-hypothesis customer interviews)

---

**Generated**: 2025-10-26 (v2.0 Strategic Refinement)
**Framework**: Testing Business Ideas - Desirability Hypothesis
