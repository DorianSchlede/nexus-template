field: generative_ai_patterns
aggregated_at: '2025-12-29T11:26:25.980081'
batches_merged: 1
patterns_input: 8
patterns_output: 8
patterns:
- name: Prompt-Invocation-Response Interaction Model
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:293-296)
    quote: the PROV-AGENT is designed to be modality-agnostic and supports other foundation
      models... as long as they follow a prompt-invocation-response interaction model
  description: Core generative AI pattern where models receive a prompt, invoke the
    model, and return a response. This is the fundamental interaction pattern for
    LLMs and other foundation models. PROV-AGENT captures this pattern through AIModelInvocation
    activities linked to Prompt and ResponseData entities.
- name: Retrieval-Augmented Generation (RAG)
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:148-150)
    quote: knowledge bases or web pages, for Retrieval-Augmented Generation (RAG)
      to dynamically augment prompts
  description: Pattern where agents communicate with external sources such as knowledge
    bases or web pages to dynamically augment prompts with relevant contextual knowledge.
    RAG enables agents to access up-to-date or domain-specific information beyond
    their training data.
- name: Context-Enhanced Prompting via RAG
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:304-306)
    quote: The additional data types can be used by the agent as part of reasoning
      or planning, for example through RAG strategies to enhance prompts with relevant
      contextual knowledge
  description: Extension of RAG where agents use system-level data (SchedulingData,
    TelemetryData) and domain data to enhance prompts with relevant contextual knowledge
    for reasoning or planning tasks.
- name: LLM Function/Tool Calling
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:285-291)
    quote: an AI agent can be associated with one or many tool executions (AgentTool)
      and each tool may be informed by... one or many AIModelInvocations
  description: Pattern where LLMs generate structured tool invocations. In PROV-AGENT,
    this is modeled as AgentTool executions associated with AIAgent instances, where
    tools can invoke AI models and generate structured outputs.
- name: LLM Wrapper Pattern for Provenance
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:358-364)
    quote: this first implementation of PROV-AGENT focuses on supporting LLMs by providing
      a generic wrapper for abstract LLM objects, compatible with models from popular
      LLM interfaces
  description: Pattern for wrapping LLM calls to capture prompts, responses, model
    metadata (provider, name, temperature parameters), and telemetry (response time).
    FlowceptLLM wrapper intercepts model invocations to record provenance data.
- name: Structured Prompt Engineering for Decision-Making
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:435-438)
    quote: The agents use structured prompts to decide which control result is best
      for print control based on their scores and other data in the agent context
  description: Pattern where structured prompts are crafted to guide LLM decision-making.
    Agents use structured prompts incorporating scores, previous decisions, and user
    guidance to make informed choices in agentic workflows.
- name: Iterative Prompt Refinement via Provenance
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:189-191)
    quote: continuous agent improvement, such as refining prompts or tuning model
      parameters to reduce hallucinations
  description: Pattern for improving generative AI outputs by analyzing provenance
    data to refine prompts or tune model parameters. Enables learning from past decisions
    to reduce hallucinations and improve agent reliability.
- name: Natural Language Query Interface for Provenance
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:373-377)
    quote: Flowcept also provides an MCP agent with a Streamlit GUI that enables users
      to interact with the provenance database through natural language queries at
      runtime
  description: Pattern where LLMs translate natural language queries into database
    queries (e.g., for provenance exploration). Users can ask questions about agent
    decisions, prompts, and responses in natural language, which are converted to
    structured queries.
