field: tools_standards
aggregated_at: '2025-12-29T11:26:27.306285'
batches_merged: 3
patterns_input: 93
patterns_output: 90
patterns:
- name: RDF Data Model Standard
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:435-442)
    quote: A standardised data model based on directed edge-labelled graphs is the
      Resource Description Framework (RDF) [111], which has been recommended by the
      W3C
  description: RDF is a W3C-recommended standardized data model for directed edge-labelled
    graphs. It defines different types of nodes including IRIs for global identification,
    literals for strings and datatype values, and blank nodes for anonymous entities.
- name: Internationalized Resource Identifiers (IRIs)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:439-441)
    quote: The RDF model defines different types of nodes, including Internationalized
      Resource Identifiers (IRIs) which allow for global identification of entities
      on the Web
  description: IRIs are used in RDF to globally identify entities on the Web, enabling
    persistent identification distinct from URLs used for information resources. This
    supports the Linked Data vision of interconnected knowledge graphs.
- name: Property Graph Model and Neo4j
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:548-562)
    quote: Property graphs are most prominently used in popular graph databases, such
      as Neo4j. In choosing between graph models, it is important to note that property
      graphs can be translated to/from directed edge-labelled graphs
  description: Property graphs are used in graph databases like Neo4j, offering a
    more flexible model with property-value pairs and labels on both nodes and edges.
    They can be translated to/from directed edge-labelled graphs without loss of information.
- name: SPARQL Query Language
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:664-665)
    quote: the SPARQL query language for RDF graphs; and Cypher, Gremlin, and G-CORE
      for querying property graphs
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:665-666)
    quote: Cypher [165], Gremlin [445], and G-CORE [15] for querying property graphs
  description: Merged from 2 sources. SPARQL is the standard query language for RDF
    graphs, providing graph patterns, relational operators, and path expressions.
    Cypher, Gremlin, and G-CORE are query languages for property graphs.
- name: RDF Schema (RDFS) Standard
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:176-182)
    quote: A prominent standard for defining a semantic schema for (RDF) graphs is
      the RDF Schema (RDFS) standard [70], which allows for defining subclasses, subproperties,
      domains, and ranges
  description: RDFS is a standard for defining semantic schemas for RDF graphs, supporting
    subclass/subproperty hierarchies and domain/range definitions. Definitions can
    be serialized as a graph and embedded into the data graph.
- name: Web Ontology Language (OWL)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:187-191)
    quote: More generally, the semantics of terms used in a graph can be defined in
      much more depth than seen here, as is supported by the Web Ontology Language
      (OWL) standard [239] for RDF graphs
  description: OWL is a W3C standard that extends RDFS to define more expressive ontological
    semantics for RDF graphs. It provides features for defining classes, properties,
    individuals, and complex axioms for reasoning.
- name: Shape Expressions (ShEx)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:380-385)
    quote: 'Two shapes languages have recently emerged for RDF graphs: Shape Expressions
      (ShEx), published as a W3C Community Group Report [423]; and SHACL (Shapes Constraint
      Language)'
  description: ShEx is a shapes language for RDF graphs published as a W3C Community
    Group Report. It allows defining constraints on node shapes for validation, used
    in domains like health-care, scientific literature, and spatial data.
- name: SHACL Shapes Constraint Language
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:383-389)
    quote: SHACL (Shapes Constraint Language), published as a W3C Recommendation [296].
      These languages support the discussed features (and more) and have been adopted
      for validating graphs
  - chunk_ref: 02-Knowledge_Graphs (Chunk 10:849-851)
    quote: Shapes Constraint Language (SHACL), W3C Recommendation 20 July 2017. W3C
      Recommendation
  description: Merged from 2 sources. SHACL is a W3C Recommendation for defining validating
    schemas using shapes. It targets sets of nodes and specifies constraints on those
    nodes, supporting open and closed shapes, boolean features, and more.
- name: XML Schema Datatypes (XSD)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:712-722)
    quote: RDF utilises XML Schema Datatypes (XSD) [411], amongst others, where a
      datatype node is given as a pair where l is a lexical string...and d is an IRI
      denoting the datatype such as xsd:dateTime
  description: XSD provides the datatype system for RDF, including types like xsd:string,
    xsd:integer, xsd:decimal, xsd:boolean, xsd:dateTime. Applications can parse, normalize,
    order, and transform values according to these standard definitions.
- name: Time Ontology
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:860-862)
    quote: One example is the Time Ontology [107], which specifies how temporal entities,
      intervals, time instants, etc. and relations between them such as before, overlaps,
      etc. can be described in RDF graphs
  description: The Time Ontology is a specification for representing temporal context
    in RDF graphs in an interoperable manner, defining temporal entities, intervals,
    time instants, and temporal relations like before and overlaps.
- name: PROV Data Model
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:864-870)
    quote: Another example is the PROV Data Model [188], which specifies how provenance
      can be described in RDF graphs, where entities are derived from other entities,
      are generated and/or used by activities
  description: PROV-DM is a W3C specification for describing provenance in RDF graphs.
    It models entities derived from other entities, generated/used by activities,
    and attributed to agents (people, software, organizations).
- name: Temporal RDF
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:111-113)
    quote: Temporal RDF [210] allows for annotating edges with time intervals, such
      as [Chile] [2006, 2010] M. Bachelet
  description: Temporal RDF is an extension that enables annotating edges with time
    intervals for temporal context, allowing queries that reason over temporal validity
    of statements.
- name: Fuzzy RDF
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:114-118)
    quote: Fuzzy RDF [502] allows for annotating edges with a degree of truth such
      as [Santiago] 0.8 Semi-Arid, indicating that it is more-or-less true with a
      degree of 0.8
  description: Fuzzy RDF extends RDF to support edges annotated with degrees of truth
    (fuzzy values), enabling representation of uncertain or approximate knowledge.
- name: Annotated RDF
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:120-124)
    quote: 'Annotated RDF [130, 530, 583] allows for representing various forms of
      context modelled as semi-rings: algebraic structures consisting of domain values
      and two main operators to combine domain values: meet and join'
  description: Annotated RDF is a domain-independent framework for contextual annotation
    using semi-rings. It supports various context types (temporal, fuzzy, etc.) with
    meet and join operators for combining annotations.
- name: RDF* Extension
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:17-19)
    quote: 'Third, we can use RDF* [218]: an extension of RDF that allows edges to
      be defined as nodes'
  description: RDF* (RDF-star) is an extension of RDF that allows edges to be treated
    as nodes, enabling direct annotation of edges with contextual values without requiring
    reification patterns.
- name: Notation3 (N3) Rules
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:122)
    quote: Notation3 (N3) [42], Rule Interchange Format (RIF) [288], Semantic Web
      Rule Language (SWRL) [254], and SPARQL Inferencing Notation (SPIN) [295]
  description: N3 is a rules language that allows expressing inference rules over
    graphs, either independently or alongside ontology languages, for automated reasoning
    and entailment.
- name: Rule Interchange Format (RIF)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:122-123)
    quote: Rule Interchange Format (RIF) [288], Semantic Web Rule Language (SWRL)
      [254], and SPARQL Inferencing Notation (SPIN) [295]
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:313-317)
    quote: rules can be directly specified in a rule language such as Notation3 (N3)
      [42], Rule Interchange Format (RIF) [288], Semantic Web Rule Language (SWRL)
      [254], or SPARQL Inferencing Notation (SPIN)
  description: 'Merged from 2 sources. Multiple rule languages for knowledge graphs:
    N3, RIF, SWRL, and SPIN - with SPIN allowing rules to be embedded in data graphs.'
- name: Semantic Web Rule Language (SWRL)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:123-124)
    quote: Semantic Web Rule Language (SWRL) [254], and SPARQL Inferencing Notation
      (SPIN) [295]
  description: SWRL combines OWL DL/Lite with a subset of the Rule Markup Language,
    allowing Horn-like rules to be combined with OWL ontologies for enhanced reasoning
    capabilities.
- name: SPARQL Inferencing Notation (SPIN)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:124)
    quote: SPARQL Inferencing Notation (SPIN) [295]
  description: SPIN allows expressing inference rules using SPARQL constructs, bridging
    the gap between SPARQL queries and rule-based reasoning over RDF graphs.
- name: OWL 2 RL/RDF Rules
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:44-46)
    quote: A more comprehensive set of rules for the OWL features of Tables 3-5 have
      been defined as OWL 2 RL/RDF [363]
  description: OWL 2 RL/RDF defines a comprehensive set of rules for OWL features
    that can be implemented using rule-based reasoning systems, though incomplete
    for some features like negation, existentials, and cardinality.
- name: OWL 2 QL Profile
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:107-109)
    quote: The OWL 2 QL profile [363] is a subset of OWL designed specifically for
      query rewriting of this form
  description: OWL 2 QL is an OWL 2 profile designed for query rewriting, allowing
    ontological entailments to be captured through query expansion without materialisation.
- name: Graph Parallel Frameworks
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:496-502)
    quote: Apache Spark (GraphX) [119, 563], GraphLab [326], Pregel [335], Signal-Collect
      [503], Shark [564], etc. These graph parallel frameworks apply a systolic abstraction
      based on a directed graph
  description: Graph parallel frameworks like Apache Spark GraphX, GraphLab, Pregel,
    Signal-Collect enable large-scale distributed graph analytics using systolic computation
    with message passing between nodes.
- name: Open Biomedical Ontologies Format (OBOF)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:352-356)
    quote: Amongst the most popular ontology languages used in practice are the Web
      Ontology Language (OWL) [239], recommended by the W3C and compatible with RDF
      graphs; and the Open Biomedical Ontologies Format (OBOF) [366]
  description: OBOF is a popular ontology language used primarily in the biomedical
    domain. It shares many similar features with OWL for defining ontological knowledge.
- name: R2RML Mapping Language
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:649-655)
    quote: A standard language along these lines is the RDB2RDF Mapping Language (R2RML)
      [118], which allows for mapping from individual rows of a table to one or more
      custom edges
  description: R2RML is a W3C standard for defining custom mappings from relational
    databases to RDF graphs, supporting templates, constants, and SQL queries for
    generating edges.
- name: JSON-LD Standard
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:710-712)
    quote: the JSON-LD standard [494] allows for mapping from JSON to (RDF) graphs
  description: JSON-LD is a W3C standard for representing Linked Data in JSON format,
    enabling mapping from JSON tree-structured data to RDF graphs.
- name: GRDDL Standard for XML
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:709-711)
    quote: the GRDLL standard [99] allows for mapping from XML to (RDF) graphs, while
      the JSON-LD standard [494] allows for mapping from JSON to (RDF) graphs
  description: GRDDL (Gleaning Resource Descriptions from Dialects of Languages) is
    a W3C standard for extracting RDF from XML documents using transformations.
- name: XSPARQL Hybrid Query Language
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:713-716)
    quote: hybrid query languages such as XSPARQL [47] allow for querying XML and
      RDF in an integrated fashion, thus supporting both materialisation and virtualisation
      of graphs over tree-structured sources
  description: XSPARQL is a hybrid query language combining XQuery and SPARQL for
    querying both XML and RDF, supporting materialisation and virtualisation of graphs
    from tree-structured legacy data.
- name: XSD DateTime for Syntactic Validation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:32-41)
    quote: a property start is defined with the range xsd:dateTime, taking a value
      such as 'March 29, 2019, 20:00'^xsd:string would be incompatible
  description: XSD datatypes (xsd:dateTime, xsd:string) used for syntactic accuracy
    validation in knowledge graphs. The range constraint mechanism enforces data type
    compatibility.
- name: Validation Tools for Syntactic Accuracy
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:47)
    quote: Such forms of syntactic accuracy can typically be assessed using validation
      tools [167, 248].
  description: Reference to validation tools for assessing syntactic accuracy in knowledge
    graphs. These tools check compliance with grammatical rules defined for the domain
    and data model.
- name: SPARQL for Knowledge Graph Querying
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:128)
    quote: public services offering such a protocol (most often supporting SPARQL
      queries [217]) have been found to often exhibit downtimes
  description: SPARQL identified as the most common protocol for complex graph pattern
    queries in knowledge graph access.
- name: Link Prediction via Statistical Relational Learning
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:301-302)
    quote: This task is often addressed with link prediction techniques proposed in
      the area of Statistical Relational Learning [184]
  description: Statistical Relational Learning as methodology for knowledge graph
    completion through link prediction techniques.
- name: Graph Neural Networks for Type Prediction
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:355-356)
    quote: Graph neural networks (see Section 5.3) can also be used for node classification/type
      prediction.
  description: Graph neural networks as a technical approach for type-link prediction
    in knowledge graphs, used for node classification tasks.
- name: String Similarity Metrics for Identity Matching
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:364-368)
    quote: value matchers determine how similar the values of two entities on a given
      property are, which may involve similarity metrics on strings, numbers, dates
  description: String, numeric, and date similarity metrics used for value matching
    in identity-link prediction for entity matching/deduplication.
- name: Blocking for Efficient Entity Matching
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:381-388)
    quote: blocking can be used to group similar entities into (possibly overlapping,
      possibly disjoint) 'blocks' based on similarity-preserving keys
  description: Blocking technique for efficient entity matching, reducing O(n^2) pairwise
    comparisons by grouping entities into similarity-preserving blocks.
- name: Minimal Hitting Sets for Inconsistency Repair
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:556-558)
    quote: Bonatti et al. [58] propose an automated method to repair inconsistencies
      based on minimal hitting sets [436]
  description: Minimal hitting sets algorithm used for automated inconsistency repair
    in knowledge graphs, where each set is a minimal explanation for an inconsistency.
- name: FAIR Principles for Data Publication
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:617-619)
    quote: the FAIR Principles proposed by Wilkinson et al. [556], and the Linked
      Data Principles proposed by Berners-Lee [41]
  description: FAIR Principles (Findability, Accessibility, Interoperability, Reusability)
    as foundational standard for publishing knowledge graph data on the Web.
- name: IRIs for Global Identifiers
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:700-702)
    quote: In terms of Findability, as discussed in Section 2, IRIs are built into
      the RDF model, providing a general schema for global identifiers
  description: IRIs (Internationalized Resource Identifiers) as the standard mechanism
    for global identifiers in RDF-based knowledge graphs.
- name: VoID for Dataset Metadata
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:702-705)
    quote: resources such as the Vocabulary of Interlinked Datasets (VoID) [11] allow
      for representing meta-data about graphs
  description: VoID (Vocabulary of Interlinked Datasets) as standard vocabulary for
    representing metadata about knowledge graph datasets.
- name: PROV Data Model for Provenance
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:715-717)
    quote: regarding Reusability, licensing will be discussed in Section 9.3, while
      the PROV Data Model [188] discussed in Section 3 allows for capturing detailed
      provenance
  description: PROV Data Model as W3C standard for capturing detailed provenance information
    in knowledge graphs.
- name: HTTP Linked Data Dereferencing
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:737-741)
    quote: Use HTTP IRIs so those names can be looked up. When a HTTP IRI is looked
      up, provide useful content about the entity
  description: HTTP IRIs with dereferencing capability as core Linked Data principle
    for making knowledge graph content retrievable on the Web.
- name: RDF Standards for Web of Data
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:747-750)
    quote: for principle (3), the standards based on RDF (including RDFS, OWL, etc.)
      are currently recommended for use
  description: RDF, RDFS, and OWL standards recommended as the foundation for Linked
    Data publication, enabling naming entities using HTTP IRIs.
- name: RDF Graph Serialization Standards
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:899-902)
    quote: for RDF graphs there are various standard syntaxes available based on XML
      [172], JSON [494], custom syntaxes [422]
  description: 'Multiple standard serialization formats for RDF graphs: XML-based
    (RDF/XML), JSON-based (JSON-LD), and custom syntaxes (N-Triples, Turtle).'
- name: GZIP/BZip2 Compression for Graph Dumps
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:905-909)
    quote: While standard compression such as GZIP or BZip2 can be straightforwardly
      applied on any file, custom compression methods have been proposed for graphs
  description: Standard compression methods (GZIP, BZip2) and custom graph compression
    methods for efficient knowledge graph dump publication.
- name: Triple Pattern Fragments Protocol
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:64-66)
    quote: Edge patterns - also known as triple patterns in the case of directed,
      edge-labelled graphs - are singleton graph patterns
  description: Triple Pattern Fragments as access protocol for edge-pattern queries,
    providing balance between server cost and query expressivity.
- name: ODRL for Machine-Readable Licenses
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:186-190)
    quote: the W3C Open Digital Rights Language (ODRL) [261] provides an information
      model and related vocabularies that can be used to specify permissions, duties,
      and prohibitions
  description: ODRL (Open Digital Rights Language) as W3C standard for specifying
    machine-readable licenses with permissions, duties, and prohibitions.
- name: WebAccessControl for Graph Security
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:217-219)
    quote: Access control policies based on edge patterns can be used to restrict
      access to parts of a knowledge graph [162, 290, 435]. WebAccessControl (WAC)
  description: WebAccessControl (WAC) as framework for access control in graphs, using
    WebID for authentication and providing vocabulary for access control policies.
- name: CryptOntology for Encryption Metadata
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:282-286)
    quote: The CryptOntology [182] can further be used to embed details about the
      encryption mechanism used within the knowledge graph
  description: CryptOntology as vocabulary for embedding encryption mechanism details
    (algorithm, key-length) within knowledge graphs.
- name: k-Anonymity for Graph Privacy
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:322-328)
    quote: A first approach to anonymisation is to suppress and generalise knowledge
      in a graph such that individuals cannot be identified, based on k-anonymity
      [459]
  description: k-anonymity technique for graph anonymization, suppressing quasi-identifiers
    to ensure individuals cannot be distinguished from k-1 others.
- name: Differential Privacy for Query Anonymization
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:395-397)
    quote: One approach is to apply epsilon-differential privacy [137] for querying
      graphs [483]
  description: Epsilon-differential privacy as technique for anonymous aggregate queries
    on graphs, adding noise to prevent leaks about individuals.
- name: DBpedia Extraction Framework
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:459-475)
    quote: The DBpedia extraction framework consists of several components, corresponding
      to abstractions of Wikipedia article sources, graph storage and serialisation
      destinations
  description: DBpedia extraction framework with components for wiki-markup extraction,
    parsing, and extraction management from Wikipedia to knowledge graph.
- name: SKOS for Category Representation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:492-494)
    quote: These schemata include a Simple Knowledge Organization System (SKOS) representation
      of Wikipedia categories
  description: SKOS (Simple Knowledge Organization System) used for representing category
    hierarchies in knowledge graphs like DBpedia.
- name: YAGO RDFS Model
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:528-531)
    quote: A schema - called the YAGO model - provides a vocabulary defined in RDFS;
      this model allows for representing words as entities, capturing synonymy and
      ambiguity
  description: YAGO model defined in RDFS for vocabulary representation, supporting
    reification, n-ary relations, and data types.
- name: Metaweb Query Language (MQL)
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:556-558)
    quote: an API that could be queried using the Metaweb Query Language (MQL); a
      Web user interface; and a lightweight typing system
  description: Metaweb Query Language (MQL) as query interface for Freebase knowledge
    graph, supporting API-based access.
- name: Wikidata Qxx/Pxx Identifier Scheme
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:607-609)
    quote: nodes and edges are assigned language-agnostic Qxx and Pxx codes (see Figure
      36) and are subsequently associated with labels, aliases, and descriptions
  description: Wikidata identifier scheme using language-agnostic Qxx (entities) and
    Pxx (properties) codes for multilingual support.
- name: RDF 1.1 XML Syntax Standard
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 10:152-154)
    quote: RDF 1.1 XML Syntax, W3C Recommendation 25 February 2014. W3C Recommendation.
      World Wide Web Consortium
  description: RDF 1.1 XML Syntax as W3C Recommendation standard for serializing RDF
    graphs in XML format.
- name: PROV Model Primer
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 10:238-242)
    quote: PROV Model Primer, W3C Working Group Note 30 April 2013. W3C Working Group
      Note. World Wide Web Consortium
  description: PROV Model as W3C standard for provenance representation, enabling
    tracking of data lineage in knowledge graphs.
- name: SPARQL 1.1 Query Language
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 10:401-405)
    quote: SPARQL 1.1 Query Language, W3C Recommendation 21 March 2013. W3C Recommendation.
      World Wide Web Consortium
  description: SPARQL 1.1 as W3C Recommendation for querying RDF knowledge graphs,
    supporting graph pattern matching.
- name: ODRL Information Model 2.2
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 10:670-672)
    quote: ODRL Information Model 2.2. W3C Recommendation. World Wide Web Consortium
  description: ODRL Information Model 2.2 as W3C Recommendation for digital rights
    expression in knowledge graphs.
- name: Knowledge Graph as Weighted Directed Edge-Labelled Graph
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:19-23)
    quote: propose a search engine for knowledge graphs, defined to be weighted directed
      edge-labelled graphs, where weights denote confidence scores
  description: Knowledge graph definition as weighted directed edge-labelled graph
    with confidence scores based on centrality of source documents.
- name: Wikipedia-based Knowledge Graph Construction
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:29-35)
    quote: construct a knowledge graph from Wikipedia, where nodes represent Wikipedia
      articles and categories, while edges represent the proximity of nodes
  description: Pattern for constructing knowledge graphs from Wikipedia using article/category
    nodes and proximity-based edges.
- name: 'Category I Definition: Directed Edge-Labelled Graph'
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:127-134)
    quote: The first category simply defines the knowledge graph as a graph where
      nodes represent entities, and edges represent relationships... a directed edge
      labelled graph is assumed
  description: Category I knowledge graph definition using directed edge-labelled
    graph structure, popularized by knowledge graph embedding papers.
- name: 'Category II Definition: Graph-Structured Knowledge Base'
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:144-152)
    quote: 'A second common definition goes as follows: ''a knowledge graph is a graph-structured
      knowledge base'''
  description: Category II definition linking knowledge graphs to knowledge bases,
    raising questions about logical formalism requirements.
- name: Category III Technical Characteristics
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:170-184)
    quote: The third category of definitions outline additional, technical characteristics...
      mainly describes real world entities... defines possible classes and relations...
      allows for potentially interrelating arbitrary entities
  description: 'Category III definition with technical criteria: real-world entities,
    schema with classes/relations, arbitrary entity interrelation, multi-domain coverage.'
- name: Formal Graph Tuple Definition
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:319-322)
    quote: A directed edge-labelled graph is a tuple G = (V, E, L), where V is a set
      of nodes, L is a set of edge labels, and E is a set of edges
  description: Formal mathematical definition of directed edge-labelled graph as tuple
    with nodes V, edges E, and labels L.
- name: Property Graph Formal Definition
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:375-385)
    quote: A property graph is a tuple G = (V, E, L, P, U, e, l, p), where V is a
      set of node ids, E is a set of edge ids, L is a set of labels
  description: Formal property graph definition with node ids, edge ids, labels, properties,
    values, and mapping functions for labels and property-value pairs.
- name: RDF Dataset as Graph Dataset Model
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 13:436-438)
    quote: An RDF dataset is a graph dataset model standardised by the W3C [111] where
      each graph is an RDF graph, and graph names can be blank nodes or IRIs
  description: RDF dataset as W3C-standardized graph dataset model supporting named
    graphs with blank node or IRI identifiers.
- name: Shapes Schema for Validation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:35-39)
    quote: Shapes languages in practice may support other forms of constraints, such
      as counting on paths [296]. In terms of implementing validation with respect
      to shapes
  description: Shapes languages (SHACL, ShEx) for implementing graph validation with
    path constraints and recursive constraint checking.
- name: Quotient Graph for Schema Extraction
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:42-52)
    quote: Emergent schemata are often based on the notion of a quotient graph...
      a quotient graph can merge multiple nodes into one node
  description: Quotient graph technique for emergent schema extraction, merging nodes
    while preserving edge structure through partitioning.
- name: Simulation and Bisimulation for Schema
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:74-93)
    quote: One way to formally define this idea is through simulation and bisimulation...
      If a simulation exists on G and G', we say that G' simulates G
  description: Simulation and bisimulation relations for defining schema quotient
    graphs that preserve graph topology.
- name: Annotation Domain Semi-Ring
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:116-118)
    quote: An annotation domain is defined as an idempotent, commutative semi-ring
      D = (A, +, x, bottom, top)
  description: Idempotent commutative semi-ring as mathematical structure for defining
    annotation domains in contextual knowledge graphs.
- name: Description Logic Knowledge Base Structure
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:342-344)
    quote: 'A DL knowledge base K is defined as a tuple (A, T, R), where A is the
      A-Box: a set of assertional axioms; T is the T-Box: a set of class axioms; and
      R is the R-Box'
  description: Description Logic knowledge base structure with A-Box (assertions),
    T-Box (terminological/class axioms), and R-Box (relation axioms).
- name: OWL 2 DL Correspondence to SROIQ
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:467-469)
    quote: DLs have been very influential in the definition of OWL, where the OWL
      2 DL fragment (roughly) corresponds to the DL SROIQ
  description: OWL 2 DL standard corresponding to SROIQ Description Logic, providing
    decidable ontology language for knowledge graphs.
- name: Knowledge Graph Embedding Tensor Operations
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:296-303)
    quote: Given two tensors X and Y, the tensor product X x Y is defined as a tensor...
      with each element computed as (X x Y)_i1...im j1...jn
  description: Tensor product operation as foundational mathematical tool for knowledge
    graph embeddings, enabling multi-dimensional representation.
- name: Convolution Operation for Graph Neural Networks
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:337-344)
    quote: ConvE [127] and HypER [28] - are based on convolutional architectures using
      the convolution operator
  description: Convolution operator used in ConvE and HypER embedding models for knowledge
    graph representation learning.
- name: Recursive GNN Architecture
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:388-396)
    quote: A recursive graph neural network (RecGNN) is a pair of functions (Agg,
      Out), such that Agg computes a new feature vector for a node
  description: Recursive Graph Neural Network architecture with Agg (aggregation)
    and Out (output) functions for node feature computation.
- name: Non-Recursive GNN with Multiple Layers
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:478-481)
    quote: A non-recursive graph neural network (NRecGNN) with l layers is an l-tuple
      of functions... for different aggregation function at each layer
  description: Non-recursive GNN architecture with l layers of different aggregation
    functions, enabling layer-wise feature transformation.
- name: AMIE Rule Mining System
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:668-672)
    quote: Systems such as AMIE [170], RuLES [241], CARL [406], DL-Learner [73], etc.,
      propose discrete mining that recursively generates candidate formulae
  description: AMIE and related systems for discrete rule mining through recursive
    formula generation with refinement operators.
- name: NeuralLP Differentiable Rule Mining
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:677-680)
    quote: systems such as NeuralLP [569] and DRUM [455] apply differentiable mining
      that allows for learning (path-like) rules and their scores in a more continuous
      fashion
  description: NeuralLP and DRUM for differentiable rule mining using gradient descent
    to learn path-like rules continuously.
- name: W3C PROV Standard Extension
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:119-121)
    quote: PROV-AGENT, a provenance model that extends the W3C PROV [7] standard and
      incorporates concepts from the Model Context Protocol (MCP)
  description: PROV-AGENT extends the W3C PROV provenance standard to capture AI agent
    interactions. W3C PROV provides the foundational Agent-Activity-Entity triad and
    relationships (used, wasGeneratedBy, wasAssociatedWith, wasInformedBy) that PROV-AGENT
    builds upon.
- name: Model Context Protocol (MCP) Integration
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:144-150)
    quote: MCP defines core agentic AI development concepts, including tools, prompts,
      resources, context management, and agent-client architecture that can communicate
      with external sources
  description: MCP is emerging as an industry and academic standard for agentic AI
    development. It defines concepts like tools, prompts, resources, and context management.
    PROV-AGENT incorporates MCP terminology (AgentTool, AIModelInvocation) to represent
    agent actions.
- name: Flowcept Open-Source Provenance Framework
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:321-324)
    quote: we extend Flowcept [9], an open-source distributed provenance framework
      designed for complex, heterogeneous workflows spanning experimental facilities
      at the edge, cloud platforms, and HPC environments
  description: Flowcept is the implementation platform for PROV-AGENT. It provides
    a federated, broker-based model for streaming raw provenance data from instrumented
    scripts, data observability hooks, and workflow tools.
- name: Python Decorator Instrumentation Pattern
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:343-351)
    quote: applying the @flowcept_task decorator ensures that, upon execution, the
      function's inputs, outputs, and any generated telemetry or scheduling data are
      automatically captured
  description: PROV-AGENT uses Python decorators (@flowcept_task, @flowcept_agent_tool)
    for non-invasive instrumentation of MCP tools. This pattern automatically captures
    provenance without modifying the core tool logic.
- name: LangChain Integration
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:359-364)
    quote: a generic wrapper for abstract LLM objects, compatible with models from
      popular LLM interfaces, including CrewAI, LangChain, and OpenAI
  description: PROV-AGENT provides FlowceptLLM wrapper that integrates with LangChain,
    enabling provenance capture for LLM invocations through the langchain_openai.ChatOpenAI
    interface.
- name: OpenAI API Compatibility
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:381-399)
    quote: from langchain_openai import ChatOpenAI... llm = FlowceptLLM(ChatOpenAI(model='gpt-4o'))
  description: The implementation demonstrates integration with OpenAI's API (gpt-4o
    model) through LangChain's ChatOpenAI wrapper, wrapped by FlowceptLLM for provenance
    capture.
- name: Redis and Kafka Data Streaming
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:329-331)
    quote: data streaming services and storage layers such as Redis, Kafka, SQLite,
      file systems, and object stores while the workflows run
  description: Flowcept supports multiple data streaming backends (Redis, Kafka) and
    storage systems (SQLite, file systems, object stores) for runtime provenance capture
    in distributed environments.
- name: Dask and MLflow Integration
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:328-329)
    quote: data observability hooks in workflow tools (e.g., Dask, MLflow)
  description: PROV-AGENT integrates with Dask (distributed computing) and MLflow
    (ML lifecycle management) through data observability hooks, enabling provenance
    capture from existing workflow tools.
- name: Streamlit GUI for Provenance Queries
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:372-377)
    quote: Flowcept also provides an MCP agent with a Streamlit GUI that enables users
      to interact with the provenance database through natural language queries at
      runtime
  description: A Streamlit-based graphical interface allows users to query the provenance
    database using natural language, enabling runtime exploration of agent decisions
    and workflow traceability.
- name: AutoGen Multi-Agent Framework
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:141-142)
    quote: LangChain [10], [11], AutoGen [12], LangGraph [13], Academy [3], and CrewAI
      [14] support multi-agent systems that interact through prompt exchanges
  description: PROV-AGENT is designed to work with multiple agentic workflow frameworks
    including AutoGen, LangGraph, Academy, and CrewAI, all supporting the MCP standard.
- name: CrewAI Framework Integration
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:141-144)
    quote: CrewAI [14] support multi-agent systems that interact through prompt exchanges,
      calls to foundation models typically hosted by AI service providers in the cloud
  description: CrewAI is listed as a compatible framework for PROV-AGENT, supporting
    multi-agent systems with cloud-hosted foundation models. The FlowceptLLM wrapper
    is compatible with CrewAI interfaces.
- name: RAG (Retrieval-Augmented Generation) Support
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:148-150)
    quote: communicate with external sources, such as knowledge bases or web pages,
      for Retrieval-Augmented Generation (RAG) [15] to dynamically augment prompts
  description: MCP and PROV-AGENT support RAG patterns where agents communicate with
    knowledge bases or web pages to augment prompts, with this context captured as
    part of the provenance graph.
