---
batch_id: "methodology_2"
field: methodology
extracted_at: "2025-12-31T00:00:00Z"
chunks_read: 5
patterns_found: 18
---

patterns:
  - name: "OntoUML Model-Based Representation"
    chunk_ref: "01-UFO (Chunk 3:5-11)"
    quote: "In Figure 8, we present an OntoUML model [17] representing this situation. In this model, a Rose is modeled as a subkind of Flower."
    description: "Top-down methodology using OntoUML as a visual modeling language grounded in UFO foundational ontology. Models are created through conceptual analysis of domain situations, then represented formally with stereotypes like subkind, role, mode, etc. The methodology emphasizes creating well-founded conceptual models before implementation."

  - name: "Partial Formalization from Conceptual Models"
    chunk_ref: "01-UFO (Chunk 3:14-23)"
    quote: "In the sequel, we show a partial formalization of this case. ObjectKind(Flower) SubKind(Rose) Rose âŠ‘ Flower"
    description: "Methodology involves translating OntoUML conceptual models into partial logical formalizations using first-order logic predicates and subsumption relations. This bridges the gap between intuitive visual models and rigorous formal semantics."

  - name: "Classical Modal Approach to Events"
    chunk_ref: "01-UFO (Chunk 3:103-117)"
    quote: "In UFO, we follow a classical view of events in which events are modally fragile entities. So, events cannot bear modal properties, they cannot genuinely change"
    description: "Top-down philosophical methodology grounded in classical metaphysics. Events are treated as modally fragile perdurants that cannot qualitatively change while maintaining numerical identity. This philosophical commitment shapes how change is modeled as either event variation or underlying endurant change."

  - name: "Endurant Focus Pattern for Event Modeling"
    chunk_ref: "01-UFO (Chunk 3:105-110)"
    quote: "Events are also polygenic manifestations of (possibly bundles of) dispositions... These (bundles of) dispositions are said to be the focuses of these events"
    description: "Methodological pattern where events are carved out of scenes by identifying underlying endurants (dispositions, modes) as their focus. The endurant serves as the stable element that changes, while events are immutable manifestations of those endurant changes."

  - name: "Higher-Order Type Pattern for Concept Evolution"
    chunk_ref: "01-UFO (Chunk 3:403-429)"
    quote: "According to the 'marriage' concept evolution case, 'a marriage is a contract that is regulated by civil and social constraints', and 'these constraints can change but the meaning continues'"
    description: "Methodology for handling concept evolution using higher-order types (types whose instances are themselves types). Identifies invariant structures (base types) and variable constraints (instantiating types) to model anticipated evolution while maintaining semantic stability."

  - name: "Anticipated vs Unanticipated Evolution"
    chunk_ref: "01-UFO (Chunk 3:536-544)"
    quote: "We should observe that we are dealing here with a case of anticipated evolution, i.e., when it is possible at specification time to foresee that types are likely to change"
    description: "Methodological distinction between anticipated evolution (designed into the model using powertype patterns and higher-order types) and unanticipated evolution (requiring model refactoring operations). Encourages proactive design for foreseeable change."

  - name: "Empirical Validation through Domain Application"
    chunk_ref: "01-UFO (Chunk 3:567-663)"
    quote: "Over the years, UFO has been used for the development of core and domain ontologies on a wide range of domains, both in academic and industrial contexts"
    description: "Bottom-up validation methodology where the foundational ontology is validated through extensive application across diverse domains including agriculture, accounting, business processes, legal issues, software engineering, etc. The breadth of successful applications provides empirical grounding for theoretical constructs."

  - name: "OntoUML as a Service Infrastructure"
    chunk_ref: "01-UFO (Chunk 3:697-709)"
    quote: "Currently, the development of UFO-based models through OntoUML is supported by a microservice-based infrastructure. The OntoUML as a Service infrastructure (OaaS)"
    description: "Practical methodology support through tooling: microservice architecture decoupling model services (transformations, verifications, simulations) from modeling tools. Uses HTTP and JSON for interoperability, enabling integration with various CASE tools like Visual Paradigm."

  - name: "Graph-Based Data Modeling for Knowledge Graphs"
    chunk_ref: "02-KG (Chunk 1:67-77)"
    quote: "Underlying all such developments is the core idea of using graphs to represent data, often enhanced with some way to explicitly represent knowledge"
    description: "Bottom-up, empirical methodology starting from data representation needs. Knowledge graphs emerge from practical scenarios requiring integration, management, and extraction of value from diverse data sources at large scale. The methodology prioritizes flexibility and evolvability over upfront schema definition."

  - name: "Incremental Schema Refinement"
    chunk_ref: "02-KG (Chunk 1:339-399)"
    quote: "Along the way, the board has to incrementally change the schema several times in order to support new sources of data. Each such change requires a costly remodelling"
    description: "Hybrid methodology where schema emerges through iterative refinement as data diversity increases. Starting with relational assumptions, the methodology discovers that flexible binary relations (graph edges) naturally accommodate incomplete and diverse data without requiring upfront schema commitment."

  - name: "Inclusive Definition Approach"
    chunk_ref: "02-KG (Chunk 1:132-163)"
    quote: "Herein we adopt an inclusive definition, where we view a knowledge graph as a graph of data intended to accumulate and convey knowledge of the real world"
    description: "Methodological stance favoring inclusive, broad definitions over restrictive technical ones. Knowledge graphs are defined by intent (accumulating real-world knowledge) rather than specific technical requirements, allowing diverse implementations under a unifying conceptual umbrella."

  - name: "Three Schema Types Methodology"
    chunk_ref: "02-KG (Chunk 2:89-98)"
    quote: "schemata can be used to prescribe a high-level structure and/or semantics that the graph follows or should follow. We discuss three types of graph schemata: semantic, validating, and emergent"
    description: "Methodological framework distinguishing three complementary approaches to graph schema: semantic (defining term meanings for reasoning), validating (enforcing structural constraints), and emergent (automatically extracting structure from data). Each serves different purposes and can be combined."

  - name: "Open World Assumption Methodology"
    chunk_ref: "02-KG (Chunk 2:192-222)"
    quote: "Semantic schema are typically defined for incomplete graph data, where the absence of an edge between two nodes... does not mean that the relation does not hold in the real world"
    description: "Methodological commitment to Open World Assumption (OWA) for semantic schemas, acknowledging that knowledge graphs represent incomplete knowledge. Local Closed World Assumption (LCWA) provides a pragmatic middle ground where specific portions can be assumed complete."

  - name: "Shapes-Based Validation Methodology"
    chunk_ref: "02-KG (Chunk 2:250-261)"
    quote: "A standard way to define a validating schema for graphs is using shapes. A shape targets a set of nodes in a data graph and specifies constraints on those nodes"
    description: "Bottom-up validation methodology using shapes (ShEx, SHACL) that target nodes and specify constraints. Unlike semantic schemas that infer new data, validating schemas check existing data against explicit structural requirements, complementing inference with validation."

  - name: "Quotient Graph Framework for Emergent Schema"
    chunk_ref: "02-KG (Chunk 2:434-458)"
    quote: "A framework often used for defining emergent schema is that of quotient graphs, which partition groups of nodes in the data graph according to some equivalence relation"
    description: "Automatic, bottom-up methodology for schema discovery. Quotient graphs partition nodes by equivalence relations (e.g., type, shape) and merge them while preserving structural properties. The approach extracts latent structure from data rather than imposing it top-down."

  - name: "Model-Theoretic Semantics Methodology"
    chunk_ref: "02-KG (Chunk 3:211-227)"
    quote: "In this section, we describe ways in which more complex entailments can be expressed and automated... we focus on ontologies, which constitute a formal representation of knowledge"
    description: "Top-down deductive methodology grounding knowledge representation in model-theoretic semantics. Interpretations map data graph terms to domain entities, and axioms define semantic conditions that constrain valid models. This provides rigorous foundations for automated reasoning."

  - name: "Rule-Based Reasoning Methodology"
    chunk_ref: "02-KG (Chunk 4:21-35)"
    quote: "One of the most straightforward ways to provide automated access to deductive knowledge is through inference rules encoding if-then-style consequences. A rule is composed of a body (if) and a head (then)"
    description: "Practical reasoning methodology using if-then rules with graph patterns as body and head. Rules can be applied through materialisation (recursive forward chaining until fixpoint) or query rewriting (extending queries to find entailed results). Corresponds to Datalog and Horn clauses."

  - name: "Inductive Learning Taxonomy"
    chunk_ref: "02-KG (Chunk 4:215-358)"
    quote: "inductively acquiring knowledge involves generalising patterns from a given set of input observations, which can then be used to generate novel but potentially imprecise predictions"
    description: "Complementary bottom-up methodology for knowledge acquisition through induction. Taxonomy includes graph analytics (unsupervised), knowledge graph embeddings (self-supervised), graph neural networks (supervised), and symbolic learning (rule/axiom mining). Each approach offers different tradeoffs between interpretability and learning power."
