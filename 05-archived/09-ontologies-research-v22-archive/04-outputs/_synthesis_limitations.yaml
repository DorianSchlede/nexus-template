field: limitations
aggregated_at: '2025-12-29T11:26:26.406025'
batches_merged: 3
patterns_input: 47
patterns_output: 47
patterns:
- name: Graph Model Inflexibility Limitation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:382-399)
    quote: Along the way, the board has to incrementally change the schema several
      times in order to support new sources of data. Each such change requires...
  description: Relational models require costly remodelling, reloading, and reindexing
    when integrating new sources - graphs offer more flexibility but still face modelling
    challenges when data scope is unknown a priori
- name: Knowledge Graph Definition Contentiousness
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:132-137)
    quote: The definition of a 'knowledge graph' remains contentious, where a number
      of (sometimes conflicting) definitions have emerged, varying from specific...
  description: Lack of unified definition for knowledge graphs creates ambiguity -
    definitions range from specific technical proposals to inclusive general proposals,
    limiting interoperability and shared understanding
- name: Heterogeneous Graph Type Restriction
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 1:496-502)
    quote: Conversely, they typically only support a one-to-one relation between nodes
      and types, which is not the case for del graphs
  description: Heterogeneous graphs only support one-to-one relation between nodes
    and types, unlike directed edge-labelled graphs which allow nodes with zero or
    multiple types
- name: Open World Assumption Query Limitations
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:213-221)
    quote: it is inconvenient if a system is unable to definitely answer 'yes' or
      'no' to questions such as 'is there a flight between Arica and Vina del Mar?'
  description: Open World Assumption prevents definitive negative answers - systems
    cannot confirm absence of relations without Local Closed World Assumption (LCWA)
    for specific graph portions
- name: Shapes Recursion and Negation Paradox
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 2:336-357)
    quote: shapes languages that freely combine recursion and negation may lead to
      semantic problems, depending on how their semantics are defined
  description: Combining recursion and negation in shapes validation leads to paradoxical
    situations (barber paradox), requiring special semantics like stratification,
    partial assignments, or stable models
- name: RDF* Contextual Grouping Limitation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:82-92)
    quote: The least flexible option is RDF*, which, in the absence of an edge id,
      does not permit different groups of contextual values to be assigned to an edge
  description: RDF* cannot pair contextual values for the same edge - e.g., cannot
    distinguish two presidencies with different valid time periods on the same edge
    without creating intermediate nodes
- name: Manual Context Query Tedium
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 3:101-109)
    quote: writing a query to manually intersect the corresponding temporal contexts
      will be tedious - or may not even be possible at all
  description: Without annotation frameworks, reasoning about context (e.g., temporal
    intersections) requires tedious manual queries or may be impossible with standard
    query languages
- name: Ontological Entailment Undecidability
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:895-901)
    quote: 'deciding if the first entails the second... is undecidable: no (finite)
      algorithm for such entailment can exist that halts on all inputs with the correct...'
  description: Full OWL entailment is undecidable - practical reasoning requires either
    incomplete algorithms, restricted feature sets, or potentially non-terminating
    procedures
- name: Rule-Based Reasoning Incompleteness
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:46-52)
    quote: these rules are likewise incomplete as such rules cannot fully capture
      negation (e.g., Complement), existentials (e.g., Some Values), universals...
  description: OWL 2 RL/RDF rules cannot fully capture negation, existentials (Some
    Values), universals (All Values), or counting (Cardinality), limiting expressiveness
    of rule-based reasoning
- name: Cyclical Pattern Inference Prohibition
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:114-118)
    quote: as they do not support ways to infer relations from cyclical graph patterns
      (for computability reasons)
  description: Ontology features cannot infer relations from cyclical graph patterns
    due to computability constraints - rules must be defined independently for such
    patterns
- name: Description Logic Computational Complexity
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:203-209)
    quote: Due to their prohibitive computational complexity - where for example,
      disjunction may lead to an exponential number of branching possibilities...
  description: Expressive Description Logic reasoning strategies (e.g., tableau methods)
    have prohibitive computational complexity, especially with disjunction, making
    them unsuitable for large-scale data
- name: Materialisation Size Explosion
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:60-64)
    quote: depending on the rules and the data, the materialised graph may become
      unfeasibly large to manage
  description: Rule-based materialisation can produce graphs too large to manage -
    the fixpoint closure of recursive rules on large data may exceed storage and processing
    capabilities
- name: TransE Simplistic Representation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:25-36)
    quote: TransE can be too simplistic; for example, in Figure 24, bus not only transforms
      San Pedro to Moon Valley, but also to Arica, Calama, and so forth
  description: TransE embedding model is too simplistic for relations with multiple
    targets or cyclical patterns - tends to give similar vectors to all target locations
    and assigns zero vectors to cyclical relations
- name: Differentiable Rule Mining Path Limitation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:8-10)
    quote: These differentiable rule mining techniques are, however, currently limited
      to learning path-like rules
  description: Neural/differentiable rule mining systems (NeuralLP, DRUM) can only
    learn path-like rules, not more complex patterns with branching or multiple body
    predicates
- name: Embedding Out-of-Vocabulary Problem
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:660-665)
    quote: Such approaches also suffer from the out-of-vocabulary problem, where they
      are unable to provide results for edges involving previously unseen nodes...
  description: Knowledge graph embeddings cannot handle unseen nodes or edges - require
    retraining when new entities are added, unlike symbolic approaches that can apply
    learned rules to novel entities
- name: Embedding Interpretability Deficit
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:650-658)
    quote: such models are often difficult to explain or understand... they will not
      provide an interpretable model to help understand why this is the case
  description: Knowledge graph embeddings lack interpretability - plausibility predictions
    are based on learned parameters that cannot be explained in human-understandable
    terms
- name: Human Collaboration Error Sources
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:150-154)
    quote: the approach has a number of key drawbacks, due primarily to human error,
      disagreement, bias, vandalism, etc.
  description: Human-collaborative knowledge graph creation suffers from errors, disagreements,
    biases, and vandalism - high costs and quality challenges from direct human contributions
- name: Text Extraction Precision-Recall Trade-off
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 6:170-178)
    quote: extracting such information with high precision and recall for the purposes
      of creating or enriching a knowledge graph is a non-trivial challenge
  description: Text extraction for knowledge graphs involves difficult precision-recall
    trade-offs - NLP and IE techniques cannot perfectly extract all relevant information
    without errors
- name: Completeness Measurement Intractability
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:109-111)
    quote: Measuring completeness directly is non-trivial as it requires knowledge
      of a hypothetical ideal knowledge graph
  description: Knowledge graph completeness cannot be directly measured because it
    requires knowing all elements that should 'ideally' be present - a hypothetical
    ideal knowledge graph that is fundamentally unknowable. This creates an inherent
    limitation in assessing coverage quality.
- name: Semantic Accuracy Assessment Challenge
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:50-65)
    quote: Assessing the level of semantic inaccuracies is challenging. While one
      option is to apply manual verification...
  description: Determining whether data values correctly represent real-world phenomena
    is difficult to automate. Options include manual verification (costly, unscalable)
    or checking against multiple sources (requires trusted external sources). Neither
    approach fully solves the semantic accuracy problem.
- name: Timeliness Decay
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:68-72)
    quote: a knowledge graph may be semantically accurate now, but may quickly become
      inaccurate (outdated) if no procedures...
  description: Knowledge graphs face temporal validity limitations - data that is
    accurate at one point becomes stale over time. Without continuous update mechanisms,
    graphs naturally decay in accuracy, creating an ongoing maintenance burden.
- name: Representativeness Bias
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:120-149)
    quote: Examples of data biases include geographic biases that under-represent
      entities/relations from certain parts of the world
  description: Knowledge graphs inherently contain biases - geographic, linguistic,
    social - that under-represent certain populations or domains. These biases stem
    from data sources, curator demographics, and schema design choices. Unrecognized
    biases can compound over time and adversely affect applications.
- name: Schema Bias Propagation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:138-140)
    quote: schema biases may result from high-level definitions extracted from biased
      data, semantic definitions that do not cover uncommon cases
  description: Schema-level biases can emerge from biased data extraction and fail
    to cover edge cases or uncommon scenarios. These structural limitations propagate
    to all instances in the knowledge graph.
- name: Knowledge Graph Inherent Incompleteness
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:295)
    quote: Knowledge graphs are characterised by incompleteness
  description: Incompleteness is a defining characteristic of knowledge graphs, not
    merely an implementation flaw. This fundamental limitation motivates knowledge
    graph completion techniques but can never be fully overcome.
- name: Identity Link Prediction Efficiency
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:380-382)
    quote: A major challenge in this setting is efficiency, where a pairwise matching
      would require O(n^2) comparisons
  description: Entity matching/deduplication faces quadratic scaling challenges. While
    blocking and windowing techniques help, fundamental computational complexity limits
    remain for identity link prediction at scale.
- name: Inconsistency Repair Complexity
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 7:532-545)
    quote: 'With respect to correcting a knowledge graph, however, detecting inconsistencies
      is not enough: techniques are also required to repair'
  description: Detecting inconsistencies is insufficient; repairing them is non-trivial
    because one edge can participate in many inconsistencies, one inconsistency can
    involve many edges, and entailment chains must be considered when removing edges.
- name: Graph Pattern Query Intractability
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:124-126)
    quote: the problem of evaluating such queries is known to be intractable
  description: Evaluating complex graph pattern queries is computationally intractable
    in the general case. This creates fundamental limits on query expressiveness vs.
    performance trade-offs for knowledge graph access protocols.
- name: SPARQL Endpoint Reliability
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:128-130)
    quote: public services offering such a protocol (most often supporting SPARQL
      queries) have been found to often exhibit downtimes, timeouts, partial results,
      slow performance
  description: Public SPARQL endpoints suffer from reliability issues including downtimes,
    timeouts, and incomplete results. This practical limitation affects the usability
    of complex query interfaces for knowledge graphs.
- name: Access Protocol Bandwidth vs. Computation Trade-off
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:83-88)
    quote: the server may often need to transfer irrelevant intermediate results to
      the client...This issue is further aggravated if the client does not have access
      to statistics
  description: Edge pattern protocols force trade-offs between server computation
    and bandwidth. Without access to knowledge graph statistics, clients cannot optimize
    join ordering, leading to inefficient query execution.
- name: Encryption Performance Limitation
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:299-305)
    quote: A key limitation of this approach, however, is that it requires attempting
      to decrypt all edges to find all possible solutions
  description: Fine-grained encryption of knowledge graph edges creates performance
    limitations because finding query solutions may require attempting to decrypt
    all edges, negating the efficiency benefits of graph indexing.
- name: Privacy-Information Trade-off
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 8:409-417)
    quote: These approaches require information loss for stronger guarantees of privacy;
      which to choose is thus heavily application dependent
  description: Privacy protection mechanisms (k-anonymity, l-diversity, differential
    privacy) inherently require information loss. Stronger privacy guarantees demand
    more information loss, creating unavoidable trade-offs.
- name: Scalability Challenge
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:19-21)
    quote: more general challenges for knowledge graphs include scalability, particularly
      for deductive and inductive reasoning
  description: Scalability remains a general challenge for knowledge graphs, especially
    for reasoning tasks. Both deductive (ontological) and inductive (machine learning)
    methods face scaling limitations as graphs grow.
- name: Quality Dimension Generality
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:21-23)
    quote: quality, not only in terms of data, but also the models induced from knowledge
      graphs
  description: Quality concerns extend beyond data quality to include the quality
    of models derived from knowledge graphs. Inductive models trained on biased or
    incomplete graphs may perpetuate or amplify those limitations.
- name: Diversity Management
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:23-24)
    quote: diversity, such as managing contextual or multi-modal data
  description: Managing diverse data types - contextual, temporal, streaming, multi-modal
    - presents ongoing challenges. Knowledge graph representations may not adequately
    capture all relevant data modalities.
- name: Dynamicity Handling
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:24-25)
    quote: dynamicity, considering temporal or streaming data
  description: Handling dynamic, temporal, and streaming data remains challenging.
    Static knowledge graph representations struggle to capture evolving real-world
    phenomena.
- name: Usability for Adoption
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:25-26)
    quote: and finally usability, which is key to increasing adoption
  description: Usability barriers limit knowledge graph adoption. Complex query languages,
    ontology engineering requirements, and lack of user-friendly tools create barriers
    for non-expert users.
- name: Unsolved Challenges
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 9:26-31)
    quote: Though techniques are continuously being proposed to address precisely
      these challenges, they are unlikely to ever be completely solved
  description: Core knowledge graph challenges (scalability, quality, diversity, dynamicity,
    usability) are acknowledged as unlikely to ever be completely solved. They represent
    ongoing dimensions along which techniques will continue to mature rather than
    problems with final solutions.
- name: Description Logic Entailment Undecidability
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 14:410-422)
    quote: Unfortunately, the problem of deciding entailment for knowledge bases expressed
      in the DL composed of the unrestricted use of all of the axioms...is undecidable
  description: Full Description Logic with unrestricted axiom use leads to undecidable
    entailment. This forces practical systems to restrict feature combinations, limiting
    expressivity to maintain computability. Trade-offs between expressivity and tractability
    are inherent.
- name: GNN Limited Expressivity
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 15:516-522)
    quote: GNNs (and indeed GPFs) relying solely on the neighbourhood of each node
      have limited expressivity in terms of their ability to distinguish nodes and
      graphs
  description: Graph Neural Networks operating only on local neighborhoods have fundamental
    expressivity limitations - they cannot distinguish certain structurally distinct
    nodes or graphs. This limits their classification and reasoning capabilities without
    extensions like global shared vectors.
- name: Hallucination and Error Propagation Risk
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:21-25)
    quote: agents can hallucinate or reason incorrectly, propagating errors when one
      agent's output becomes another's input
  description: Core limitation of AI agents in agentic workflows - LLM-based agents
    may generate hallucinated or incorrect outputs that propagate through the workflow
    when agent outputs become inputs for other agents or downstream tasks. This compounds
    errors and makes it difficult to assess correctness of results.
- name: Non-Deterministic Behavior
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:81-84)
    quote: agentic workflows are non-deterministic, shaped by near real-time data,
      adaptive decisions, and evolving interactions
  description: Unlike traditional workflows with static, deterministic paths, agentic
    workflows exhibit non-deterministic behavior. This makes reproducibility challenging
    as agent decisions are shaped by dynamic, cyclic behavior where agent outputs
    inform subsequent decisions or feedback loops.
- name: Traditional Provenance Inadequacy
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:93-98)
    quote: traditional provenance approaches are not designed to capture the intrinsic
      dynamics of modern AI agents
  description: Existing provenance methods fail to capture and relate agent-centric
    metadata (prompts, responses, decisions) with the broader workflow context and
    downstream outcomes. Provenance data must represent reasoning processes, model
    invocations, and contextual information driving agent decisions.
- name: Agent-Workflow Isolation
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:160-168)
    quote: these data are typically isolated from the rest of the workflow. This disconnection
      hinders the contextualization of agent interactions
  description: Current MCP-based agent frameworks record prompts, responses, and AI
    service invocations, but these data are disconnected from the broader workflow.
    Existing provenance techniques lack explicit representations of key agent artifacts
    and model workflows as static graphs, missing semantics needed to capture agentic
    behavior, dynamic decisions, and model-driven reasoning.
- name: Pre-Agentic PROV Extensions
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:244-246)
    quote: these earlier efforts predate agentic workflows, lacking support for core
      agentic AI concepts and how they relate to broader workflow
  description: Although W3C PROV has been extended for agents and multi-agent systems,
    these earlier efforts predate agentic workflows with LLMs. They lack support for
    core agentic AI concepts (tools, prompts, responses, model invocations) and how
    they relate to broader workflow provenance.
- name: LLM-Centric Implementation Scope
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:354-358)
    quote: this first implementation of PROV-AGENT focuses on supporting LLMs by providing
      a generic wrapper for abstract LLM objects
  description: Current PROV-AGENT implementation is limited to LLMs as the primary
    foundation model type. While the model is designed to be modality-agnostic and
    supports other foundation models (vision, audio, multimodal), the implementation
    prioritizes LLM-based agents given current use case prevalence.
- name: Iterative Error Amplification
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:441-445)
    quote: because the agent relies on an LLM, there is a risk of hallucinated or
      incorrect outputs. Since each decision influences the next in this iterative
      loop
  description: In iterative agentic workflows where each decision informs the next,
    a single LLM error may propagate across multiple iterations (e.g., layers in additive
    manufacturing), potentially compromising all downstream outputs. This cascading
    error effect makes provenance tracking essential.
- name: Early-Stage Framework Maturity
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:558-564)
    quote: To the best of our knowledge, this is the first provenance framework designed
      to track agent actions and decisions in agentic workflows. While this is an
      early step
  description: PROV-AGENT represents an early-stage contribution to agentic provenance.
    The paper acknowledges this as a foundational step that researchers and practitioners
    can build upon, indicating the framework is not yet mature for all use cases and
    requires further development for detection and remediation of hallucinations.
