# Hook Pattern Extraction: claude-code-hooks-mastery
# Focus: UserPromptSubmit and Notification hooks
# Extracted: 2024-12-31

patterns:
  # ============================================================================
  # UserPromptSubmit Patterns
  # ============================================================================

  - pattern_name: "prompt-logging"
    hook_event: "UserPromptSubmit"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/user_prompt_submit.py"
    description: "Logs all user prompts to a JSON file for debugging, analytics, and audit trails."
    implementation:
      matcher: ""
      decision_type: "allow"
      exit_code: "0"
    technique:
      summary: "Appends each prompt with full input_data to a JSON log file, creating directory if needed."
      code_snippet: |
        def log_user_prompt(session_id, input_data):
            """Log user prompt to logs directory."""
            log_dir = Path("logs")
            log_dir.mkdir(parents=True, exist_ok=True)
            log_file = log_dir / 'user_prompt_submit.json'

            if log_file.exists():
                with open(log_file, 'r') as f:
                    try:
                        log_data = json.load(f)
                    except (json.JSONDecodeError, ValueError):
                        log_data = []
            else:
                log_data = []

            log_data.append(input_data)

            with open(log_file, 'w') as f:
                json.dump(log_data, f, indent=2)
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - logging only, no context injection"
    use_case:
      category: "Observability"
      when_to_use: "When you need to track user interactions for debugging, analytics, or audit compliance."
      when_not_to_use: "In production where privacy concerns exist, or when disk I/O is a concern."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies:
        - "python-dotenv"

  - pattern_name: "session-prompt-tracking"
    hook_event: "UserPromptSubmit"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/user_prompt_submit.py"
    description: "Stores prompts per session in individual JSON files, enabling session history and status line display."
    implementation:
      matcher: ""
      decision_type: "allow"
      exit_code: "0"
    technique:
      summary: "Creates per-session JSON files in .claude/data/sessions/ containing all prompts for that session."
      code_snippet: |
        def manage_session_data(session_id, prompt, name_agent=False):
            """Manage session data in the new JSON structure."""
            sessions_dir = Path(".claude/data/sessions")
            sessions_dir.mkdir(parents=True, exist_ok=True)

            session_file = sessions_dir / f"{session_id}.json"

            if session_file.exists():
                try:
                    with open(session_file, 'r') as f:
                        session_data = json.load(f)
                except (json.JSONDecodeError, ValueError):
                    session_data = {"session_id": session_id, "prompts": []}
            else:
                session_data = {"session_id": session_id, "prompts": []}

            session_data["prompts"].append(prompt)

            with open(session_file, 'w') as f:
                json.dump(session_data, f, indent=2)
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - stores data for status line consumption"
    use_case:
      category: "Context"
      when_to_use: "When building features that need prompt history (status lines, session summaries, context windows)."
      when_not_to_use: "When session data is not needed or storage is limited."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies:
        - "python-dotenv"

  - pattern_name: "llm-agent-naming"
    hook_event: "UserPromptSubmit"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/user_prompt_submit.py"
    description: "Generates unique agent names using LLM (Ollama or Anthropic) on first prompt of a session."
    implementation:
      matcher: ""
      decision_type: "allow"
      exit_code: "0"
    technique:
      summary: "On first prompt, calls local Ollama (preferred) or Anthropic API to generate a memorable single-word agent name, stored in session data."
      code_snippet: |
        # Try Ollama first (preferred)
        try:
            result = subprocess.run(
                ["uv", "run", ".claude/hooks/utils/llm/ollama.py", "--agent-name"],
                capture_output=True,
                text=True,
                timeout=5  # Shorter timeout for local Ollama
            )

            if result.returncode == 0 and result.stdout.strip():
                agent_name = result.stdout.strip()
                if len(agent_name.split()) == 1 and agent_name.isalnum():
                    session_data["agent_name"] = agent_name
                else:
                    raise Exception("Invalid name from Ollama")
        except Exception:
            # Fall back to Anthropic if Ollama fails
            result = subprocess.run(
                ["uv", "run", ".claude/hooks/utils/llm/anth.py", "--agent-name"],
                capture_output=True,
                text=True,
                timeout=10
            )
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - generates metadata for display"
    use_case:
      category: "Productivity"
      when_to_use: "When running multiple agent sessions and need unique identifiers for tracking/display."
      when_not_to_use: "When latency is critical (adds 5-10 seconds on first prompt) or LLM APIs unavailable."
    quality:
      complexity: "medium"
      performance: "50-100ms (Ollama), >100ms (API fallback)"
      dependencies:
        - "python-dotenv"
        - "openai (for Ollama compatibility)"
        - "anthropic (for fallback)"

  - pattern_name: "prompt-validation-framework"
    hook_event: "UserPromptSubmit"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/user_prompt_submit.py"
    description: "Extensible framework for validating user prompts against blocked patterns before processing."
    implementation:
      matcher: ""
      decision_type: "block"
      exit_code: "2"
    technique:
      summary: "Pattern-based validation that can block prompts matching dangerous patterns, outputting reason to stderr and exiting with code 2."
      code_snippet: |
        def validate_prompt(prompt):
            """
            Validate the user prompt for security or policy violations.
            Returns tuple (is_valid, reason).
            """
            blocked_patterns = [
                # Add any patterns you want to block
                # Example: ('rm -rf /', 'Dangerous command detected'),
            ]

            prompt_lower = prompt.lower()

            for pattern, reason in blocked_patterns:
                if pattern.lower() in prompt_lower:
                    return False, reason

            return True, None

        # In main():
        if args.validate and not args.log_only:
            is_valid, reason = validate_prompt(prompt)
            if not is_valid:
                # Exit code 2 blocks the prompt with error message
                print(f"Prompt blocked: {reason}", file=sys.stderr)
                sys.exit(2)
    context_loading:
      mechanism: "permissionDecisionReason"
      what_loaded: "Outputs blocking reason to stderr, which Claude sees as explanation."
    use_case:
      category: "Safety"
      when_to_use: "When implementing input filtering, content policies, or prompt injection detection."
      when_not_to_use: "When all prompts should be allowed through without filtering."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies:
        - "python-dotenv"

  # ============================================================================
  # Notification Patterns
  # ============================================================================

  - pattern_name: "tts-notification-announcer"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/notification.py"
    description: "Announces notifications via text-to-speech when Claude needs user input, with multi-provider support."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Detects notification events and announces via TTS (ElevenLabs > OpenAI > pyttsx3), skipping generic 'waiting for input' messages."
      code_snippet: |
        def announce_notification():
            """Announce that the agent needs user input."""
            try:
                tts_script = get_tts_script_path()
                if not tts_script:
                    return  # No TTS scripts available

                engineer_name = os.getenv('ENGINEER_NAME', '').strip()

                # Create notification message with 30% chance to include name
                if engineer_name and random.random() < 0.3:
                    notification_message = f"{engineer_name}, your agent needs your input"
                else:
                    notification_message = "Your agent needs your input"

                subprocess.run([
                    "uv", "run", tts_script, notification_message
                ],
                capture_output=True,  # Suppress output
                timeout=10  # 10-second timeout
                )
            except (subprocess.TimeoutExpired, subprocess.SubprocessError):
                pass  # Fail silently
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - output only (audio)"
    use_case:
      category: "Communication"
      when_to_use: "When working away from screen and need audio alerts for Claude's attention requests."
      when_not_to_use: "In quiet environments, shared workspaces, or when audio is disruptive."
    quality:
      complexity: "medium"
      performance: "50-100ms (local), >100ms (API TTS)"
      dependencies:
        - "python-dotenv"
        - "elevenlabs (optional)"
        - "openai (optional)"
        - "pyttsx3 (fallback)"

  - pattern_name: "tts-provider-cascade"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/notification.py"
    description: "Cascading TTS provider selection based on available API keys, with offline fallback."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Checks for API keys in priority order (ElevenLabs > OpenAI > pyttsx3) and returns appropriate TTS script path."
      code_snippet: |
        def get_tts_script_path():
            """
            Determine which TTS script to use based on available API keys.
            Priority order: ElevenLabs > OpenAI > pyttsx3
            """
            script_dir = Path(__file__).parent
            tts_dir = script_dir / "utils" / "tts"

            # Check for ElevenLabs API key (highest priority)
            if os.getenv('ELEVENLABS_API_KEY'):
                elevenlabs_script = tts_dir / "elevenlabs_tts.py"
                if elevenlabs_script.exists():
                    return str(elevenlabs_script)

            # Check for OpenAI API key (second priority)
            if os.getenv('OPENAI_API_KEY'):
                openai_script = tts_dir / "openai_tts.py"
                if openai_script.exists():
                    return str(openai_script)

            # Fall back to pyttsx3 (no API key required)
            pyttsx3_script = tts_dir / "pyttsx3_tts.py"
            if pyttsx3_script.exists():
                return str(pyttsx3_script)

            return None
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - provider selection only"
    use_case:
      category: "Productivity"
      when_to_use: "When building resilient TTS features that work across different environments (cloud/offline)."
      when_not_to_use: "When you need a specific TTS provider guaranteed."
    quality:
      complexity: "low"
      performance: "<10ms (selection only)"
      dependencies:
        - "python-dotenv"

  - pattern_name: "notification-logging"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/notification.py"
    description: "Logs all notification events to JSON file for debugging and analytics."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Appends each notification input_data to a persistent JSON log file."
      code_snippet: |
        # Ensure log directory exists
        log_dir = os.path.join(os.getcwd(), 'logs')
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, 'notification.json')

        # Read existing log data or initialize empty list
        if os.path.exists(log_file):
            with open(log_file, 'r') as f:
                try:
                    log_data = json.load(f)
                except (json.JSONDecodeError, ValueError):
                    log_data = []
        else:
            log_data = []

        # Append new data
        log_data.append(input_data)

        # Write back to file with formatting
        with open(log_file, 'w') as f:
            json.dump(log_data, f, indent=2)
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - logging only"
    use_case:
      category: "Observability"
      when_to_use: "When debugging notification timing or analyzing interaction patterns."
      when_not_to_use: "When storage is limited or notifications are too frequent."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies:
        - "python-dotenv"

  - pattern_name: "smart-notification-filtering"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/notification.py"
    description: "Filters out generic notification messages to reduce audio alert fatigue."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Checks notification message content and skips TTS for generic 'waiting' messages."
      code_snippet: |
        # Announce notification via TTS only if --notify flag is set
        # Skip TTS for the generic "Claude is waiting for your input" message
        if args.notify and input_data.get('message') != 'Claude is waiting for your input':
            announce_notification()
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - filtering logic only"
    use_case:
      category: "Productivity"
      when_to_use: "When you want TTS alerts only for meaningful notifications, not routine waiting states."
      when_not_to_use: "When you need to hear every notification regardless of content."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies: []

  - pattern_name: "personalized-notification-message"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/notification.py"
    description: "Optionally includes engineer's name in TTS announcements for personalized experience."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Reads ENGINEER_NAME from environment and includes it in 30% of notifications for variety."
      code_snippet: |
        # Get engineer name if available
        engineer_name = os.getenv('ENGINEER_NAME', '').strip()

        # Create notification message with 30% chance to include name
        if engineer_name and random.random() < 0.3:
            notification_message = f"{engineer_name}, your agent needs your input"
        else:
            notification_message = "Your agent needs your input"
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - message generation only"
    use_case:
      category: "Communication"
      when_to_use: "When building a more personal, engaging agent experience."
      when_not_to_use: "In shared environments where personalization is not needed."
    quality:
      complexity: "low"
      performance: "<10ms"
      dependencies: []

  # ============================================================================
  # Supporting TTS Providers (used by Notification hook)
  # ============================================================================

  - pattern_name: "elevenlabs-turbo-tts"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/utils/tts/elevenlabs_tts.py"
    description: "High-quality TTS using ElevenLabs Turbo v2.5 model with direct audio playback."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Uses ElevenLabs API with Turbo v2.5 model for fast, high-quality voice synthesis with immediate playback."
      code_snippet: |
        from elevenlabs.client import ElevenLabs
        from elevenlabs import play

        elevenlabs = ElevenLabs(api_key=api_key)

        audio = elevenlabs.text_to_speech.convert(
            text=text,
            voice_id="WejK3H1m7MI9CHnIjW9K",  # Specified voice
            model_id="eleven_turbo_v2_5",
            output_format="mp3_44100_128",
        )

        play(audio)
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - audio output only"
    use_case:
      category: "Communication"
      when_to_use: "When highest quality TTS is needed and ElevenLabs subscription is available."
      when_not_to_use: "When cost is a concern or offline operation is required."
    quality:
      complexity: "low"
      performance: ">100ms (API + playback)"
      dependencies:
        - "elevenlabs"
        - "python-dotenv"

  - pattern_name: "openai-streaming-tts"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/utils/tts/openai_tts.py"
    description: "OpenAI TTS with streaming audio playback using gpt-4o-mini-tts model."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Uses OpenAI's latest TTS with async streaming and LocalAudioPlayer for real-time playback."
      code_snippet: |
        from openai import AsyncOpenAI
        from openai.helpers import LocalAudioPlayer

        openai = AsyncOpenAI(api_key=api_key)

        async with openai.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",
            voice="nova",
            input=text,
            instructions="Speak in a cheerful, positive yet professional tone.",
            response_format="mp3",
        ) as response:
            await LocalAudioPlayer().play(response)
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - audio output only"
    use_case:
      category: "Communication"
      when_to_use: "When OpenAI API is available and lower latency than ElevenLabs is needed."
      when_not_to_use: "When offline operation is required or cost is a concern."
    quality:
      complexity: "medium"
      performance: ">100ms (API + streaming)"
      dependencies:
        - "openai"
        - "openai[voice_helpers]"
        - "python-dotenv"

  - pattern_name: "pyttsx3-offline-tts"
    hook_event: "Notification"
    source_repo: "claude-code-hooks-mastery"
    source_file: ".claude/hooks/utils/tts/pyttsx3_tts.py"
    description: "Offline TTS using pyttsx3 for environments without API access."
    implementation:
      matcher: ""
      decision_type: "none"
      exit_code: "0"
    technique:
      summary: "Uses pyttsx3 for cross-platform offline text-to-speech with configurable rate and volume."
      code_snippet: |
        import pyttsx3

        # Initialize TTS engine
        engine = pyttsx3.init()

        # Configure engine settings
        engine.setProperty('rate', 180)    # Speech rate (words per minute)
        engine.setProperty('volume', 0.8)  # Volume (0.0 to 1.0)

        # Speak the text
        engine.say(text)
        engine.runAndWait()
    context_loading:
      mechanism: "none"
      what_loaded: "N/A - audio output only"
    use_case:
      category: "Communication"
      when_to_use: "When offline operation is required or no API keys are available."
      when_not_to_use: "When high-quality voice synthesis is required."
    quality:
      complexity: "low"
      performance: "<10ms (local synthesis)"
      dependencies:
        - "pyttsx3"

# ============================================================================
# Summary Statistics
# ============================================================================

summary:
  total_patterns: 13
  by_hook_event:
    UserPromptSubmit: 4
    Notification: 9
  by_category:
    Observability: 2
    Context: 1
    Productivity: 3
    Safety: 1
    Communication: 5
  notable_techniques:
    - "Multi-provider cascade with fallback (TTS)"
    - "LLM-powered metadata generation (agent naming)"
    - "Pattern-based prompt validation with exit code blocking"
    - "Session-scoped data persistence"
    - "Smart message filtering to reduce alert fatigue"
    - "Personalization via environment variables"
