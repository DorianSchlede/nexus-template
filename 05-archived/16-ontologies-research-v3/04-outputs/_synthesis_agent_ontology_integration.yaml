field: agent_ontology_integration
aggregated_at: '2026-01-01T16:22:11.263328'
batches_merged: 6
patterns_input: 115
patterns_output: 115
patterns:
- name: Query Rewriting for Ontology-Guided Retrieval
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:92-109)
    quote: Another strategy is to use rules for query rewriting, which given a query,
      will automatically extend the query in order to find solutions entailed by a
      set of rules
  description: Agents can leverage query rewriting to expand user queries based on
    ontological rules. The ontology's class hierarchies and inference rules automatically
    extend queries to retrieve semantically related results. This pattern enables
    agents to find relevant information even when queries don't use exact ontological
    terms, supporting ontology-guided reasoning over knowledge graphs.
- name: Graph Parallel Frameworks for Agent Analytics
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:496-514)
    quote: Various frameworks have been proposed for large-scale graph analytics,
      often in a distributed (cluster) setting... These graph parallel frameworks
      apply a systolic abstraction based on a directed graph, where nodes are processors
      that can send messages to other nodes along edges
  description: Graph parallel frameworks like Apache Spark (GraphX), Pregel, and GraphLab
    provide a computational model where agents can perform distributed reasoning over
    knowledge graphs. The systolic abstraction enables message-passing between graph
    nodes, supporting agent-based traversal and aggregation of ontological knowledge
    at scale.
- name: Analytics Combined with Entailment for Agent Reasoning
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:728-764)
    quote: Knowledge graphs are often associated with a semantic schema or ontology
      that defines the semantics of domain terms, giving rise to entailments... Applying
      analytics with or without such entailments may yield radically different results
  description: Agents querying knowledge graphs must consider ontological entailments
    to get consistent results. The combination of graph analytics with semantic inference
    allows agents to analyze the semantic content of knowledge graphs rather than
    just topological features, enabling semantically-invariant analytics that yield
    same results over semantically-equivalent graphs.
- name: Knowledge Graph Embeddings for Agent Plausibility Scoring
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 4:768-822)
    quote: The main goal of knowledge graph embedding techniques is to create a dense
      representation of the graph in a continuous, low-dimensional vector space that
      can then be used for machine learning tasks
  description: Knowledge graph embeddings enable agents to compute plausibility scores
    for potential edges, supporting link prediction and confidence assignment. Agents
    can use these embeddings to evaluate assertions extracted from external sources,
    complete missing edges, and measure similarity between entities for recommendation
    or duplicate detection tasks.
- name: Entailment-Aware Embeddings for Rule Integration
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:341-390)
    quote: The embeddings thus far consider the data graph alone. But what if an ontology
      or set of rules is provided? Such deductive knowledge could be used to improve
      the embeddings
  description: Agents can leverage joint embeddings that combine both data graphs
    and ontological rules. KALE uses t-norm fuzzy logics to integrate rule-based reasoning
    with embedding plausibility scores. FSL trains relation embeddings while respecting
    inequalities implied by rules. This interplay between deductive (rules) and inductive
    (embeddings) knowledge enables more sophisticated agent reasoning.
- name: Graph Neural Networks for Supervised Agent Classification
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:393-445)
    quote: A graph neural network (GNN) builds a neural network based on the topology
      of the data graph... Unlike knowledge graphs embeddings, GNNs support end-to-end
      supervised learning for specific tasks
  description: GNNs provide agents with supervised learning capabilities over graph-structured
    data. Agents can use GNNs to classify graph elements or entire graphs, predict
    traffic patterns, build recommendations, and even replace traditional graph algorithms
    for finding central nodes. The GNN topology mirrors the knowledge graph structure,
    enabling agents to learn task-specific patterns.
- name: Symbolic Learning for Interpretable Agent Models
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:646-696)
    quote: An alternative (sometimes complementary) approach is to adopt symbolic
      learning in order to learn hypotheses in a symbolic (logical) language that
      explain a given set of positive and negative edges
  description: Symbolic learning enables agents to discover interpretable rules and
    axioms from knowledge graphs. Unlike numeric embedding models, symbolic models
    (rules, DL axioms) are interpretable, can be verified by domain experts, and apply
    to unseen examples through quantification. Agents can use learned rules for deductive
    reasoning and providing explanations for predictions.
- name: Rule Mining for Agent Knowledge Acquisition
  sources:
  - chunk_ref: 02-Knowledge_Graphs (Chunk 5:704-770)
    quote: Rule mining, in the general sense, refers to discovering meaningful patterns
      in the form of rules from large collections of background knowledge... The goal
      of rule mining is to identify new rules that entail a high ratio of positive
      edges from other positive edges
  description: Agents can use rule mining systems like AMIE to automatically discover
    logical rules from knowledge graphs. Rules are learned with support and confidence
    measures, enabling agents to identify patterns that generalize well. The Partial
    Completeness Assumption (PCA) handles incomplete data typical in real-world knowledge
    graphs.
- name: PROV-AGENT Model for Agentic Workflow Provenance
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:30-38)
    quote: PROV-AGENT, a provenance model that extends W3C PROV and leverages the
      Model Context Protocol (MCP) and data observability to integrate agent interactions
      into end-to-end workflow provenance
  description: PROV-AGENT extends W3C PROV ontology to capture AI agent interactions
    within agentic workflows. It integrates agent-specific metadata (prompts, responses,
    decisions) with broader workflow context, enabling end-to-end traceability. This
    ontological extension allows agents and their actions to be first-class citizens
    in provenance graphs, supporting hallucination detection and root cause analysis.
- name: Agent-Activity-Entity Triad in PROV Ontology
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:197-204)
    quote: The W3C PROV standard already defines Agent, the central abstraction in
      this work, as one of its three core classes, alongside Entity (data) and Activity
      (process), with agents representing either software or human actors responsible
      for activities
  description: 'W3C PROV provides a foundational ontological structure with three
    core classes: Agent, Entity, and Activity. This Agent-Activity-Entity triad serves
    as the basis for modeling AI agent interactions. Agents are responsible for activities
    that use and generate entities, creating a queryable provenance graph for understanding
    agent behavior.'
- name: AIAgent as Ontological Extension
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:278-296)
    quote: We extend the abstract W3C PROV Agent by modeling AIAgent as its subclass,
      enabling a natural integration of agent actions and interactions into the broader
      workflow provenance graph
  description: PROV-AGENT models AIAgent as a subclass of PROV Agent, enabling ontology-guided
    integration of AI agents into workflow provenance. Agent tools (AgentTool) are
    associated with AIModelInvocations that use Prompts and generate ResponseData.
    This ontological structure supports multi-agent scenarios and captures collaborative
    or parallel agent behaviors.
- name: MCP-Based Agent Tool Provenance Capture
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:338-377)
    quote: Building on the MCP concepts, when the MCP server is initialized, we begin
      by creating a new instance of AIAgent... we introduce a new decorator, @flowcept_agent_tool,
      which creates a corresponding AgentTool execution activity
  description: The Model Context Protocol (MCP) provides standardized concepts for
    agentic AI development that can be captured in provenance ontology. Agent tools
    decorated with @flowcept_agent_tool automatically create AgentTool activities
    linked to executing agents via PROV relationships. This enables runtime capture
    of agent-ontology interactions.
- name: Provenance Queries for Agent Lineage Tracing
  sources:
  - chunk_ref: 03-PROV-AGENT (Chunk 1:493-537)
    quote: Given an agent decision Agent_Decision_i, the query traverses to its generating
      Agent_Tool_i, then to the inputs it used... These are traced back through Model_Evaluation_i
      and Physics_Model_i to the original Sensor_Data_i
  description: Ontology-structured provenance enables sophisticated queries for tracing
    agent decisions. Agents can query their own lineage to understand decision origins,
    trace error propagation, identify hallucination sources, and understand downstream
    impacts. The unified provenance graph supports Q&A about agent reasoning, prompt-response
    relationships, and control flow influence.
- name: OCEL 2.0 Schema for Object-Event-Agent Relationships
  sources:
  - chunk_ref: 09-OCEL_20_Specification (Chunk 4:197-331)
    quote: We defined a validation schema for the OCEL 2.0 JSON specification... events,
      objects, eventTypes, objectTypes with relationships and attributes
  description: OCEL 2.0 provides a JSON schema that structures object-centric event
    data with typed events, typed objects, and qualified relationships. Events contain
    relationships to objects with qualifiers explaining the nature of the relationship.
    This schema supports agents in understanding process semantics and enables ontology-based
    extraction and validation of event data.
- name: Standard Object and Event Types for AI Integration
  sources:
  - chunk_ref: 09-OCEL_20_Specification (Chunk 4:386-405)
    quote: We also hope that OCEL 2.0 will also be the basis for creating standard
      object and event types for different application domains... This creates possibilities
      for both generative and discriminative Artificial Intelligence (AI)
  description: OCEL 2.0 aims to standardize object and event types across application
    domains, enabling AI agents to work with normalized process data. Standard taxonomies
    of objects/events with inheritance support both generative AI (creating process
    models) and discriminative AI (classifying process behaviors). Agents can leverage
    domain-standard ontologies without reinventing definitions.
- name: Object-Centric Process Mining with Ontological Metrics
  sources:
  - chunk_ref: 10-OC-PM (Chunk 2:71-112)
    quote: We present some possibilities for conformance checking on top of object-centric
      event logs... confnum_obj and confdur_lif as the set of events/objects violating
      the rule
  description: Object-centric process mining enables agents to apply conformance checking
    rules to event logs. Agents can detect anomalies like excessive objects per activity
    or abnormal lifecycle durations using ontologically-defined constraints. The metrics
    (CC1, CC2) provide agents with model-independent verification of process properties.
- name: Graph Database Queries for Process Mining
  sources:
  - chunk_ref: 10-OC-PM (Chunk 2:403-418)
    quote: In [18,19], the usage of graph databases for the storage, querying, and
      aggregation of object-centric event data is proposed. An object-centric event
      log is inserted in the graph by creating nodes for the events, objects, object
      types
  description: Graph databases provide agents with flexible query and aggregation
    capabilities over object-centric event data. Events, objects, and types become
    graph nodes with connecting edges based on log content. Ontology-based extraction
    approaches enable agents to query process data using semantic relationships rather
    than relational schemas.
- name: Ontology-Based Data Access for Event Log Extraction
  sources:
  - chunk_ref: 12-Foundations_of_Process_Event_Data (Chunk 1:426-433)
    quote: One noteworthy scientific initiative in this context is ontology-based
      data access (ODBA) for event log extraction. The approach is based on an ontological
      view of the domain of interest and linking it as such to a database schema
  description: Ontology-Based Data Access (OBDA) enables agents to extract event logs
    using ontological mappings to database schemas. Implemented in tools like Onprom,
    OBDA provides an ontological view of the domain that guides event extraction.
    Agents can leverage domain ontologies to transform relational data into process-oriented
    event logs without manual mapping.
- name: OCEL Standard for Multi-Case Agent Reasoning
  sources:
  - chunk_ref: 12-Foundations_of_Process_Event_Data (Chunk 1:431-433)
    quote: Finally, the recently introduced OCEL standard is another relevant piece
      of work, putting forward a general standard to interchange object-centric event
      data with multiple case notions
  description: The OCEL standard provides agents with a normalized format for object-centric
    event data supporting multiple case notions simultaneously. Agents can reason
    across different process perspectives without flattening data to a single case
    ID. This enables more sophisticated multi-object, multi-process analysis by AI
    agents.
- name: Ontological Knowledge Graph as Agent Context Provider
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:30-34)
    quote: 'SciAgents, an approach that leverages three core concepts: (1) the use
      of large-scale ontological knowledge graphs to organize and interconnect diverse
      scientific concepts'
  description: The framework integrates ontological knowledge graphs as the foundational
    substrate for multi-agent reasoning. The knowledge graph organizes and interconnects
    diverse scientific concepts, providing agents with structured context for hypothesis
    generation. This demonstrates how agents can interact with ontological structures
    to guide their reasoning and discovery process.
- name: Sub-graph Sampling for Agent Context Injection
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:133-137)
    quote: We implemented a novel sampling strategy to extract relevant sub-graphs
      from this comprehensive knowledge graph, allowing us to identify and understand
      the key concepts and their interrelationships
  description: Agents receive ontological context through sub-graph extraction rather
    than accessing the entire knowledge graph. This sampling strategy allows agents
    to work with focused, relevant portions of the ontology, enabling targeted reasoning
    while maintaining computational efficiency. The sub-graph serves as the agent's
    contextual knowledge substrate.
- name: Ontologist Agent for Concept Relationship Interpretation
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:225-227)
    quote: 'Each agent plays a specialized role: The Ontologist defines key concepts
      and relationships, Scientist 1 crafts a detailed research proposal'
  description: A dedicated Ontologist agent is responsible for defining concepts and
    relationships from the knowledge graph, translating ontological structure into
    actionable knowledge for other agents. This agent serves as the interface between
    the formal ontology and the reasoning agents, interpreting graph data into meaningful
    scientific relationships.
- name: Path-Based Graph Traversal for Knowledge Discovery
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:239-246)
    quote: At the core of our model is an expansive knowledge graph... we provide
      it with a sub-graph derived from this more extensive knowledge graph. This sub-graph
      depicts a pathway that connects two crucial concepts or nodes
  description: Agents interact with ontologies through path-based traversal, following
    connections between nodes to discover relationships. The path represents a chain
    of ontological relationships (concept -- relation -- concept) that guides agent
    reasoning. Random path sampling infuses richer conceptual diversity compared to
    shortest-path approaches.
- name: Dynamic Knowledge Generation from Static Ontology
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:289-296)
    quote: the agent helps transition from static knowledge retrieval to dynamic knowledge
      generation. This crucial shift is what enables the model to identify gaps in
      existing research and propose new angles of inquiry
  description: Agents use ontological structures not just for retrieval but for generative
    reasoning. The Ontologist agent applies advanced reasoning and inference techniques
    to synthesize and interpret the complex web of ontological data, extracting insights
    that are not obvious from the graph structure alone. This transforms static ontology
    into dynamic hypothesis generation.
- name: Multi-Agent Role Specialization for Ontology Processing
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:708-738)
    quote: 'Human: human user... Planner: suggests a detailed plan... Ontologist:
      responsible to define the relationships and concepts within the knowledge graph.
      Scientist 1: crafts the initial draft... Critic: conducts a thorough review'
  description: The multi-agent system assigns specialized roles for processing ontological
    knowledge. The Ontologist agent specifically handles concept definition and relationship
    interpretation, while other agents (Planner, Scientists, Critic) build upon this
    ontological foundation. This demonstrates role-based decomposition of ontology-to-reasoning
    pipelines.
- name: Knowledge Graph Path as Structured Research Context
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:134-138)
    quote: We use a large graph generated as part of earlier work... The graph utilized
      here includes 33,159 nodes and 48,753 edges and represents the giant component
      of the graph generated from around 1,000 papers
  description: The ontological knowledge graph is constructed from scientific literature
    (1,000 papers) and serves as structured context for agent reasoning. With 33,159
    nodes and 48,753 edges organized into 92 communities, this represents a large-scale
    ontology that agents navigate to generate research hypotheses.
- name: Heuristic Pathfinding with Embeddings for Ontology Navigation
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:245-260)
    quote: The algorithm presented in this work combines heuristic-based pathfinding
      with node embeddings and randomized waypoints to discover diverse paths in a
      graph... the embeddings are generated using a pre-trained model
  description: Agents navigate ontological graphs using embedding-based heuristics
    rather than purely symbolic traversal. Node embeddings (using BAAI/bge-large-en-v1.5)
    enable semantic similarity-based pathfinding, allowing agents to discover conceptually
    related paths even when explicit ontological links are sparse. This hybrid symbolic-neural
    approach enhances agent-ontology interaction.
- name: Sub-graph Context Expansion for Agent Reasoning
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:256-260)
    quote: After the path is found, a subgraph consisting of the path nodes and their
      second-hop neighbors is generated, providing a broader context for the discovered
      route
  description: Agents receive expanded ontological context beyond the primary path
    by including second-hop neighbors. This enriches the agent's reasoning substrate
    with related concepts and relationships, enabling more comprehensive hypothesis
    generation while maintaining focused relevance to the core research question.
- name: JSON Schema-Guided Ontology-to-Output Generation
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:305-307)
    quote: The output, in JSON format, provides key fields such as mechanisms, unexpected_properties,
      and comparison, offering a highly detailed analysis
  description: Agents translate ontological knowledge into structured JSON outputs
    following predefined schemas. The schema includes fields for hypothesis, outcome,
    mechanisms, design principles, unexpected properties, comparison, and novelty.
    This demonstrates ontology-guided structured generation where the knowledge graph
    informs content while the schema constrains output format.
- name: Ontology-Guided Hypothesis Generation Pipeline
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:279-307)
    quote: the algorithm begins by identifying two key nodes... The graph structure
      is used not only for identifying the connectivity between the nodes but also
      for guiding the algorithm's search for the most relevant or exploratory paths
  description: 'The full pipeline shows how agents use ontologies: (1) identify key
    nodes, (2) generate path through knowledge graph, (3) extract sub-graph context,
    (4) expand definitions via Ontologist agent, (5) generate structured hypothesis
    via Scientist agents, (6) critique and refine via Critic agent. This demonstrates
    end-to-end ontology-guided agent reasoning.'
- name: Semantic Scholar API for Literature-Based Ontology Validation
  sources:
  - chunk_ref: 15-SciAgents (Chunk 2:505-511)
    quote: We use the Semantic Scholar API, an AI-powered search engine for academic
      resources, to search for related publications using a set of keywords... The
      novelty assistant agent then thoroughly analyzes the abstracts and provides
      a review
  description: Agents validate ontology-derived hypotheses against external literature
    databases. The Assistant agent calls Semantic Scholar API to retrieve related
    publications, and a Novelty Assistant agent analyzes whether the ontology-guided
    hypothesis is novel relative to existing research. This demonstrates external
    knowledge source integration for ontology validation.
- name: Automated Agent Selection via Group Chat Manager
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:770-773)
    quote: The manager selects the working agents to collaborate based on the current
      chat context, fostering cooperation and enabling mutual adjustments to solve
      the problem
  description: A Group Chat Manager orchestrates which agents engage with ontological
    data at each step of the reasoning process. The manager dynamically selects agents
    based on conversation context, enabling adaptive workflow where ontology processing
    is distributed across specialized agents as needed.
- name: Shared Memory for Ontological Context Propagation
  sources:
  - chunk_ref: 15-SciAgents (Chunk 1:784-788)
    quote: the second approach allows agents to share memory, giving them access to
      all the content generated in previous interactions. This means they operate
      with full visibility of the history of their collaboration
  description: Agents share memory containing ontological context and derived insights.
    Unlike the first approach where agents receive filtered information, the automated
    multi-agent system provides full visibility of collaboration history, ensuring
    ontological definitions and relationships propagate consistently across all agent
    interactions.
- name: Knowledge Graph Path Generation for Agent Reasoning
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:145-165)
    quote: 'Generate Random Keywords and Knowledge Path: Use the generate_path function
      to generate a knowledge path between two randomly selected keywords'
  description: SciAgents uses a generate_path function to create knowledge paths between
    concepts in the ontology/knowledge graph. This path then serves as the structured
    input for multi-agent reasoning, with the ontologist agent defining terms and
    relationships from the graph traversal. This demonstrates how AI agents can programmatically
    query ontological structures to retrieve semantic context for research generation.
- name: Ontologist Agent as Knowledge Graph Interpreter
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:131-133)
    quote: 'ontologist: An ontologist who defines each of the terms and discusses
      the relationships in the path'
  description: A specialized 'ontologist' agent role is responsible for interpreting
    knowledge graph paths - defining terms and explicating relationships between concepts.
    This agent bridges raw graph data and human-interpretable semantic knowledge,
    translating ontological structure into actionable definitions for downstream reasoning
    agents.
- name: Multi-Agent Orchestration with Ontology-Driven Roles
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:127-139)
    quote: 'planner: A planner who can suggest a plan... ontologist: An ontologist
      who defines each of the terms... scientist: A scientist who can craft the research
      proposal'
  description: SciAgents implements a multi-agent architecture where specialized agents
    (planner, ontologist, scientist, hypothesis_agent, outcome_agent, mechanism_agent,
    etc.) collaborate on research proposal generation. The ontologist agent specifically
    interfaces with the knowledge graph, providing semantic grounding for the scientist
    and other specialized agents that expand proposal aspects.
- name: Ontology-to-Research-Proposal Pipeline
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:171-182)
    quote: 'Define Terms and Relationships: The ontologist will define each term...
      Craft the Research Proposal: The scientist will use the definitions and relationships
      provided by the ontologist'
  description: The system implements a structured pipeline where ontological knowledge
    (terms and relationships from the knowledge graph) flows from the ontologist agent
    to the scientist agent, who then crafts research proposals grounded in the formal
    semantic definitions. This represents ontology-guided content generation.
- name: Knowledge Path as Semantic Context Injection
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:229-232)
    quote: heat transfer performance -- considered analogous despite differences in
      surface wettability -- soft lithography -- improves for biological applications
      -- biocompatibility
  description: The knowledge graph path is presented as a chain of concepts connected
    by relationship predicates (e.g., 'improves for', 'demonstrate', 'can be combined
    with'). This path structure provides rich semantic context that agents use to
    understand how concepts relate, enabling ontology-guided reasoning about novel
    research directions.
- name: Relationship Taxonomy from Graph Traversal
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:253-314)
    quote: 'Soft Lithography -- improves for biological applications -- Biocompatibility:
      Soft lithography techniques are enhanced when applied to biological applications'
  description: The ontologist agent extracts and explicates typed relationships from
    the knowledge graph, including relationship categories like 'improves for', 'demonstrate',
    'can be combined with', 'is found in'. These relationship types form a taxonomy
    that structures how agents reason about concept connections.
- name: Agent-Driven Hypothesis Generation from Graph Structure
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:355-361)
    quote: 'Title: Development of Biomimetic Microfluidic Chips with Enhanced Heat
      Transfer Performance... Hypothesis: We hypothesize that integrating biomimetic
      materials with microfluidic chips'
  description: The scientist agent generates novel research hypotheses by synthesizing
    the ontological definitions and relationships provided by the ontologist. The
    hypothesis directly derives from combining concepts connected in the knowledge
    graph path, demonstrating ontology-driven creative reasoning.
- name: Specialized Expansion Agents for Proposal Aspects
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:133-139)
    quote: hypothesis_agent who can expand the 'hypothesis' aspect... outcome_agent
      who can expand the 'outcome' aspect... mechanism_agent who can expand the 'mechanism'
      aspect
  description: Seven specialized agents (hypothesis, outcome, mechanism, design_principles,
    unexpected_properties, comparison, novelty) each expand specific aspects of research
    proposals. Each operates on the ontological foundation provided by the ontologist,
    demonstrating how structured knowledge enables modular agent specialization.
- name: Critic Agent for Quality Assessment
  sources:
  - chunk_ref: 15-SciAgents (Chunk 5:138-139)
    quote: 'critic_agent: Summarizes, critiques, and suggests improvements after all
      seven aspects of the proposal have been expanded by the agents'
  description: A critic_agent performs meta-level reasoning over the combined outputs
    of all specialized agents, providing summaries, critiques, and improvement suggestions.
    This represents a quality control layer in multi-agent systems that validates
    ontology-grounded outputs.
- name: Novelty-Feasibility Rating via Knowledge Graph Search
  sources:
  - chunk_ref: 15-SciAgents (Chunk 6:117-127)
    quote: 'Novelty and Feasibility Rating... Novelty: High - The integration of biomimetic
      materials with microfluidic technology... Feasibility: Moderate'
  description: SciAgents includes a rate_novelty_feasibility function that evaluates
    research hypotheses by searching existing literature against the knowledge graph
    concepts. This mechanism uses ontological structure to assess how novel proposed
    combinations are relative to existing knowledge.
- name: Literature Search Validation Against Ontology
  sources:
  - chunk_ref: 15-SciAgents (Chunk 6:141-177)
    quote: 'Literature Search Results: Query 1: ''biomimetic materials microfluidic
      chips heat transfer performance biocompatibility'' Total Results: 36... Query
      2: ''lamellar structure biomaterials keratin scales'' Total Results: 0'
  description: The system performs literature searches using ontological terms and
    relationships to validate hypothesis novelty. Multiple queries are constructed
    from knowledge graph concepts, with result counts indicating how well-explored
    specific concept combinations are in existing literature.
- name: Ontology-Derived Query Construction
  sources:
  - chunk_ref: 15-SciAgents (Chunk 6:144-166)
    quote: 'Query 1: ''biomimetic materials microfluidic chips heat transfer performance
      biocompatibility''... Query 2: ''lamellar structure biomaterials keratin scales
      microfluidic chips soft lithography'''
  description: Search queries for novelty validation are systematically constructed
    from ontological terms extracted from the knowledge graph path. This demonstrates
    how ontology structure can be transformed into information retrieval queries for
    agent-assisted literature review.
- name: Multi-Scale Knowledge Integration
  sources:
  - chunk_ref: 15-SciAgents (Chunk 7:183-193)
    quote: 'Integration of Biological and Mechanical Principles: Novel Aspect: Combining
      cell signaling and mechanical forces to create a dynamic, adaptable material'
  description: The multi-agent system integrates knowledge across multiple scales
    (molecular, cellular, macroscale) as defined in the ontology. Agents reason about
    cross-scale relationships and mechanisms, demonstrating ontology's role in supporting
    multi-scale scientific reasoning.
- name: Hierarchical Structure Ontology Patterns
  sources:
  - chunk_ref: 15-SciAgents (Chunk 6:293-296)
    quote: theoretically reversible or partially reversible -- despite being -- stiffness
      memory -- Demonstrated through -- dynamic 3d structures -- Demonstrated during
      -- biological interactions
  description: Knowledge graph paths encode hierarchical relationships between material
    properties and structures. The ontology captures how properties like 'stiffness
    memory' relate to structures and biological interactions through typed relationship
    predicates, enabling agents to reason about material hierarchies.
- name: Ontology-Guided Mechanism Specification
  sources:
  - chunk_ref: 15-SciAgents (Chunk 6:378-381)
    quote: 'Mechanisms: Molecular Scale: Collagen fibers will self-assemble... Cellular
      Scale: Cell signaling will induce changes... Macroscale: The interconnected
      3D porous architecture'
  description: The mechanism_agent produces detailed mechanism specifications organized
    by ontological scale levels (molecular, cellular, macroscale). The ontology provides
    the categorical structure for organizing mechanistic explanations across levels
    of abstraction.
- name: Quantitative Goal Generation from Ontological Context
  sources:
  - chunk_ref: 15-SciAgents (Chunk 7:206-207)
    quote: 'Quantitative Goal: Achieve a 30% increase in crashworthiness and a 25%
      increase in Young''s modulus compared to traditional materials'
  description: Specialized agents generate specific quantitative goals (percentages,
    measurement values) grounded in ontological concept definitions. The ontology
    provides the semantic context (what properties to measure) while agents generate
    specific target values.
- name: Comparative Analysis Against Ontological Baselines
  sources:
  - chunk_ref: 15-SciAgents (Chunk 7:88-109)
    quote: 'Crashworthiness: Traditional Materials: Typical Performance: Traditional
      materials... exhibit limited crashworthiness due to their homogeneous structure...
      Proposed Material: Expected to exhibit a 30% increase'
  description: The comparison_agent generates structured comparisons between proposed
    materials and baselines defined in the ontology. The ontology provides the categorical
    framework (what properties to compare) while agents populate quantitative comparisons.
- name: Iterative Ontology-to-Proposal Refinement
  sources:
  - chunk_ref: 15-SciAgents (Chunk 7:267-271)
    quote: 'Iterative Design: Optimize the material design based on experimental results
      and computational predictions. Iterate the design and fabrication process to
      achieve the desired mechanical properties'
  description: The multi-agent system supports iterative refinement where experimental
    results feed back into the ontology-grounded proposal generation process. This
    represents a closed-loop between ontological knowledge, agent reasoning, and empirical
    validation.
- name: Multi-Agent Research Proposal Workflow
  sources:
  - chunk_ref: 15-SciAgents (Chunk 10:59-65)
    quote: Caller, please select the outcome_agent to expand on the 'outcome' aspect
      of the research proposal. Agent outcome_agent, please expand...
  description: Demonstrates a structured multi-agent workflow where specialized agents
    (outcome_agent, mechanism_agent, design_principles_agent, critic_agent) interact
    with ontologically-structured knowledge (research hypothesis components). Each
    agent handles a specific facet of the research proposal, showing how agents can
    be organized around ontological categories of scientific reasoning.
- name: Critic Agent Evaluation Pattern
  sources:
  - chunk_ref: 15-SciAgents (Chunk 10:437-448)
    quote: Critical Scientific Review... Strengths... Weaknesses... Suggested Improvements...
      Rating of Novelty and Feasibility
  description: The critic_agent applies a structured ontological framework for evaluation
    with defined categories (Strengths, Weaknesses, Improvements, Ratings). This shows
    how agents can use ontological schemas to structure their reasoning and output
    generation for consistent evaluation across different research proposals.
- name: Molecular Modeling Agent Integration
  sources:
  - chunk_ref: 15-SciAgents (Chunk 10:505-566)
    quote: Key Steps to Set Up and Conduct Molecular Modeling and Simulation... 1.
      Define the Objective... 2. Select Appropriate Modeling Techniques
  description: Demonstrates agent-ontology integration where the user agent requests
    molecular modeling guidance. The response follows an ontologically-structured
    methodology (objective definition, technique selection, model preparation, simulation
    setup) showing how domain ontologies can guide agent reasoning and output structure.
- name: Autonomous KG Reasoning Agent Framework
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:19-39)
    quote: we propose an autonomous LLM-based agent framework, called KG-Agent, which
      enables a small LLM to actively make decisions until finishing the reasoning
      process over KGs
  description: 'Core pattern for agent-ontology integration: KG-Agent integrates LLM,
    multifunctional toolbox, KG-based executor, and knowledge memory. The agent autonomously
    iterates through tool selection and memory updates to reason over knowledge graphs,
    demonstrating tight coupling between agent decision-making and KG structure.'
- name: Three-Tool-Type KG Toolbox
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:237-259)
    quote: we design three types of tools for LLMs reasoning over KG, i.e., extraction,
      semantic, and logic tools
  description: 'Ontology-guided tool design pattern: Extraction tools (get_relation,
    get_head_entity, get_tail_entity), Logic tools (count, intersect, union, judge,
    end), and Semantic tools (retrieve_relation, disambiguate_entity). The toolbox
    structure mirrors the ontological operations needed for KG traversal and reasoning.'
- name: Knowledge Memory Architecture
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:545-551)
    quote: 'The knowledge memory preserves the currently useful information... It
      mainly contains four parts: natural language question, toolbox definition, current
      KG information, and history reasoning program'
  description: Agent memory structured around ontological knowledge access. The four-part
    memory design (question, toolbox, KG info, history) enables the agent to maintain
    context while reasoning over KG, showing how ontological structure informs agent
    memory architecture.
- name: Program-Based KG Reasoning Synthesis
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:99-105)
    quote: we leverage program language to formulate the multi-hop reasoning process
      over the KG, and synthesize a code-based instruction dataset to fine-tune the
      base LLM
  description: 'Novel pattern for agent-ontology integration: converting KG reasoning
    chains into programmatic function calls. This bridges symbolic KG operations with
    LLM-based agent reasoning, allowing the agent to execute structured queries against
    the ontological knowledge base.'
- name: Iterative Tool Selection and Memory Update
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:629-638)
    quote: The KG-Agent framework autonomously iterates the above tool selection and
      memory updation process to perform step-by-step reasoning, where the knowledge
      memory is used to maintain the accessed information
  description: Autonomous iteration pattern where the agent walks through the KG along
    relations, with tool selection guided by ontological structure. The agent stops
    when reaching answer entities, demonstrating how ontology structure guides agent
    termination conditions.
- name: Query Graph to Reasoning Program Conversion
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 1:420-431)
    quote: the query graph has a tree-like structure that can be directly mapped to
      a logical form... we adopt breadth-first search (BFS) to visit all the nodes
      on the query graph
  description: Pattern for converting ontological query structures into agent-executable
    reasoning chains. BFS traversal of query graphs produces reasoning chains that
    link start entities to answer entities while respecting constraint conditions.
- name: Agent Tool Interface Specification
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 2:752-845)
    quote: 'Table 8: The detailed definition and usage of all the tools... get_relation:
      Input: entity set... Output: one-hop relations'
  description: Formal specification of agent-ontology interface through tool definitions.
    Each tool maps to specific KG operations with typed inputs/outputs (entity sets,
    relations, constraints), providing a contract between agent reasoning and ontological
    operations.
- name: Multi-KG Transfer Learning
  sources:
  - chunk_ref: 16-KG-Agent (Chunk 2:663-666)
    quote: the agent instruction tuning data is constructed from various KGs (e.g.,
      Wikidata and Freebase), which helps our KG-Agent to learn the general autonomous
      decision making capabilities over various KGs
  description: 'Cross-ontology agent training pattern: by training on multiple KGs
    with different schemas, the agent learns transferable reasoning patterns independent
    of specific ontological structures, enabling generalization across knowledge domains.'
- name: Logic-Embedding Integration Taxonomy
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:21-27)
    quote: 'we have a more fine-grained categorization to these studies, from two
      perspectives: (i) injecting logics... into embedding learning, and (ii) utilizing
      KG embeddings for logic reasoning-relevant tasks'
  description: 'Fundamental taxonomy for agent-ontology integration: distinguishes
    between (1) using ontological logic to enhance embeddings and (2) using embeddings
    to enhance ontological reasoning. This bidirectional integration pattern applies
    to how agents can leverage both symbolic and neural approaches.'
- name: Embedding-Based Query Answering
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:359-368)
    quote: Query answering returns correct entities in a KG as answers of a given
      structured query, where reasoning is usually considered for hidden answers
  description: Pattern for agents to answer queries over incomplete KGs using embeddings.
    Enables agents to handle uncertainty in ontological knowledge by predicting plausible
    answers rather than relying solely on explicit KG triples.
- name: Differentiable Theorem Proving
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:418-436)
    quote: Differentiable theorem proving using embeddings overcome the limits of
      symbolic provers on generalizing to queries with similar but not identical symbols
  description: 'NTP (Neural Theorem Prover) pattern: agents can prove theorems over
    KGs by comparing symbols using embeddings rather than exact matches. Enables generalization
    in ontological reasoning while maintaining logical structure.'
- name: Embedding-Guided Rule Mining
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:454-475)
    quote: RuLES adds confidential triples using embedding models for quality extension
      of KGs. It iteratively extends rules induced from a KG through feedback from
      embedding models
  description: 'Pattern for agents to discover new ontological rules: embeddings help
    evaluate rule quality and guide search during rule mining, compensating for KG
    incompleteness. Enables agents to extend their ontological knowledge base autonomously.'
- name: Logic Types for KG Integration
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:124-128)
    quote: 'We consider two mainstream logic forms used in KG reasoning: (1) logic
      rules and (2) Ontological schema, such as those supported by OWL 2'
  description: 'Classification of logic types for agent-ontology integration: path
    rules (compositional reasoning) and ontological schemas (OWL 2 axioms, class hierarchies,
    relation properties). Agents must handle both rule-based and schema-based ontological
    knowledge.'
- name: Integration Stage Classification
  sources:
  - chunk_ref: 17-KG_Reasoning (Chunk 1:136-140)
    quote: 'there are three stages: 1) Pre: conducting symbolic reasoning before learning
      embeddings... 2) Joint: injecting the logics during embedding learning... 3)
      Post: conducting symbolic reasoning after embeddings are learned'
  description: 'Temporal pattern for agent-ontology integration: Pre, Joint, and Post
    stages determine when ontological constraints are applied relative to embedding
    learning. Informs agent pipeline design for combining symbolic and neural components.'
- name: Agent Interaction Layer Architecture
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 1:74-80)
    quote: LLM-powered multi-agent systems realize an interaction layer... Externally,
      this layer facilitates the interaction between the LLM and its contextual environment...
      Internally, the interaction layer allows for organizing the task-management
      activity
  description: 'Architectural pattern for agent-ontology integration: the interaction
    layer mediates between agents, LLMs, and contextual resources (data, tools, models).
    This layer enables ontology-aware coordination of multi-agent activities and resource
    access.'
- name: Domain-Ontology Model for Multi-Agent Systems
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 1:185-188)
    quote: We outline the architectural characteristics of autonomous LLM-powered
      multi-agent systems and propose a domain-ontology model represented as a UML
      class diagram structuring the architectural concepts
  description: 'Meta-pattern: using domain ontologies to formally specify multi-agent
    system architecture. The UML class diagram structures concepts like Agent, Task,
    Action, Memory, Context, and their relationships, providing an ontological foundation
    for agent system design.'
- name: Task-Management Activity Ontology
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 1:856-868)
    quote: 'Task decomposition is the first of three core phases within the Task-Management
      Activity: Decomposition... Orchestration... Synthesis'
  description: 'Ontological structuring of agent task management into three phases:
    (1) Decomposition of complex tasks, (2) Orchestration distributing tasks to agents,
    (3) Synthesis combining results. This ontology guides how agents organize and
    execute work.'
- name: Agent Type Ontology
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 1:902-921)
    quote: 'Task-Management Agents... Domain Role Agents... Technical Agents: These
      agents are tech-savvies, typically tasked with interfacing with technical platforms'
  description: 'Classification ontology for agent types: Task-Management Agents (creation,
    prioritization, execution), Domain Role Agents (domain-specific experts), and
    Technical Agents (SQL Agent, Python Agent). This ontology informs agent composition
    and specialization.'
- name: Context Resource Ontology
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 2:104-166)
    quote: Tools... can be categorized into... Search and Analysis Tools... Execution
      Tools... Reasoning Tools... Development Tools... Communication Tools
  description: 'Ontological classification of contextual resources available to agents:
    Tools (5 categories), Data (4 types including structured, unstructured, multimodal,
    domain-specific), and Foundation Models (NLP, Vision, Audio, Multimodal). This
    ontology guides agent-resource integration.'
- name: Communication Protocol Ontology
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 2:75-92)
    quote: 'distinct protocols are observable: Strict finite processes... Dialogue
      cycles... Multi-cycle process frameworks with interactions between generic agent
      types'
  description: 'Ontological classification of multi-agent communication patterns:
    (1) Strict finite processes with predefined action sequences, (2) Dialogue cycles
    with alternating delegate/execute actions, (3) Multi-cycle frameworks with dynamic
    agent interactions. Informs how agents coordinate using ontological protocols.'
- name: Action Type Ontology for Agents
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 2:35-49)
    quote: 'the following sub-types of Action performed by the Agents can be distinguished:
      DecomposeTask... Create Task... DelegateTask... ExecuteTask... EvaluateResult...
      MergeResult'
  description: 'Ontology of agent actions: DecomposeTask, CreateTask, DelegateTask,
    ExecuteTask, EvaluateResult, MergeResult. Each action type has defined semantics
    and can be composed into larger workflows, providing an ontological basis for
    agent behavior specification.'
- name: Autonomy-Alignment Balance Framework
  sources:
  - chunk_ref: 18-Multi-Agent (Chunk 2:185-204)
    quote: Alignment, on the one hand, primarily manifests through the implementation
      of dedicated Alignment Techniques by the System Architect... Autonomy, on the
      other hand, primarily surfaces from the capability of the multi-agent system
      to fulfill the designated Goal
  description: Framework for balancing agent autonomy with ontological alignment constraints.
    Alignment techniques (integrated by architects) and user preferences provide ontological
    guardrails, while agent autonomy enables self-organized strategy and reasoning.
    This interplay is central to agent-ontology integration.
- name: Domain-Ontology Driven Viewpoint Architecture
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 3:46-50)
    quote: Drawing from the domain-ontology model (Fig. 4), we now systematize the
      viewpoint-specific aspects employed in our taxonomy
  description: The taxonomy uses a domain-ontology model as the foundation for systematizing
    architectural viewpoints in multi-agent systems. This demonstrates how ontological
    structures can guide the organization and classification of agent architectures,
    with viewpoints derived from ontological categories.
- name: Ontology-Grounded Agent Composition Taxonomy
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 3:201-208)
    quote: The aspects of Agent Composition applied by the taxonomy comprise Agent
      Generation, Role Definition, Memory Usage, and Network Management
  description: 'Agent composition is taxonomically organized around four ontological
    aspects: how agents are created, how roles are specified, how memory is utilized,
    and how network relationships are managed. This provides an ontological framework
    for understanding agent architecture.'
- name: Contextual Resource Ontology Integration
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 3:239-244)
    quote: For Context Interaction, the taxonomic aspects comprise Resources Integration
      and Resources Utilization
  description: Context interaction with external resources (data, tools, models) is
    formally categorized into integration mechanisms and utilization patterns. This
    ontological structuring enables systematic analysis of how agents interface with
    contextual resources.
- name: Goal-Task Ontological Decomposition
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 3:118-124)
    quote: 'Taxonomic aspects of Goal-driven Task Management comprise the three constituting
      phases: Decomposition, Orchestration, and Synthesis'
  description: 'Goal-driven task management is ontologically decomposed into three
    phases: how goals are broken into sub-tasks (Decomposition), how tasks are distributed
    among agents (Orchestration), and how results are combined (Synthesis). This triad
    provides an ontological foundation for understanding agent task workflows.'
- name: Multi-Viewpoint Ontological Analysis
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 3:73-76)
    quote: Across the four distinct viewpoints, a total of 12 characteristic aspects
      are identified. Each of these aspects can be assessed and classified
  description: The taxonomy identifies 12 ontological aspects across four viewpoints
    (Goal-driven Task Management, Multi-Agent Collaboration, Agent Composition, Context
    Interaction), enabling systematic classification of multi-agent system configurations.
- name: Autonomy-Alignment Matrix for Agent Classification
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 4:196-204)
    quote: Our taxonomy conceptualizes autonomy and alignment not as binary extremes
      in a one-dimensional continuum, but as interacting and synergistic aspects
  description: The taxonomy provides an ontological framework for classifying agents
    along two dimensions (autonomy and alignment), creating a two-dimensional matrix
    that enables nuanced categorization of agent behaviors and system configurations.
- name: Agent-Role Ontological Flexibility
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 4:51-60)
    quote: Role-Agent Systems employ an interplay or simulation between multiple dedicated
      roles agents. This collaboration can serve different purposes
  description: Role-agent systems leverage ontological role definitions to enable
    flexible agent collaboration. Agents play defined roles with dedicated responsibilities,
    enabling domain-specific applications through ontological role specialization.
- name: Integrated Alignment via Ontological Mechanisms
  sources:
  - chunk_ref: 18-Multi-Agent_Architecture_Taxonomy_LLM (Chunk 4:86-90)
    quote: the predefined and rule-based mechanisms serve as integrated alignment
      guiding and controlling the accurate operation of the dependent autonomous aspects
  description: Ontological mechanisms (predefined rules and structures) serve as integrated
    alignment tools that guide autonomous agent behavior. This shows how ontological
    constraints can control agent operations without requiring explicit user intervention.
- name: Graph-Based Thought Reasoning Structure
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:17-22)
    quote: The key idea and primary advantage of GoT is the ability to model the information
      generated by an LLM as an arbitrary graph, where units of information are vertices,
      and edges correspond to dependencies
  description: Graph of Thoughts models LLM reasoning as a directed graph where thoughts
    are vertices and dependencies are edges. This graph-ontological approach enables
    combining arbitrary thoughts, distilling networks, and using feedback loops -
    advancing beyond linear chain-of-thought reasoning.
- name: Graph Reasoning State (GRS) for Agent Memory
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:390-396)
    quote: Graph Reasoning State (GRS) is a dynamic structure that maintains the state
      of the ongoing LLM reasoning process (the history of its thoughts and their
      states)
  description: The GRS provides an ontological memory structure for tracking the entire
    reasoning process, maintaining thought histories, validity scores, and execution
    state. This enables agents to maintain structured knowledge about their reasoning
    trajectory.
- name: Graph of Operations (GoO) as Execution Ontology
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:433-443)
    quote: GoO is a static structure that specifies the graph decomposition of a given
      task, i.e., it prescribes transformations to be applied to LLM thoughts, together
      with their order and dependencies
  description: The Graph of Operations provides an ontological blueprint for task
    execution, specifying thought transformations and their dependencies before execution.
    This separates the execution plan ontology (static) from the reasoning state ontology
    (dynamic).
- name: Thought Transformation Ontology
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:306-316)
    quote: GoT enables novel transformations of thoughts thanks to the graph-based
      model for reasoning. We refer to them as graph-enabled transformations
  description: GoT defines an ontology of thought transformations including Aggregation
    (combining multiple thoughts), Refinement (iterating on a thought), and Generation
    (creating new thoughts from existing ones). This provides a formal vocabulary
    for reasoning operations.
- name: Heterogeneous Graph for Multi-Type Reasoning
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:253-259)
    quote: In certain use cases, graph nodes belong to different classes. GoT embraces
      a heterogeneous graph G = (V, E, c) to model the LLM reasoning, where c maps
      vertices V into their respective classes C
  description: GoT supports heterogeneous graphs where nodes can be typed (e.g., plans
    vs paragraphs in writing tasks). This ontological typing enables differentiation
    between kinds of thoughts, supporting more structured reasoning with explicit
    entity categories.
- name: Volume Metric for Reasoning Scope
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:129-134)
    quote: For a given thought v, the volume of v is the number of LLM thoughts, from
      which one can reach v using directed edges
  description: The 'volume' metric provides an ontological measure of reasoning scope
    - quantifying how many prior thoughts could have contributed to a given conclusion.
    This enables comparison of reasoning paradigms (CoT, ToT, GoT) based on their
    ontological connectivity.
- name: Modular Scoring and Ranking Functions
  sources:
  - chunk_ref: 19-Graph_of_Thoughts_LLM_Reasoning (Chunk 1:368-377)
    quote: A score is modeled as a general function E(v, G, p), where v is a thought
      to be evaluated. We use the state of the whole reasoning process (G) in E
  description: Scoring and ranking functions in GoT are ontologically grounded in
    the full graph state, enabling relative evaluation of thoughts based on the entire
    reasoning context. This supports ontology-aware quality assessment of agent reasoning.
- name: Agentic RAG Knowledge Integration Pipeline
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:55-60)
    quote: Agentic RAG transcends these limitations by embedding autonomous AI agents
      into the RAG pipeline. These agents leverage agentic design patterns - reflection,
      planning, tool use, and multi-agent collaboration
  description: Agentic RAG integrates autonomous agents into the retrieval-augmented
    generation pipeline, using four core agentic patterns (reflection, planning, tool
    use, multi-agent collaboration) to dynamically manage retrieval strategies and
    refine contextual understanding through structured knowledge integration.
- name: Graph RAG for Relational Knowledge Reasoning
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:299-317)
    quote: Graph RAG extends traditional RAG systems by integrating graph-based data
      structures... These systems leverage the relationships and hierarchies within
      graph data to enhance multi-hop reasoning
  description: Graph RAG explicitly integrates ontological graph structures (node
    connectivity, hierarchical knowledge management, context enrichment) into the
    RAG pipeline, enabling agents to reason over structured relationships rather than
    just unstructured documents.
- name: 'Agent-G: Knowledge Graph and Document Fusion'
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:446-478)
    quote: Agent-G introduces a novel agentic architecture that integrates graph knowledge
      bases with unstructured document retrieval... combining structured and unstructured
      data sources
  description: Agent-G provides an agentic framework for integrating graph knowledge
    bases with document retrieval. The critic module validates retrieved data for
    relevance, while dynamic agent interaction coordinates between graph-structured
    and text sources for comprehensive ontology-document fusion.
- name: 'GeAR: Graph-Enhanced Agent Retrieval'
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:583-601)
    quote: 'GeAR advances RAG performance through two primary innovations: Graph Expansion
      enhances conventional base retrievers by expanding the retrieval process to
      include graph-structured data'
  description: GeAR combines graph expansion with agent-based architecture for enhanced
    multi-hop retrieval. Agents autonomously select graph-expanded retrieval paths,
    enabling dynamic reasoning over entity relationships and dependencies in knowledge
    graphs.
- name: Hierarchical Agent Ontological Delegation
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:100-127)
    quote: Hierarchical Agentic RAG systems employ a structured, multi-tiered approach...
      Agents are organized in a hierarchy, with higher-level agents overseeing and
      directing lower-level agents
  description: Hierarchical Agentic RAG uses an ontological hierarchy of agents where
    top-tier agents perform strategic decision-making and delegate to subordinate
    specialist agents. This mirrors ontological class hierarchies, with abstract orchestrators
    directing concrete workers.
- name: Corrective RAG with Ontological Refinement
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:190-224)
    quote: Corrective RAG introduces mechanisms to self-correct retrieval results...
      The core principle lies in its ability to evaluate retrieved documents dynamically,
      perform corrective actions, and refine queries
  description: Corrective RAG employs specialized agents (Relevance Evaluation, Query
    Refinement, External Knowledge Retrieval, Response Synthesis) that iteratively
    refine knowledge retrieval through ontological validation. Documents below relevance
    thresholds trigger corrective query reformulation.
- name: Adaptive RAG Query Complexity Classification
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:314-346)
    quote: Adaptive RAG dynamically adjusting query handling strategies based on the
      complexity of the incoming query... employs a classifier to assess query complexity
      and determine the most appropriate approach
  description: Adaptive RAG uses a classifier to ontologically categorize queries
    by complexity (straightforward, simple, complex), then routes to appropriate retrieval
    strategies. This dynamic categorization enables resource-efficient retrieval based
    on ontological query typing.
- name: Multi-Agent RAG Specialization Architecture
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:874-904)
    quote: Multi-Agent RAG represents a modular and scalable evolution... distributes
      responsibilities across multiple agents, each optimized for a specific role
      or data source
  description: 'Multi-Agent RAG distributes retrieval across specialized agents: SQL
    database agents, semantic search agents, web search agents, and recommendation
    agents. This ontological division of labor enables parallel processing with type-specific
    expertise.'
- name: AI Agent Component Ontology
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:484-502)
    quote: 'In essence, an AI agent comprises: LLM (with defined Role and Task), Memory
      (Short-Term and Long-Term), Planning (Reflection and Self-Critique), Tools (Vector
      Search, Web Search, APIs)'
  description: 'The paper defines a core ontology of AI agent components: LLM as reasoning
    engine, Memory for context persistence, Planning for task decomposition, and Tools
    for external capability extension. This four-component ontology provides a foundational
    model for agent architecture.'
- name: Agentic Workflow Pattern Ontology
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:610-614)
    quote: Agentic workflow patterns structure LLM-based applications to optimize
      performance, accuracy, and efficiency. Different approaches are suitable depending
      on task complexity
  description: 'The survey defines an ontology of agentic workflow patterns: Prompt
    Chaining (sequential processing), Routing (input classification), Parallelization
    (concurrent execution), Orchestrator-Workers (dynamic delegation), and Evaluator-Optimizer
    (iterative refinement). These patterns provide reusable ontological building blocks.'
- name: Reflection Pattern for Ontological Self-Improvement
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 1:512-531)
    quote: Reflection is a foundational design pattern in agentic workflows, enabling
      agents to iteratively evaluate and refine their outputs. By incorporating self-feedback
      mechanisms, agents can identify and address errors
  description: The Reflection pattern enables agents to self-critique outputs using
    feedback loops. Agents generate outputs, critique them for correctness/style/efficiency,
    then incorporate feedback iteratively. This ontological self-improvement mechanism
    is demonstrated in Self-Refine, Reflexion, and CRITIC systems.
- name: Agentic Document Workflows for Knowledge Automation
  sources:
  - chunk_ref: 20-Agentic_RAG_Survey (Chunk 2:701-748)
    quote: Agentic Document Workflows extend traditional RAG paradigms by enabling
      end-to-end knowledge work automation... integrating document parsing, retrieval,
      reasoning, and structured outputs with intelligent agents
  description: ADW provides an ontological framework for document-centric knowledge
    automation, integrating parsing, retrieval, reasoning, and structured output generation.
    The system maintains state across processes, applies domain-specific business
    rules, and generates actionable recommendations through orchestrated agent interaction.
- name: LLM-Driven Process Model to Code Translation
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:12-27)
    quote: we present an exploratory study to investigate the use of LLMs for generating
      smart contract code from business process descriptions
  description: Pattern where LLMs consume formal process model representations (BPMN)
    and generate executable code (Solidity smart contracts). This represents a form
    of agent-ontology integration where the LLM reasons over structured ontological
    process models to produce code that enforces process flow, resource allocation,
    and data-based conditions. The ontology (BPMN metamodel) constrains and guides
    the LLM generation.
- name: Ontology-Augmented Prompt Engineering
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:306-316)
    quote: This encoding is embedded into the prompt, along with the model data, by
      the LLM provider interface, which calls the external LLM provider
  description: Pattern where ontological structures (task IDs, participant IDs, process
    encodings) are embedded into LLM prompts to guide generation. The simulator generates
    encodings that map events and participants to structured representations in smart
    contracts. This shows how ontological metadata becomes part of the agent's context
    for reasoning.
- name: Process Trace Replay for Ontology Conformance Verification
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:238-251)
    quote: An established method to benchmark the correctness of a blockchain-based
      business process is to replay all possible conforming traces (which the smart
      contract has to accept)
  description: Pattern for verifying that LLM-generated code conforms to ontological
    process specifications. Conforming and non-conforming traces are generated from
    the process model (ontology) and replayed against generated artifacts. This represents
    ontology-driven validation of agent outputs, ensuring the agent's work aligns
    with formal process semantics.
- name: Model-Driven Code Generation with LLM Flexibility
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:54-61)
    quote: Blockchain-based business process execution relies on a model-driven paradigm,
      where process descriptions are transformed into executable artefacts based on
      rule-based transformation tools
  description: Integration pattern where traditional rule-based model-to-code transformations
    are augmented with LLM capabilities. LLMs overcome limitations of rigid rule-based
    approaches while still operating on ontologically-structured process models. The
    ontology provides the formal input structure that the LLM transforms.
- name: Few-Shot Ontology Translation
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:145-147)
    quote: In zero-shot prompting, models complete tasks based solely on instructions
      without prior examples, whereas few-shot prompting involves providing a handful
      of illustrative examples
  description: Pattern where agents learn ontology-to-code translation through limited
    examples. One-shot and two-shot prompts with ontological process models guide
    the LLM to produce correct translations. The examples encode the mapping between
    ontological concepts (BPMN elements) and their code representations.
- name: Ontology as Benchmark for Agent Evaluation
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:546-558)
    quote: 'True Positive: Each event in a conforming trace was accepted (led to a
      state change in the contract), and the whole trace led to the end event'
  description: Pattern using ontological specifications to create automated evaluation
    metrics for agent outputs. Process conformance checking based on ontological trace
    definitions (True Positive, False Positive, True Negative, False Negative) enables
    systematic benchmarking of LLM-generated artifacts against formal process specifications.
- name: Virtual Agent for Ontology-Based Process Execution Support
  sources:
  - chunk_ref: 31-BBO_BPMN_Ontology (Chunk 1:77-78)
    quote: the ontology forms a knowledge base (KB) that will be exploited by a virtual
      agent to support operators in the execution of BP step-by-step
  description: Pattern where an AI virtual agent queries and reasons over an ontology-populated
    knowledge base to guide human operators through business process execution. The
    agent uses the BBO ontology to answer questions about process steps, required
    resources, and execution constraints in real-time.
- name: SPARQL Querying for Competency Question Answering
  sources:
  - chunk_ref: 31-BBO_BPMN_Ontology (Chunk 1:524-532)
    quote: Table 7 shows examples of how we turned competency questions into SPARQL
      queries
  description: Pattern for agent-ontology integration via SPARQL query generation.
    Competency questions (natural language) are translated to SPARQL queries against
    the BBO ontology knowledge base. This enables agents to retrieve structured answers
    about process resources, task sequences, manufacturing facilities, and resource
    types from the ontological representation.
- name: Ontology-Driven Process Navigation
  sources:
  - chunk_ref: 31-BBO_BPMN_Ontology (Chunk 1:559-561)
    quote: SELECT ?nextTask WHERE { BBO:T1 BBO:has_outgoing ?SequenceFlow. ?SequenceFlow
      BBO:has_targetRef ?nextTask. ?nextTask a BBO:Task}
  description: Pattern for agents to navigate process execution paths using ontological
    relationships. By querying SequenceFlow relationships and FlowNode references,
    agents can determine task ordering, conditional branches, and execution dependencies.
    This enables dynamic process guidance based on formal ontology structure.
- name: Resource Type Resolution via Ontological Reasoning
  sources:
  - chunk_ref: 31-BBO_BPMN_Ontology (Chunk 1:531-532)
    quote: We have performed queries on the inferred ontology, which explains the
      three answers to question 4
  description: Pattern leveraging ontological reasoning (inference) to resolve resource
    types and classifications. Queries on the inferred ontology return hierarchical
    type information (SoftwareResource, Resource, NamedIndividual), enabling agents
    to reason about resource taxonomy and inheritance relationships defined in BBO.
- name: Ontology-Constrained Output Validation
  sources:
  - chunk_ref: 21-LLM_Smart_Contracts_from_BPMN (Chunk 1:651-659)
    quote: This could involve using LLMs to propose code snippets or modifications,
      which are then rigorously checked against formal specifications
  description: Pattern for responsible AI integration where ontological specifications
    serve as validation constraints for LLM outputs. LLMs propose code that is verified
    against formal process specifications using automated theorem provers or benchmarking
    frameworks. The ontology defines the 'ground truth' for correctness checking.
- name: Natural Language to Process Ontology Pipeline
  sources:
  - chunk_ref: 31-BBO_BPMN_Ontology (Chunk 1:581-582)
    quote: we need to systematically instantiate BBO with all the process descriptions
      in the companies' technical documents. We will implement a Natural Language
      Processing pipeline
  description: Pattern for populating ontologies from natural language using NLP/AI
    pipelines. Technical documents describing business processes are processed to
    extract ontological assertions that instantiate the BBO knowledge base. This enables
    automated knowledge base construction from unstructured sources, which agents
    can then query.
