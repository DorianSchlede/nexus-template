---
batch_id: "tools_standards_9"
field: tools_standards
extracted_at: "2025-12-31T12:00:00Z"
chunks_read: 6
patterns_found: 42
---

patterns:
  # Paper 16: KG-Agent Knowledge Graph Reasoning

  - name: "SPARQL Structured Query Language for KG"
    chunk_ref: "16-KG-Agent (Chunk 1:66-68)"
    quote: "synergy-augmented methods can benefit from the structured search on KG (e.g., SPARQL) and the language understanding capacity of LLMs"
    description: "SPARQL is identified as a key standard for structured search on knowledge graphs. The paper positions SPARQL as enabling structured queries that complement LLM language understanding in synergy-augmented reasoning methods."

  - name: "Freebase Knowledge Graph"
    chunk_ref: "16-KG-Agent (Chunk 1:235)"
    quote: "reasoning over KG (e.g., Freebase or Wikidata) typically requires three fundamental operations"
    description: "Freebase is referenced as one of the major knowledge graph implementations used for KG reasoning benchmarks and research. It serves as a standard dataset for evaluating KGQA methods."

  - name: "Wikidata Knowledge Graph"
    chunk_ref: "16-KG-Agent (Chunk 1:235)"
    quote: "reasoning over KG (e.g., Freebase or Wikidata) typically requires three fundamental operations"
    description: "Wikidata is identified as a primary knowledge graph standard used alongside Freebase for KG reasoning tasks, representing modern open knowledge graph infrastructure."

  - name: "LLaMA2-7B as Backbone LLM"
    chunk_ref: "16-KG-Agent (Chunk 1:271)"
    quote: "we construct a high-quality instruction dataset for fine-tuning a small LLM (i.e., LLaMA2-7B)"
    description: "LLaMA2-7B is used as the standard backbone language model for instruction tuning in the KG-Agent framework, demonstrating that smaller open-source LLMs can be effective for autonomous KG reasoning."

  - name: "SQL Query Format for KGQA"
    chunk_ref: "16-KG-Agent (Chunk 1:284-288)"
    quote: "These KGQA datasets contain the annotated SQL queries that can be executed to directly extract the answer entities for each question"
    description: "SQL is used as the query format standard in KGQA datasets, providing structured representations that can be grounded on knowledge graphs for reasoning program synthesis."

  - name: "Python Program Compiler for KG Execution"
    chunk_ref: "16-KG-Agent (Chunk 1:568-569)"
    quote: "the KG-based executor will execute it using a program compiler. It can cache or operate the intermediate variables"
    description: "A program compiler (Python-based) serves as the execution environment for KG-Agent, enabling code-format function calls to be executed against the knowledge graph."

  - name: "WebQSP Benchmark Dataset"
    chunk_ref: "16-KG-Agent (Chunk 1:676-677)"
    quote: "i.e., WebQSP, CWQ, and GrailQA, which are based on Freebase"
    description: "WebQSP (Web Questions Semantic Parsing) is a standard benchmark dataset for KGQA based on Freebase, used for evaluating in-domain KG reasoning performance."

  - name: "CWQ Complex WebQuestions Dataset"
    chunk_ref: "16-KG-Agent (Chunk 1:676-677)"
    quote: "i.e., WebQSP, CWQ, and GrailQA, which are based on Freebase"
    description: "Complex WebQuestions (CWQ) is a challenging benchmark dataset extending WebQSP with multi-hop and constraint-based questions for evaluating complex KGQA."

  - name: "GrailQA Benchmark Dataset"
    chunk_ref: "16-KG-Agent (Chunk 1:677)"
    quote: "i.e., WebQSP, CWQ, and GrailQA, which are based on Freebase"
    description: "GrailQA is a comprehensive benchmark dataset for evaluating generalization in KGQA across three levels: i.i.d., compositional, and zero-shot settings."

  - name: "KQA Pro Wikidata-based Dataset"
    chunk_ref: "16-KG-Agent (Chunk 1:678)"
    quote: "and KQA Pro, which is based on Wikidata"
    description: "KQA Pro is a benchmark dataset based on Wikidata requiring multiple reasoning capabilities including compositional reasoning, multi-hop reasoning, and quantitative comparison."

  - name: "OpenAI API for LLM Access"
    chunk_ref: "16-KG-Agent (Chunk 2:633-635)"
    quote: "When evaluating the performance of Davinci-003, ChatGPT, and GPT4, we use the latest February version of APIs from OpenAI"
    description: "OpenAI APIs (gpt-3.5-turbo-instruct, gpt-3.5-turbo, gpt-4) serve as standard interfaces for accessing commercial LLMs for KGQA evaluation and baseline comparison."

  - name: "MetaQA Movie Domain KG"
    chunk_ref: "16-KG-Agent (Chunk 2:469-470)"
    quote: "we further select the MetaQA (Zhang et al., 2018), which is based on a domain-specific movie KG"
    description: "MetaQA is a domain-specific benchmark based on a movie knowledge graph, used to evaluate generalizability of KG reasoning methods to specialized domains."

  # Paper 17: KG Reasoning Logics Embeddings Survey

  - name: "OWL Web Ontology Language"
    chunk_ref: "17-KG_Reasoning (Chunk 1:44-48)"
    quote: "HermiT [Glimm et al., 2014] is a classic description logic reasoner for OWL ontologies; RDFox [Nenov et al., 2015] is a famous KG storage supporting Datalog rule reasoning"
    description: "OWL (Web Ontology Language) is identified as the key standard schema language for knowledge graphs, with HermiT as a classic description logic reasoner for OWL ontologies."

  - name: "HermiT Description Logic Reasoner"
    chunk_ref: "17-KG_Reasoning (Chunk 1:44)"
    quote: "HermiT [Glimm et al., 2014] is a classic description logic reasoner for OWL ontologies"
    description: "HermiT is referenced as a classic implementation of description logic reasoning for OWL ontologies, representing the standard tool for symbolic ontology reasoning."

  - name: "RDFox KG Storage with Datalog"
    chunk_ref: "17-KG_Reasoning (Chunk 1:45)"
    quote: "RDFox [Nenov et al., 2015] is a famous KG storage supporting Datalog rule reasoning"
    description: "RDFox is identified as a prominent knowledge graph storage system supporting Datalog rule reasoning, combining efficient storage with logical inference capabilities."

  - name: "SROIQ Description Logic"
    chunk_ref: "17-KG_Reasoning (Chunk 1:87-88)"
    quote: "It is based on the SROIQ DL [Horrocks et al., ]. OWL 2 provides rich expressive power"
    description: "SROIQ is the description logic foundation for OWL 2, providing the formal logical basis for the web ontology language standard."

  - name: "OWL 2 Schema Language"
    chunk_ref: "17-KG_Reasoning (Chunk 1:86-92)"
    quote: "the Web Ontology Language OWL 2, which is based on Description Logics (DLs), is a key standard schema language of KGs"
    description: "OWL 2 is identified as the key standard schema language for knowledge graphs, supporting rich expressive power including datatypes and rules for defining class hierarchies and complex relations."

  - name: "TransE Embedding Method"
    chunk_ref: "17-KG_Reasoning (Chunk 1:102)"
    quote: "Many successful KGE methods, such as TransE [Bordes et al., 2013], ComplEx [Trouillon et al., 2016] and RotatE [Sun et al., 2019]"
    description: "TransE is one of the foundational KG embedding methods, using translation-based scoring in Euclidean space where h+r should approximate t for valid triples."

  - name: "ComplEx Embedding Method"
    chunk_ref: "17-KG_Reasoning (Chunk 1:102)"
    quote: "Many successful KGE methods, such as TransE [Bordes et al., 2013], ComplEx [Trouillon et al., 2016] and RotatE [Sun et al., 2019]"
    description: "ComplEx is a KG embedding method using complex vector space to model asymmetric relations, extending beyond real-valued embeddings for richer relational modeling."

  - name: "RotatE Embedding Method"
    chunk_ref: "17-KG_Reasoning (Chunk 1:102)"
    quote: "Many successful KGE methods, such as TransE [Bordes et al., 2013], ComplEx [Trouillon et al., 2016] and RotatE [Sun et al., 2019]"
    description: "RotatE is a KG embedding method defining relations as rotations from head to tail entity in complex vector space, enabling composition modeling."

  - name: "SPARQL Query Language"
    chunk_ref: "17-KG_Reasoning (Chunk 1:361)"
    quote: "Conventional query answering is conducted based on structure query languages such as SPARQL to retrieve and manipulate knowledge in a KG"
    description: "SPARQL is identified as the standard query language for retrieving and manipulating knowledge in knowledge graphs, enabling structured access to graph data."

  - name: "WN18RR Benchmark Dataset"
    chunk_ref: "17-KG_Reasoning (Chunk 1:534)"
    quote: "Commonly used benchmarks for KGEs' evaluation, such as WN18RR, FB15k-237 and NELL"
    description: "WN18RR is one of the commonly used benchmark datasets for evaluating knowledge graph embeddings, derived from WordNet."

  - name: "FB15k-237 Benchmark Dataset"
    chunk_ref: "17-KG_Reasoning (Chunk 1:535)"
    quote: "Commonly used benchmarks for KGEs' evaluation, such as WN18RR, FB15k-237 and NELL"
    description: "FB15k-237 is a standard benchmark dataset for KGE evaluation derived from Freebase, addressing test leakage issues in the original FB15k."

  - name: "NELL Knowledge Base"
    chunk_ref: "17-KG_Reasoning (Chunk 1:535)"
    quote: "Commonly used benchmarks for KGEs' evaluation, such as WN18RR, FB15k-237 and NELL"
    description: "NELL (Never-Ending Language Learning) is referenced as a benchmark knowledge base for evaluating knowledge graph embedding methods."

  - name: "Prolog Logic Programming Language"
    chunk_ref: "17-KG_Reasoning (Chunk 1:419)"
    quote: "Conventional theorem proving methods are based on different logic languages, such as Prolog, Datalog, and OWL"
    description: "Prolog is identified as a foundational logic programming language for theorem proving, serving as the basis for differentiable theorem proving approaches like NTP."

  - name: "Datalog Rule Language"
    chunk_ref: "17-KG_Reasoning (Chunk 1:419)"
    quote: "Conventional theorem proving methods are based on different logic languages, such as Prolog, Datalog, and OWL"
    description: "Datalog is referenced as a standard rule language for logic-based reasoning and theorem proving in knowledge graph systems."

  - name: "TensorLog Differentiable Probabilistic Logic"
    chunk_ref: "17-KG_Reasoning (Chunk 1:470-472)"
    quote: "They are inspired by TensorLog [Cohen et al., 2020], a differentiable probabilistic logic. Tensorlog establishes a connection between inference using first-order rules and sparse matrix multiplication"
    description: "TensorLog is a differentiable probabilistic logic system enabling first-order logical inference through sparse matrix operations, foundational for differentiable rule mining."

  - name: "AMIE Rule Mining System"
    chunk_ref: "17-KG_Reasoning (Chunk 1:444)"
    quote: "Conventional methods like AMIE [Galarraga et al., 2015] and AnyBURL [Meilicke et al., 2019] are symbolic-based"
    description: "AMIE is a standard symbolic rule mining system for knowledge graphs that determines rule structures via random walking and evaluates quality using statistical metrics."

  - name: "AnyBURL Rule Mining System"
    chunk_ref: "17-KG_Reasoning (Chunk 1:444)"
    quote: "Conventional methods like AMIE [Galarraga et al., 2015] and AnyBURL [Meilicke et al., 2019] are symbolic-based"
    description: "AnyBURL is a bottom-up rule learning system for knowledge graph completion, representing anytime symbolic rule mining approaches."

  # Paper 18: Multi-Agent Architecture Taxonomy LLM

  - name: "UML Class Diagram for Domain Ontology"
    chunk_ref: "18-Multi-Agent (Chunk 1:816-818)"
    quote: "Our domain ontology is represented as a conceptual model in terms of a class diagram of the Unified Modeling Language (UML2)"
    description: "UML2 class diagrams are used as the standard notation for representing domain ontology models, organizing concepts as classes with generalizations and associations."

  - name: "LangChain Python Framework"
    chunk_ref: "18-Multi-Agent (Chunk 1:348-352)"
    quote: "Some of these recent multi-agent systems as well as further related projects such as GORILLA or VOYAGER are built upon the LANGCHAIN Python framework"
    description: "LangChain is identified as a foundational Python framework for building multi-agent systems, providing predefined components for agent types, prompt templates, and tool/data integration."

  - name: "Vector Databases for Agent Memory"
    chunk_ref: "18-Multi-Agent (Chunk 2:135-136)"
    quote: "For optimal processing by LLMs, unstructured text is typically stored in vector databases like PINECONE or CHROMA"
    description: "Vector databases (Pinecone, Chroma) are standard tools for storing unstructured text data in multi-agent systems, enabling semantic search through vector embeddings."

  - name: "Hugging Face Model Platform"
    chunk_ref: "18-Multi-Agent (Chunk 2:170-171)"
    quote: "Platforms like HUGGING FACE even offer access to numerous models provided by the global machine learning community"
    description: "Hugging Face is identified as the standard platform for accessing foundation models, providing the global ML community's models for multi-agent system integration."

  - name: "Wolfram Alpha Reasoning Tool"
    chunk_ref: "18-Multi-Agent (Chunk 2:116-117)"
    quote: "For instance, platforms like WOLFRAM ALPHA empower agents with advanced computational skills"
    description: "Wolfram Alpha is referenced as an example reasoning tool that enhances agent computational intelligence capabilities in multi-agent systems."

  - name: "AutoGPT Multi-Agent System"
    chunk_ref: "18-Multi-Agent (Chunk 1:336)"
    quote: "Exemplary but representative autonomous multi-agent systems are AUTOGPT, BABYAGI, SUPERAGI, HUGGINGGPT, CAMEL, AGENTGPT and METAGPT"
    description: "AutoGPT is identified as a representative autonomous multi-agent system providing general-purpose task management with generic agent types and collaboration mechanics."

  - name: "MetaGPT Multi-Agent System"
    chunk_ref: "18-Multi-Agent (Chunk 1:338)"
    quote: "Exemplary but representative autonomous multi-agent systems are AUTOGPT, BABYAGI, SUPERAGI, HUGGINGGPT, CAMEL, AGENTGPT and METAGPT"
    description: "MetaGPT is referenced as a representative multi-agent system designed for software development domain with specialized domain agents and processes."

  - name: "GPT-3 Foundation Model"
    chunk_ref: "18-Multi-Agent (Chunk 1:317)"
    quote: "The advent and widespread use of large language models (LLMs) like GPT-3 have opened up new opportunities for creating increasingly sophisticated and human-like AI systems"
    description: "GPT-3 is referenced as a foundational large language model that enabled the emergence of autonomous multi-agent systems with advanced reasoning capabilities."

  - name: "API-based Resource Access"
    chunk_ref: "18-Multi-Agent (Chunk 2:174-176)"
    quote: "Access to LLMs, as well as associated resources such as tools, foundation models, and external data resources, is typically facilitated through Application Programming Interfaces (APIs)"
    description: "APIs are the standard mechanism for accessing LLMs and contextual resources in multi-agent systems, with access details integrated into the interaction layer."

  # Paper 19: Graph of Thoughts LLM Reasoning

  - name: "GPT Transformer Architecture"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:37-38)"
    quote: "Recent years saw a rapid development of models primarily based on the decoder-only Transformer variant, such as GPT, PaLM, or LLaMA"
    description: "The decoder-only Transformer architecture is identified as the foundation for major LLMs (GPT, PaLM, LLaMA) that enable modern prompting and reasoning frameworks."

  - name: "GPT-4 Language Model"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:95-96)"
    quote: "This enables rapid prototyping of novel prompting ideas using GoT, while experimenting with different models such as GPT-3.5, GPT-4, or Llama-2"
    description: "GPT-4 is supported as one of the LLM backends for the Graph of Thoughts framework, enabling experimentation with different model capabilities."

  - name: "GPT-3.5 Language Model"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:95)"
    quote: "experimenting with different models such as GPT-3.5, GPT-4, or Llama-2"
    description: "GPT-3.5 (ChatGPT) is used as the primary LLM for evaluation in the Graph of Thoughts framework due to cost considerations while maintaining quality."

  - name: "Llama-2 Open Source LLM"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:96)"
    quote: "experimenting with different models such as GPT-3.5, GPT-4, or Llama-2"
    description: "Llama-2 is supported as an open-source LLM option in the GoT framework, though noted to be slower and typically performing worse than GPT-3.5 in experiments."

  - name: "Directed Acyclic Graph Structure"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:69)"
    quote: "Executing algorithms also expose networked patterns, often represented by Directed Acyclic Graphs"
    description: "DAGs are identified as a standard computational structure for representing algorithmic execution patterns, inspiring the graph-based approach to LLM reasoning in GoT."

  - name: "GitHub Repository for GoT"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:31)"
    quote: "Website & code: https://github.com/spcl/graph-of-thoughts"
    description: "The GoT framework is released as open-source on GitHub, providing extensible APIs for implementing different prompting schemes and thought transformations."
