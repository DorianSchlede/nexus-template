---
batch_id: "tools_standards_3"
field: tools_standards
extracted_at: "2025-12-31T00:00:00Z"
chunks_read: 6
patterns_found: 78
---

patterns:
  # ==================== REASONING AND INFERENCE SYSTEMS ====================

  - name: "OWL 2 RL/RDF Rules for Ontological Entailment"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:45-49)"
    quote: "A more comprehensive set of rules for the OWL features of Tables 3-5 have been defined as OWL 2 RL/RDF; these rules are likewise incomplete"
    description: "OWL 2 RL/RDF is a standardized rule-based reasoning profile for OWL that enables practical reasoning over knowledge graphs. It provides rules for sub-class, sub-property, domain, and range features but cannot fully capture negation, existentials, universals, or counting features."

  - name: "Datalog for Rule-Based Reasoning"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:35-36)"
    quote: "Rules of this form correspond to (positive) Datalog [85] in databases, Horn clauses [323] in logic programming, etc."
    description: "Datalog is a foundational rule language used in databases that supports if-then-style inference rules with body and head patterns. Positive Datalog rules encode deductive knowledge and enable automated entailment checking."

  - name: "Datalog Extensions (Datalog+-)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:51-52)"
    quote: "Other rule languages have, however, been proposed to support additional such features, including existentials (see, e.g., Datalog [+-] [36]), disjunction (see, e.g., Disjunctive Datalog [449])"
    description: "Datalog+- and Disjunctive Datalog extend basic Datalog to support existential quantification and disjunction in rule heads, enabling more expressive reasoning capabilities beyond standard Datalog limitations."

  - name: "Horn Clauses in Logic Programming"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:35)"
    quote: "Rules of this form correspond to (positive) Datalog [85] in databases, Horn clauses [323] in logic programming, etc."
    description: "Horn clauses from logic programming provide a formal foundation for inference rules in knowledge graphs, enabling if-then-style deductive reasoning with graph patterns."

  - name: "First Order Logic Theorem Provers"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:10-11)"
    quote: "Though option (3) has been explored using, e.g., theorem provers for First Order Logic [466], options (1) and (2) are more commonly pursued"
    description: "First Order Logic theorem provers can provide complete reasoning but may not halt on certain inputs. They offer an alternative to rules and Description Logics for ontological reasoning."

  - name: "Materialisation for Rule Reasoning"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:54-58)"
    quote: "Materialisation refers to the idea of applying rules recursively to a graph, adding the conclusions generated back to the graph until a fixpoint is reached"
    description: "Materialisation is a reasoning strategy that recursively applies inference rules to a graph, adding derived conclusions until no new facts can be inferred. It is useful for pre-computing entailments for faster query answering."

  - name: "Rete Networks for Materialisation Optimization"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:61-62)"
    quote: "the efficiency and scalability of materialisation can be enhanced through optimisations like Rete networks [164], or using distributed frameworks like MapReduce [531]"
    description: "Rete networks provide an optimization technique for materialisation-based reasoning, improving efficiency and scalability of rule application over knowledge graphs."

  - name: "Query Rewriting for Ontological Reasoning"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:92-95)"
    quote: "Another strategy is to use rules for query rewriting, which given a query, will automatically extend the query in order to find solutions entailed by a set of rules"
    description: "Query rewriting is an alternative to materialisation that extends user queries at runtime to capture ontological entailments, avoiding the need to pre-compute and store all derived facts."

  - name: "OWL 2 QL Profile for Query Rewriting"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:107-109)"
    quote: "The OWL 2 QL profile [363] is a subset of OWL designed specifically for query rewriting of this form [21]."
    description: "OWL 2 QL is a standardized OWL profile optimized for query rewriting, enabling efficient ontological reasoning over large datasets without materialisation."

  - name: "Tableau Methods for DL Satisfiability"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:195-199)"
    quote: "Thereafter methods such as tableau can be used to check satisfiability, cautiously constructing models by completing them along similar lines to the materialisation strategy"
    description: "Tableau methods are decision procedures for Description Logic satisfiability checking, constructing models through completion rules and branching for disjunction."

  # ==================== RULE AND ONTOLOGY LANGUAGES ====================

  - name: "Notation3 (N3) Rule Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:122)"
    quote: "Various languages allow for expressing rules over graphs... including: Notation3 (N3) [42], Rule Interchange Format (RIF) [288]"
    description: "Notation3 (N3) is a language for expressing rules over graphs, enabling declarative specification of if-then inference rules independently or alongside ontology languages."

  - name: "Rule Interchange Format (RIF)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:122)"
    quote: "Various languages allow for expressing rules over graphs... including: Notation3 (N3) [42], Rule Interchange Format (RIF) [288]"
    description: "RIF is a W3C standard for exchanging rules between different rule systems, providing interoperability for rule-based reasoning over knowledge graphs."

  - name: "Semantic Web Rule Language (SWRL)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:123-124)"
    quote: "Semantic Web Rule Language (SWRL) [254], and SPARQL Inferencing Notation (SPIN) [295]."
    description: "SWRL combines OWL with RuleML, providing a rule language that extends OWL's expressivity for knowledge graph reasoning."

  - name: "SPARQL Inferencing Notation (SPIN)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:124)"
    quote: "and SPARQL Inferencing Notation (SPIN) [295]."
    description: "SPIN uses SPARQL CONSTRUCT queries to express inference rules over RDF graphs, combining querying and reasoning capabilities in a single framework."

  - name: "Description Logics (DLs)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:127-134)"
    quote: "Description Logics (DLs) were initially introduced as a way to formalise the meaning of frames [355] and semantic networks [426]... DLs thus hold an important place in the logical formalisation of knowledge graphs"
    description: "Description Logics form a family of logics that provide the formal foundation for OWL, enabling decidable reasoning over knowledge graphs with expressivity/complexity trade-offs."

  - name: "OWL 2 DL Language Fragment"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:179-181)"
    quote: "the OWL 2 DL language is a fragment of OWL restricted so that entailment becomes decidable"
    description: "OWL 2 DL is a restricted OWL fragment ensuring decidable reasoning while maintaining high expressivity, forming the basis for practical knowledge graph ontologies."

  # ==================== GRAPH ANALYTICS FRAMEWORKS ====================

  - name: "Apache Spark GraphX"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:498-499)"
    quote: "Various frameworks have been proposed for large-scale graph analytics, often in a distributed (cluster) setting. Amongst these we can mention Apache Spark (GraphX) [119, 563]"
    description: "Apache Spark GraphX is a distributed graph processing framework supporting large-scale analytics on knowledge graphs using a systolic abstraction for parallel computation."

  - name: "GraphLab"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:499-500)"
    quote: "GraphLab [326], Pregel [335], Signal-Collect [503]"
    description: "GraphLab is a distributed machine learning framework for graph analytics supporting iterative vertex-centric computation on large-scale graphs."

  - name: "Pregel Graph Processing Framework"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:500)"
    quote: "Pregel [335], Signal-Collect [503]"
    description: "Pregel is Google's graph processing framework implementing a Bulk Synchronous Parallel model for distributed graph analytics with message passing between vertices."

  - name: "Signal-Collect Framework"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:500)"
    quote: "Signal-Collect [503]"
    description: "Signal-Collect is a distributed graph processing framework based on signal-collect abstraction where vertices signal neighboring vertices and collect incoming signals."

  - name: "Shark Distributed Analytics"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:500)"
    quote: "Shark [564], etc."
    description: "Shark is a distributed analytics system enabling SQL-like queries over large-scale graph data."

  - name: "MapReduce for Graph Materialisation"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:62)"
    quote: "or using distributed frameworks like MapReduce [531]"
    description: "MapReduce can be used to scale materialisation-based reasoning, distributing rule application across a cluster for large knowledge graphs."

  - name: "Systolic Abstraction for Graph Computing"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:501-504)"
    quote: "These graph parallel frameworks apply a systolic abstraction [304] based on a directed graph, where nodes are processors that can send messages to other nodes along edges"
    description: "The systolic abstraction provides the computational model underlying graph parallel frameworks, with nodes as processors and edges as communication channels for iterative computation."

  - name: "PageRank Algorithm"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:519-522)"
    quote: "A good way to measure this is using centrality, where we choose PageRank [391], which computes the probability of a tourist randomly following the routes shown in the graph being at a particular place"
    description: "PageRank is a graph centrality algorithm computing node importance based on random walk probabilities, applicable for ranking entities in knowledge graphs."

  # ==================== KNOWLEDGE GRAPH EMBEDDINGS ====================

  - name: "TransE Translational Embedding Model"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:12-14)"
    quote: "The most elementary approach in this family is TransE [63]. Over all positive edges [s] p -, TransE learns vectors es, rp, and eo aiming to make es + rp as close as possible to eo"
    description: "TransE is a foundational translational embedding model that interprets edge labels as transformations translating subject entity embeddings to object entity embeddings in vector space."

  - name: "TransH Hyperplane Translation"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:38-42)"
    quote: "TransH [553] represents different relations using distinct hyperplanes, where for the edge [s] p -, [s] is first projected onto the hyperplane of p before the translation to [o] is learnt"
    description: "TransH extends TransE by projecting entities onto relation-specific hyperplanes before translation, handling complex relation patterns better."

  - name: "TransR Relation-Specific Projection"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:42-44)"
    quote: "TransR [318] generalises this approach by projecting [s] and [o] into a vector space specific to p, which involves multiplying the entity embeddings for [s] and [o] by a projection matrix specific to p"
    description: "TransR projects entities into relation-specific vector spaces using learned projection matrices, enabling distinct representations for different relation types."

  - name: "TransD Simplified Projection"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:44-47)"
    quote: "TransD [271] simplifies TransR by associating entities and relations with a second vector, where these secondary vectors are used to project the entity into a relation-specific vector space"
    description: "TransD simplifies TransR by using secondary vectors for projection instead of full matrices, reducing parameters while maintaining expressivity."

  - name: "RotatE Complex Space Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:48-52)"
    quote: "RotatE [511] proposes translational embeddings in complex space, which allows to capture more characteristics of relations, such as direction, symmetry, inversion, antisymmetry, and composition"
    description: "RotatE models relations as rotations in complex vector space, capturing symmetric, antisymmetric, inverse, and compositional relation patterns."

  - name: "MuRP Hyperbolic Space Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:54-58)"
    quote: "MuRP [29] uses relation embeddings that transform entity embeddings in the hyperbolic space of the Poincare ball model, whose curvature provides more 'space' to separate entities"
    description: "MuRP embeds knowledge graphs in hyperbolic space (Poincare ball model), providing better separation for hierarchical structures than Euclidean embeddings."

  - name: "DistMult Tensor Decomposition"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:194-202)"
    quote: "DistMult [568] is a seminal method for computing knowledge graph embeddings based on rank decompositions, where each entity and relation is associated with a vector of dimension d"
    description: "DistMult applies tensor decomposition to knowledge graphs, learning entity and relation vectors that maximize plausibility scores through element-wise vector multiplication."

  - name: "RESCAL Matrix Relation Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:207-211)"
    quote: "RESCAL [386] uses a matrix, which allows for combining values from es and eo across all dimensions, and thus can capture (e.g.) edge direction"
    description: "RESCAL uses matrices rather than vectors for relation embeddings, enabling capture of edge direction and more complex relation patterns."

  - name: "HolE Circular Correlation"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:211-216)"
    quote: "HolE [385] uses vectors for relation and entity embeddings, but proposes to use the circular correlation operator - which takes sums along the diagonals of the outer product of two vectors"
    description: "HolE uses circular correlation to combine entity embeddings, capturing asymmetric relations while maintaining vector-based efficiency."

  - name: "ComplEx Complex Vector Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:216-221)"
    quote: "ComplEx [526], on the other hand, uses a complex vector (i.e., a vector containing complex numbers) as a relational embedding, which similarly allows for breaking the aforementioned symmetry"
    description: "ComplEx uses complex-valued vectors for embeddings, breaking symmetry limitations of real-valued approaches while keeping parameters low."

  - name: "SimplE CP Decomposition"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:222-225)"
    quote: "SimplE [283] rather proposes to compute a standard CP decomposition computing two initial vectors for entities from X and Z and then averaging terms"
    description: "SimplE applies standard Canonical Polyadic (CP) decomposition to knowledge graphs, computing averaged entity vectors from decomposed tensors."

  - name: "TuckER Tucker Decomposition"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:225-237)"
    quote: "TuckER [30] employs a different type of decomposition - called a Tucker Decomposition [528], which computes a smaller 'core' tensor T and a sequence of three matrices A, B and C"
    description: "TuckER applies Tucker decomposition to knowledge graphs, achieving state-of-the-art results on standard benchmarks through a core tensor approach."

  - name: "Canonical Polyadic (CP) Decomposition"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:103)"
    quote: "rank decomposition of tensors; this method is called Canonical Polyadic (CP) decomposition [236]."
    description: "CP decomposition decomposes a tensor into sum of rank-1 tensors, providing a foundational technique for tensor-based knowledge graph embeddings."

  # ==================== NEURAL NETWORK MODELS ====================

  - name: "Semantic Matching Energy (SME)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:248-251)"
    quote: "One of the earliest proposals of a neural model was Semantic Matching Energy (SME) [192], which learns parameters (aka weights: w, w') for two functions"
    description: "SME is an early neural model for knowledge graph embeddings using parameterized functions to compute plausibility scores via dot product."

  - name: "Neural Tensor Networks (NTN)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:251-257)"
    quote: "Neural Tensor Networks (NTN) [488], which rather proposes to maintain a tensor W of internal weights, such that the plausibility score is computed by a complex function"
    description: "NTN uses a weight tensor to compute plausibility scores through outer products of entity embeddings combined with neural layers, though limited in scalability."

  - name: "Multi Layer Perceptron (MLP) for KG"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:257-258)"
    quote: "Multi Layer Perceptron (MLP) [131] is a simpler model, where es, rp and eo are concatenated and fed into a hidden layer to compute the plausibility score."
    description: "MLP-based embedding models concatenate entity and relation vectors and pass through hidden layers for plausibility scoring, offering simpler architecture than NTN."

  - name: "ConvE Convolutional Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:260-268)"
    quote: "ConvE [127] proposes to generate a matrix from es and rp by 'wrapping' each vector over several rows and concatenating both matrices. The concatenated matrix serves as the input for a set of (2D) convolutional layers"
    description: "ConvE applies 2D convolutional layers to wrapped and concatenated entity/relation embeddings, generating feature maps for plausibility scoring."

  - name: "HypER Convolutional Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:272-280)"
    quote: "HypER [28] is a similar model using convolutions, but avoids the need to wrap vectors into matrices. Instead, a fully connected layer (called the 'hypernetwork') is applied to rp"
    description: "HypER uses a hypernetwork to generate relation-specific convolutional filters applied directly to entity embeddings, outperforming ConvE on benchmarks."

  - name: "Graph Neural Networks (GNNs)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:427-429)"
    quote: "A graph neural network (GNN) [462] builds a neural network based on the topology of the data graph; i.e., nodes are connected to their neighbours per the data graph"
    description: "GNNs build neural network architectures reflecting knowledge graph topology, enabling end-to-end supervised learning for node classification and graph-level tasks."

  - name: "Recursive Graph Neural Networks (RecGNNs)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:452-455)"
    quote: "Recursive graph neural networks (RecGNNs) are the seminal approach to graph neural networks [462, 493]. The approach is conceptually similar to the systolic abstraction"
    description: "RecGNNs recursively pass messages between neighboring nodes until fixpoint, learning transition and output functions from supervised node labels."

  - name: "Convolutional Graph Neural Networks (ConvGNNs)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:613-615)"
    quote: "a number of convolutional graph neural networks (ConvGNNs) [71, 289, 559] have been proposed, where the transition function is implemented by means of convolutions"
    description: "ConvGNNs apply convolutional operations over graph neighborhoods, with spectral or spatial representations addressing irregular neighborhood structures."

  - name: "Attention Mechanism for GNNs"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:631-633)"
    quote: "An alternative is to use an attention mechanism [535] to learn the nodes whose features are most important to the current node."
    description: "Attention mechanisms enable GNNs to learn which neighboring nodes are most relevant, addressing varying neighborhood sizes and structures."

  # ==================== LANGUAGE EMBEDDING MODELS ====================

  - name: "word2vec Language Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:296-301)"
    quote: "word2vec [352] and GloVe [408] being two seminal approaches. Both approaches compute embeddings for words based on large corpora of text such that words used in similar contexts have similar vectors"
    description: "word2vec computes word embeddings using neural networks (continuous bag of words or skip-gram), foundational for language-based graph embedding approaches."

  - name: "GloVe Word Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:306-308)"
    quote: "GloVe rather applies a regression model over a matrix of co-occurrence probabilities of word pairs."
    description: "GloVe computes word embeddings via regression on word co-occurrence matrices, providing an alternative to neural approaches for embedding generation."

  - name: "RDF2Vec Graph-to-Language Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:316-328)"
    quote: "RDF2Vec [441] performs (biased [95]) random walks on the graph and records the paths (the sequence of nodes and edge labels traversed) as 'sentences', which are then fed as input into the word2vec model"
    description: "RDF2Vec generates sentences from random walks on knowledge graphs and applies word2vec, enabling transfer of language embedding techniques to graphs."

  - name: "KGloVe PageRank-Based Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:332-338)"
    quote: "KGloVe [96] is based on the GloVe model. Much like how the original GloVe model considers words that co-occur frequently in windows of text to be more related, KGloVe uses personalised PageRank"
    description: "KGloVe adapts GloVe for knowledge graphs using personalized PageRank to determine node relatedness instead of text co-occurrence."

  # ==================== RULE AND AXIOM MINING ====================

  - name: "AMIE Rule Mining System"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:773-775)"
    quote: "An influential rule-mining system for graphs is AMIE [169, 170], which adopts the PCA measure of confidence, and builds rules in a top-down fashion"
    description: "AMIE is an influential rule mining system that discovers high-confidence rules from knowledge graphs using Partial Completeness Assumption and top-down rule refinement."

  - name: "AMIE+ Optimized Rule Mining"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:827)"
    quote: "For further discussion of possible optimisations based on pruning and indexing, we refer to the paper on AMIE+ [169]."
    description: "AMIE+ provides optimizations over AMIE for more efficient rule mining through improved pruning and indexing strategies."

  - name: "RuLES Non-Monotonic Rule Learning"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:845-848)"
    quote: "The RuLES system [241] - which is also capable of learning non-monotonic rules - proposes to mitigate the limitations of the PCA heuristic by extending the confidence measure"
    description: "RuLES learns non-monotonic rules and extends confidence measures using knowledge graph embedding plausibility scores for edges not in the graph."

  - name: "CARL Cardinality-Aware Rule Learning"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:855-858)"
    quote: "CARL [406] exploits additional knowledge about the cardinalities of relations to refine the set of negative examples and the confidence measure for candidate rules."
    description: "CARL enhances rule mining by incorporating relation cardinality constraints to better identify negative examples and compute rule confidence."

  - name: "NeuralLP Differentiable Rule Mining"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:896-899)"
    quote: "NeuralLP [569] uses an attention mechanism to select a variable-length sequence of edge labels for path-like rules of the form [?x] p1 ?y1 p2 ... pn ?yn pn+1 ?z => [?x] p ?z"
    description: "NeuralLP applies differentiable rule mining using attention mechanisms to learn path-like rules with variable-length edge label sequences and confidence scores."

  - name: "DRUM Recurrent Neural Rule Mining"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:901-908)"
    quote: "DRUM [455] also learns path-like rules, where... the system uses bidirectional recurrent neural networks (a popular technique for learning over sequential data) to learn sequences of relations for rules"
    description: "DRUM uses bidirectional RNNs for differentiable rule mining, learning relation sequences that form path-like rules."

  - name: "DL-Learner Axiom Mining"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:59-61)"
    quote: "A prominent such system is DL-Learner [73], which is based on algorithms for class learning (aka concept learning), whereby given a set of positive nodes and negative nodes"
    description: "DL-Learner mines Description Logic axioms through class learning, finding logical class descriptions that separate positive from negative node examples."

  - name: "T-Norm Fuzzy Logics for Embeddings"
    chunk_ref: "02-Knowledge_Graphs (Chunk 5:357-366)"
    quote: "KALE [207] computes entity and relation embeddings using a translational model (specifically TransE) that is adapted to further consider rules using t-norm fuzzy logics"
    description: "T-norm fuzzy logics provide a mechanism to integrate rules with embeddings, computing updated plausibility scores based on rule application."

  # ==================== NLP AND INFORMATION EXTRACTION ====================

  - name: "Named Entity Recognition (NER)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:205-209)"
    quote: "The NER task identifies mentions of named entities in a text [369, 434], typically targetting mentions of people, organisations, locations, and potentially other types"
    description: "NER identifies named entities in text for knowledge graph construction, using lexical features, gazetteers, and supervised/bootstrapping approaches."

  - name: "Entity Linking (EL)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:233-238)"
    quote: "The EL task associates mentions of entities in a text with the existing nodes of a target knowledge graph, which may be the nucleus of a knowledge graph under creation"
    description: "Entity Linking connects text mentions to knowledge graph nodes, handling mention ambiguity and entity aliases through disambiguation."

  - name: "Relation Extraction (RE)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:274-277)"
    quote: "The RE task extracts relations between entities in the text [24, 582]. The simplest case is that of extracting binary relations in a closed setting wherein a fixed set of relation types are considered"
    description: "Relation Extraction identifies relations between entities in text for knowledge graph enrichment, supporting binary, n-ary, and open information extraction."

  - name: "Open Information Extraction (OIE)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:292-296)"
    quote: "Binary RE can also be applied using unsupervised methods in an open setting - often referred to as Open Information Extraction (OIE) [31, 149, 150, 341, 342, 357]"
    description: "OIE extracts relations without predefined relation types, deriving relations from dependency parse trees and requiring subsequent alignment with knowledge graph vocabularies."

  - name: "Frame Semantics for N-ary RE"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:306-314)"
    quote: "Various methods for n-ary RE are based on frame semantics [159], which, for a given verb... captures the entities involved and how they may be interrelated"
    description: "Frame semantics (FrameNet) provides semantic frames for verbs enabling n-ary relation extraction with contextual elements like time, place, and purpose."

  - name: "FrameNet Semantic Frames"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:309-314)"
    quote: "Resources such as FrameNet [26] then define frames for words, such as to identify that the semantic frame for 'named' includes a speaker (the person naming something), an entity (the thing named) and a name"
    description: "FrameNet defines semantic frames associating verbs with participant roles and optional context elements for n-ary relation extraction."

  - name: "Discourse Representation Theory (DRT)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:316-324)"
    quote: "Other RE methods are rather based on Discourse Representation Theory (DRT) [278], which considers a logical representation of text based on existential events"
    description: "DRT provides logical text representation based on existential events, supporting neo-Davidsonian formulas analogous to reification for n-ary relations."

  - name: "WordNet Lexical Database"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:197-198)"
    quote: "linking words with a lexicon of senses (e.g., WordNet [353] or BabelNet [373])"
    description: "WordNet provides a lexical database of word senses used for Word Sense Disambiguation in knowledge graph construction from text."

  - name: "BabelNet Multilingual Knowledge Graph"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:198)"
    quote: "(e.g., WordNet [353] or BabelNet [373])"
    description: "BabelNet combines WordNet and Wikipedia for multilingual lexical knowledge, supporting word sense disambiguation and entity linking."

  # ==================== MAPPING AND ETL TOOLS ====================

  - name: "R2RML RDB-to-RDF Mapping Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:649-654)"
    quote: "A standard language along these lines is the RDB2RDF Mapping Language (R2RML) [118], which allows for mapping from individual rows of a table to one or more custom edges"
    description: "R2RML is a W3C standard for declarative mapping from relational databases to RDF graphs, supporting custom mappings with templates and SQL queries."

  - name: "Direct Mapping for Tables to RDF"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:597-599)"
    quote: "A direct mapping automatically generates a graph from a table. We present in Figure 34 the result of a standard direct mapping [20]"
    description: "W3C Direct Mapping automatically converts relational tables to RDF graphs, creating edges from rows with table-encoded node identifiers."

  - name: "CSV/Tabular Data Mapping to RDF"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:625-629)"
    quote: "Another direct mapping has been defined for CSV and other tabular data [516] that further allows for specifying column names, primary/foreign keys, and datatypes"
    description: "W3C standards extend direct mapping for CSV and tabular data, allowing specification of metadata like keys and datatypes as part of the mapping."

  - name: "GRDDL XML-to-RDF Mapping"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:710-711)"
    quote: "the GRDDL standard [99] allows for mapping from XML to (RDF) graphs"
    description: "GRDDL is a W3C standard for extracting RDF graphs from XML documents using transformations."

  - name: "JSON-LD JSON-to-RDF Mapping"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:711-712)"
    quote: "the JSON-LD standard [494] allows for mapping from JSON to (RDF) graphs"
    description: "JSON-LD is a W3C standard for embedding RDF in JSON, enabling JSON data to be interpreted as linked data graphs."

  - name: "XSPARQL Hybrid Query Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:713-716)"
    quote: "hybrid query languages such as XSPARQL [47] allow for querying XML and RDF in an integrated fashion, thus supporting both materialisation and virtualisation"
    description: "XSPARQL integrates XQuery and SPARQL for querying XML and RDF together, supporting both materialisation and virtualisation approaches."

  - name: "Ontology-Based Data Access (OBDA)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:689-695)"
    quote: "The area of Ontology-Based Data Access (OBDA) [561] is then concerned with QR approaches that support ontological entailments"
    description: "OBDA provides query rewriting approaches that translate graph queries to SQL while supporting ontological entailments, including recursive entailments."

  - name: "Extract-Transform-Load (ETL)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 6:673-677)"
    quote: "Once the mappings have been defined, one option is to use them to materialise graph data following an Extract-Transform-Load (ETL) approach"
    description: "ETL processes materialise knowledge graphs by transforming and loading source data according to defined mappings."

  # ==================== QUALITY AND VALIDATION ====================

  - name: "Shape Expressions for Validation"
    chunk_ref: "02-Knowledge_Graphs (Chunk 7:179-181)"
    quote: "Validity means that the knowledge graph is free of constraint violations, such as captured by shape expressions [521] (see Section 3.1.2)"
    description: "Shape expressions provide constraint languages for validating knowledge graphs, defining expected patterns and cardinalities for node types."

  - name: "FAIR Principles for Data Publication"
    chunk_ref: "02-Knowledge_Graphs (Chunk 7:621-629)"
    quote: "The FAIR Principles were originally proposed in the context of publishing scientific data [556]... FAIR itself is an acronym for four foundational principles"
    description: "FAIR (Findable, Accessible, Interoperable, Reusable) provides principles for publishing knowledge graphs to maximize re-use and machine-readability."

  - name: "Linked Data Principles"
    chunk_ref: "02-Knowledge_Graphs (Chunk 7:731-738)"
    quote: "the Linked Data Principles, proposed by Berners-Lee [41], which provide a technical basis for one possible way in which these FAIR Principles can be achieved"
    description: "Linked Data Principles (use IRIs, HTTP lookups, standard formats, include links) provide technical implementation for FAIR publishing of knowledge graphs."

  - name: "Vocabulary of Interlinked Datasets (VoID)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 7:703-705)"
    quote: "resources such as the Vocabulary of Interlinked Datasets (VoID) [11] allow for representing meta-data about graphs"
    description: "VoID provides vocabulary for describing dataset metadata, supporting Findability principle of FAIR through structured dataset descriptions."

  - name: "PROV Data Model for Provenance"
    chunk_ref: "02-Knowledge_Graphs (Chunk 7:715-716)"
    quote: "the PROV Data Model [188] discussed in Section 3 allows for capturing detailed provenance"
    description: "PROV-DM (W3C standard) enables capturing detailed provenance information for knowledge graphs, supporting Reusability principle of FAIR."

  # ==================== ACCESS PROTOCOLS ====================

  - name: "SPARQL Query Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:128-129)"
    quote: "public services offering such a protocol (most often supporting SPARQL queries [217]) have been found to often exhibit downtimes, timeouts"
    description: "SPARQL is the W3C standard query language for RDF graphs, supporting complex graph patterns with joins, unions, and optional patterns."

  - name: "Cypher Query Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:686-688)"
    quote: "Query languages such as SPARQL [217], Cypher [165], and G-CORE [15] allow for outputting graphs, where such queries can be used to select sub-graphs for analysis"
    description: "Cypher is the declarative query language for property graphs (Neo4j), supporting graph pattern matching and shortest path finding."

  - name: "G-CORE Graph Query Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:687)"
    quote: "Query languages such as SPARQL [217], Cypher [165], and G-CORE [15]"
    description: "G-CORE is a property graph query language supporting graph construction, composable queries, and paths as first-class citizens."

  - name: "Gremlin Traversal Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 4:718)"
    quote: "While one could solve this task using an imperative language such as Gremlin [445], GraphX [563], or R [518]"
    description: "Gremlin is an imperative graph traversal language enabling programmatic navigation and manipulation of property graphs."

  - name: "Triple Pattern Fragments"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:65-70)"
    quote: "Edge patterns - also known as triple patterns in the case of directed, edge-labelled graphs - are singleton graph patterns, i.e., graph patterns with a single edge"
    description: "Triple Pattern Fragments provide a lightweight access protocol returning solutions for single edge patterns, enabling client-side query processing."

  - name: "HTTP Dereferencing for Linked Data"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:30-34)"
    quote: "Such a protocol is the basis for the Linked Data principles outlined previously, where node lookups are implemented through HTTP dereferencing"
    description: "HTTP dereferencing enables node lookups in Linked Data by returning RDF descriptions when HTTP IRIs are accessed."

  # ==================== LICENSING AND USAGE CONTROL ====================

  - name: "ODRL Rights Language"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:188-192)"
    quote: "the W3C Open Digital Rights Language (ODRL) [261] provides an information model and related vocabularies that can be used to specify permissions, duties, and prohibitions"
    description: "ODRL is a W3C standard for expressing digital rights as graphs, supporting machine-readable licenses with permissions, duties, and prohibitions."

  - name: "WebAccessControl (WAC)"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:217-218)"
    quote: "WebAccessControl (WAC) [31] is an access control framework for graphs that uses WebID for authentication"
    description: "WAC provides access control for graphs using WebID authentication and vocabulary for specifying access policies."

  - name: "DALICC License Clearance"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:210-214)"
    quote: "the Data Licenses Clearance Center (DALICC), which includes a library of standard machine readable licenses, and tools that enable users both to compose arbitrary custom licenses and also to verify the compatibility"
    description: "DALICC provides tools for license composition and compatibility verification, supporting Apache, Creative Commons, and BSD license families."

  - name: "CryptOntology for Encryption Metadata"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:282-286)"
    quote: "The CryptOntology [182] can further be used to embed details about the encryption mechanism used within the knowledge graph"
    description: "CryptOntology provides vocabulary for embedding encryption metadata (algorithm, key-length) within knowledge graphs for fine-grained access control."

  # ==================== ANONYMISATION TECHNIQUES ====================

  - name: "K-Anonymity for Graphs"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:324-328)"
    quote: "Approaches to apply k-anonymity on graphs identify and suppress 'quasi-identifiers' that would allow a given individual to be distinguished from fewer than k-1 other individuals"
    description: "K-anonymity suppresses quasi-identifiers in graphs to ensure individuals cannot be distinguished from k-1 others, protecting privacy."

  - name: "K-Degree Anonymity"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:354-358)"
    quote: "k-degree anonymity [321], which ensures that individuals cannot be deanonymised by attackers with knowledge of the degree of particular individuals"
    description: "K-degree anonymity modifies graphs so each node has at least k-1 other nodes with the same degree, preventing degree-based deanonymisation."

  - name: "K-Isomorphic Neighbour Anonymity"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:360-367)"
    quote: "k-isomorphic neighbour anonymity [580], avoids neighbourhood attacks where an attacker knows how an individual is connected to nodes in their neighbourhood"
    description: "K-isomorphic neighbour anonymity ensures each node has k-1 other nodes with isomorphic neighborhoods, preventing neighborhood-based attacks."

  - name: "K-Automorphism for Graph Anonymity"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:370-374)"
    quote: "k-automorphism [584], which ensures that for every node, it is structurally indistinguishable from k-1 other nodes, thus avoiding any attack based on structural information"
    description: "K-automorphism provides strongest structural anonymity guarantee, making every node structurally indistinguishable from k-1 others."

  - name: "Differential Privacy for Graph Queries"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:395-400)"
    quote: "One approach is to apply epsilon-differential privacy [137] for querying graphs [483]. Such mechanisms are typically used for aggregate (e.g., count) queries, where noise is added"
    description: "Epsilon-differential privacy adds noise to query results to prevent individual identification, controlling privacy-utility tradeoff via epsilon parameter."

  # ==================== OPEN KNOWLEDGE GRAPHS ====================

  - name: "DBpedia Knowledge Graph"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:458-476)"
    quote: "The DBpedia project was developed to extract a graph-structured representation of the semi-structured data embedded in Wikipedia articles [22]"
    description: "DBpedia extracts structured knowledge from Wikipedia infoboxes and categories, providing multilingual RDF data with links to external datasets."

  - name: "YAGO Knowledge Graph"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:505-529)"
    quote: "YAGO likewise extracts graph-structured data from Wikipedia, which are then unified with the hierarchical structure of WordNet"
    description: "YAGO combines Wikipedia extraction with WordNet hierarchies, supporting reification, n-ary relations, and data types in its RDFS-based model."

  - name: "Freebase Knowledge Graph"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:544-570)"
    quote: "Freebase was a general collection of human knowledge that aimed to address some of the large scale information integration problems"
    description: "Freebase used Metaweb Query Language (MQL) and collaborative editing with a lightweight typing system, later migrated to Wikidata."

  - name: "Wikidata Knowledge Graph"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:579-621)"
    quote: "The Wikimedia Foundation thus uses Wikidata as a centralised, collaboratively edited knowledge graph to supply Wikipedia"
    description: "Wikidata provides multilingual, collaboratively-edited knowledge with claims and references, using language-agnostic Qxx/Pxx identifiers."

  - name: "SKOS Knowledge Organization"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:493-495)"
    quote: "These schemata include a Simple Knowledge Organization System (SKOS) representation of Wikipedia categories"
    description: "SKOS provides vocabulary for representing knowledge organization systems like taxonomies and thesauri within knowledge graphs."

  - name: "UMBEL Ontology Categorisation"
    chunk_ref: "02-Knowledge_Graphs (Chunk 8:496-497)"
    quote: "an Upper Mapping and Binding Exchange Layer (UMBEL) ontology categorisation schema"
    description: "UMBEL provides upper-level ontology categories for classifying entities in knowledge graphs like DBpedia."
