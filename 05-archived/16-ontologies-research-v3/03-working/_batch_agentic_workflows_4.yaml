---
batch_id: "agentic_workflows_4"
field: agentic_workflows
extracted_at: "2025-12-31T00:00:00Z"
chunks_read: 9
patterns_found: 32
---

patterns:
  # Paper 19 - Graph of Thoughts: LLM Reasoning

  - name: "Graph of Thoughts (GoT) Framework"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:17-28)"
    quote: "Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts"
    description: "GoT is a meta-prompting framework that models LLM reasoning as an arbitrary graph structure where thoughts are vertices and dependencies are edges. This enables combining arbitrary LLM thoughts into synergistic outcomes, distilling whole networks of thoughts, or enhancing thoughts using feedback loops. Unlike linear CoT or tree-based ToT, GoT allows for complex networked reasoning patterns that mirror human cognition and brain mechanisms like recurrence."

  - name: "Graph-Enabled Thought Transformations"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:70-82)"
    quote: "graph-enabled transformations bring a promise of more powerful prompting when applied to LLM thoughts, but they are not naturally expressible with CoT or ToT"
    description: "GoT enables novel thought transformations through its graph model including aggregation (merging multiple thoughts), generation (spawning new thoughts from existing ones), and refining (iterative improvement loops). These transformations extend beyond what is possible with chain or tree structures, allowing thoughts to have multiple incoming edges for aggregation and self-loops for refinement."

  - name: "GoT Modular Architecture with Controller"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:383-396)"
    quote: "The GoT architecture consists of a set of interacting modules: the Prompter, the Parser, the Scoring module, and the Controller which coordinates the entire reasoning process"
    description: "GoT implements a modular system architecture with four key components: Prompter (prepares LLM messages), Parser (extracts information from thoughts), Scoring (verifies and scores thoughts), and Controller (coordinates the process). The Controller contains Graph of Operations (GoO) as a static execution plan and Graph Reasoning State (GRS) as dynamic state tracking. This enables systematic orchestration of complex multi-agent-like reasoning workflows."

  - name: "Graph of Operations (GoO) Execution Plan"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:390-396)"
    quote: "GoO is a static structure that specifies the graph decomposition of a given task, prescribes transformations to be applied to LLM thoughts, together with their order and dependencies"
    description: "GoO serves as a declarative workflow specification that defines how a complex task should be decomposed into graph operations. It prescribes which thought transformations (Generate, Aggregate, Score, KeepBest, Improve) to apply and in what order, enabling reproducible and systematic orchestration of multi-step reasoning processes."

  - name: "Task Decomposition via Merge-Sort Pattern"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:471-479)"
    quote: "In GoT, we employ merge-based sorting: First, one decomposes the input sequence into subarrays. Then, one sorts these subarrays individually, and then respectively merges them into a final solution"
    description: "GoT applies algorithmic decomposition patterns to LLM tasks. The sorting use case demonstrates decomposing a complex problem into parallel subtasks (sorting sub-arrays), solving them independently, then aggregating results (merging). This divide-and-conquer approach enables LLMs to handle larger problems by working on manageable chunks and combining partial solutions."

  - name: "Aggregation Transformation for Thought Synthesis"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:344-352)"
    quote: "with GoT, one can aggregate arbitrary thoughts into new ones, to combine and reinforce the advantages of these thoughts, while eliminating their disadvantages"
    description: "Aggregation is a key graph-enabled transformation that allows merging multiple independent reasoning chains into a single synthesized thought. This enables combining the best aspects of different reasoning paths, aggregating partial solutions into complete ones, and leveraging diverse perspectives to produce superior outcomes that no single chain could achieve alone."

  - name: "Refining Transformation with Self-Loops"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:355-357)"
    quote: "Another thought transformation is the refining of a current thought v by modifying its content: V+ = {} and E+ = {(v, v)}. This loop in the graph indicates an iterated thought"
    description: "The refining transformation enables iterative improvement of a thought through self-referential loops in the graph structure. A thought can reference itself as input, allowing for progressive enhancement cycles. This pattern supports self-critique and iterative refinement workflows where an LLM can repeatedly improve its own output based on evaluation feedback."

  - name: "Volume Metric for Thought Information Scope"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:729-740)"
    quote: "For a given thought t, the volume of t is the number of preceding LLM thoughts that could have impacted t. Formally, the volume of t is the number of thoughts from which there exists a path to t"
    description: "GoT introduces a novel metric called 'volume' to measure the information scope accessible to any given thought. Unlike CoT (linear volume) or ToT (logarithmic volume), GoT achieves maximum volume N with logarithmic latency, meaning final thoughts can draw from all preceding thoughts in the reasoning graph. This quantifies the reasoning capacity advantage of graph-based over linear approaches."

  - name: "Latency-Volume Tradeoff Optimization"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 1:756-767)"
    quote: "GoT is the only scheme to come with both a low latency of log_k N and a high volume N. This is enabled by the fact that GoT harnesses aggregations of thoughts"
    description: "GoT optimizes the fundamental tradeoff between reasoning latency (number of steps to reach a conclusion) and volume (scope of information considered). Through aggregation, GoT achieves both logarithmic latency and maximum volume, outperforming CoT (high latency, high volume), CoT-SC (medium both), and ToT (low latency, low volume). This represents a Pareto improvement in reasoning efficiency."

  - name: "Generate-Score-KeepBest Selection Pattern"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 3:566-575)"
    quote: "For each sub-list: Sort the sub-list (sort prompt) five times; score each sort attempt; keep the best"
    description: "GoT implements a generate-evaluate-select pattern where multiple candidate solutions are generated in parallel, each is scored against a quality metric, and only the best performing candidates are retained for subsequent operations. This pattern enables robust solution selection through competition and eliminates low-quality intermediate results before they propagate through the reasoning graph."

  - name: "Self-Evaluation for Thought Scoring"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 2:528-538)"
    quote: "Self-reflection and self-evaluation were introduced recently. They are used to enhance different tasks. In GoT, we partially rely on self-evaluation when taking decisions on how to expand the graph of thoughts"
    description: "GoT incorporates self-evaluation mechanisms where the LLM assesses its own outputs to guide graph expansion decisions. This enables autonomous quality control within the reasoning workflow, allowing the system to identify and prioritize promising reasoning paths while pruning less valuable branches. Self-evaluation supports adaptive, feedback-driven reasoning orchestration."

  - name: "LLM-Based Planning for Complex Tasks"
    chunk_ref: "19-Graph_of_Thoughts (Chunk 2:541-547)"
    quote: "There are many works recently on how to plan complex tasks with LLMs. GoT could be seen as a generic framework that could potentially be used to enhance such schemes, by offering a paradigm for generating complex graph-based plans"
    description: "GoT provides a foundation for LLM-based task planning by enabling complex graph-structured execution plans. Rather than simple linear or tree-based plans, GoT allows for plans with merging paths, feedback loops, and parallel execution branches. This supports more sophisticated planning that can adapt to discovered information and combine insights from multiple exploration paths."

  # Paper 20 - Agentic RAG Survey

  - name: "Agentic RAG Paradigm"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:55-61)"
    quote: "Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns - reflection, planning, tool use, and multi-agent collaboration"
    description: "Agentic RAG represents a paradigm shift in RAG systems by integrating autonomous AI agents that can dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows. Unlike static RAG, agents apply design patterns including reflection (self-critique), planning (task decomposition), tool use (external APIs), and multi-agent collaboration to handle complex, multi-step reasoning."

  - name: "Four Core Agentic Design Patterns"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:106-107)"
    quote: "These agents leverage agentic patterns, such as reflection, planning, tool use, and multi-agent collaboration, to enhance decision-making and adaptability"
    description: "Agentic systems are built on four foundational design patterns: (1) Reflection - iterative self-evaluation and refinement, (2) Planning - autonomous task decomposition into manageable subtasks, (3) Tool Use - integration with external APIs, databases, and computational resources, and (4) Multi-Agent Collaboration - distributing tasks among specialized agents. These patterns enable dynamic, adaptive workflow orchestration."

  - name: "Agentic Workflow Patterns for Task Orchestration"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:110-113)"
    quote: "these agents employ agentic workflow patterns, such as prompt chaining, routing, parallelization, orchestrator-worker models, and evaluator-optimizer, to structure and optimize task execution"
    description: "Beyond design patterns, agentic systems employ workflow patterns to structure execution: prompt chaining (sequential subtask processing), routing (directing inputs to specialized handlers), parallelization (concurrent execution), orchestrator-worker (dynamic task delegation), and evaluator-optimizer (iterative refinement). These patterns enable efficient management of complex, multi-domain reasoning tasks."

  - name: "Reflection Pattern for Iterative Refinement"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:515-530)"
    quote: "Reflection is a foundational design pattern in agentic workflows, enabling agents to iteratively evaluate and refine their outputs. By incorporating self-feedback mechanisms, agents can identify and address errors"
    description: "The Reflection pattern enables agents to critique their own outputs for correctness, style, and efficiency, then incorporate this feedback into subsequent iterations. It can involve prompting agents to self-evaluate, using external validation tools (unit tests, web searches), or distributing critique across multiple agents. Studies like Self-Refine, Reflexion, and CRITIC demonstrate significant performance improvements from reflection."

  - name: "Planning Pattern for Task Decomposition"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:540-549)"
    quote: "Planning is a key design pattern in agentic workflows that enables agents to autonomously decompose complex tasks into smaller, manageable subtasks. This capability is essential for multi-hop reasoning"
    description: "The Planning pattern allows agents to dynamically determine the sequence of steps needed to accomplish a larger objective without predefined workflows. Agents break down complex tasks into subtasks, enabling flexible decision-making in dynamic and uncertain scenarios. While powerful, planning can produce less predictable outcomes compared to deterministic reflection-based workflows."

  - name: "Tool Use Pattern for External Integration"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:555-564)"
    quote: "Tool Use enables agents to extend their capabilities by interacting with external tools, APIs, or computational resources. This pattern allows agents to gather information, perform computations, and manipulate data beyond their pre-trained knowledge"
    description: "The Tool Use pattern extends agent capabilities through integration with external resources including APIs, databases, web search, and computational tools. Modern implementations like GPT-4's function calling enable agents to autonomously select and execute appropriate tools for given tasks. Key challenges include optimizing tool selection when many options are available, often addressed using RAG-inspired heuristic selection."

  - name: "Multi-Agent Collaboration Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:575-592)"
    quote: "Multi-agent collaboration is a key design pattern that enables task specialization and parallel processing. Agents communicate and share intermediate results, ensuring the overall workflow remains efficient"
    description: "The Multi-Agent pattern distributes complex tasks among specialized agents that communicate and share intermediate results. Each agent operates with its own memory and workflow (potentially including tools, reflection, or planning). This enables decomposing intricate tasks into smaller subtasks assigned to different agents, improving scalability and adaptability. Frameworks like AutoGen, Crew AI, and LangGraph support multi-agent implementations."

  - name: "Prompt Chaining Workflow Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:620-632)"
    quote: "Prompt chaining decomposes a complex task into multiple steps, where each step builds upon the previous one. This structured approach improves accuracy by simplifying each subtask before moving forward"
    description: "Prompt chaining structures LLM tasks as sequential processing pipelines where each step receives output from the previous step as input. This pattern is effective when tasks can be broken into fixed subtasks, such as generating content then translating it, or creating an outline then verifying then expanding. While it improves accuracy through decomposition, it may increase latency due to sequential processing."

  - name: "Routing Workflow Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:647-655)"
    quote: "Routing involves classifying an input and directing it to an appropriate specialized prompt or process. This method ensures distinct queries or tasks are handled separately"
    description: "The Routing pattern classifies incoming inputs and directs them to specialized processing pathways optimized for each category. Examples include directing customer queries to appropriate departments (technical support, refunds, general inquiries) or assigning simple queries to smaller models while complex requests go to advanced models. This optimizes efficiency by matching task complexity to appropriate resources."

  - name: "Parallelization Workflow Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:674-685)"
    quote: "Parallelization divides a task into independent processes that run simultaneously, reducing latency and improving throughput. It can be categorized into sectioning (independent subtasks) and voting (multiple outputs)"
    description: "Parallelization splits tasks into concurrent independent processes to reduce latency. Two sub-patterns exist: sectioning (different models handle different aspects, e.g., one screens input while another generates response) and voting (multiple models produce outputs for cross-validation, improving confidence through consensus). This pattern is applicable when subtasks are independent and can benefit from simultaneous execution."

  - name: "Orchestrator-Worker Workflow Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:699-709)"
    quote: "This workflow features a central orchestrator model that dynamically breaks tasks into subtasks, assigns them to specialized worker models, and compiles the results. Unlike parallelization, it adapts to varying input complexity"
    description: "The Orchestrator-Worker pattern features a central orchestrating agent that dynamically decomposes tasks based on the specific input, assigns subtasks to specialized worker agents, and synthesizes their results. Unlike static parallelization, it adapts the decomposition to each input's complexity. Applications include automatically modifying codebases based on change requests or conducting multi-source real-time research."

  - name: "Evaluator-Optimizer Workflow Pattern"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:724-740)"
    quote: "The evaluator-optimizer workflow iteratively improves content by generating an initial output and refining it based on feedback from an evaluation model"
    description: "The Evaluator-Optimizer pattern creates a feedback loop where an initial output is generated, then evaluated against quality criteria, and refined based on evaluation feedback. This iterative cycle continues until quality thresholds are met. Effective when clear evaluation criteria exist, such as improving literary translations through multiple cycles or refining research queries through successive iterations."

  - name: "Single-Agent Router Architecture"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:755-798)"
    quote: "A Single-Agent Agentic RAG serves as a centralized decision-making system where a single agent manages the retrieval, routing, and integration of information"
    description: "Single-Agent RAG consolidates all retrieval, routing, and integration tasks into one unified agent. The workflow involves: query submission and evaluation, knowledge source selection (structured databases, semantic search, web search, recommendation systems), data integration and LLM synthesis, and output generation. Suitable for systems with limited tools or well-defined tasks, offering centralized simplicity and dynamic routing capabilities."

  - name: "Multi-Agent RAG Architecture"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 1:877-920)"
    quote: "Multi-Agent RAG represents a modular and scalable evolution of single-agent architectures, designed to handle complex workflows by leveraging multiple specialized agents"
    description: "Multi-Agent RAG distributes retrieval and reasoning across specialized agents, each optimized for specific data sources or task types. A coordinator agent delegates queries to specialized agents (SQL databases, semantic search, web search, recommendations), which retrieve in parallel. Results are integrated by an LLM for synthesis. This provides modularity, scalability, task specialization, and versatility for multi-domain applications."

  - name: "Hierarchical Agentic RAG Architecture"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:100-131)"
    quote: "Hierarchical Agentic RAG systems employ a structured, multi-tiered approach to information retrieval and processing, enhancing both efficiency and strategic decision-making"
    description: "Hierarchical RAG organizes agents in tiers with higher-level agents overseeing lower-level ones. Top-tier agents evaluate query complexity and prioritize data sources, mid-level agents retrieve from specialized sources, and lower-level agents perform specific retrieval tasks. This enables strategic prioritization, multi-level decision-making, and scalable handling of complex multi-faceted queries through structured delegation."

  - name: "Corrective RAG with Self-Correction Mechanisms"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:193-244)"
    quote: "Corrective RAG introduces mechanisms to self-correct retrieval results, enhancing document utilization and improving response generation quality"
    description: "Corrective RAG embeds intelligent agents for iterative refinement: Context Retrieval Agent (initial retrieval), Relevance Evaluation Agent (assesses document relevance), Query Refinement Agent (rewrites queries for better results), External Knowledge Retrieval Agent (supplements with web search when context insufficient), and Response Synthesis Agent (produces final output). This ensures iterative correction and minimizes errors."

  - name: "Adaptive RAG with Dynamic Strategy Selection"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:317-398)"
    quote: "Adaptive Retrieval-Augmented Generation (Adaptive RAG) enhances flexibility and efficiency by dynamically adjusting query handling strategies based on the complexity of the incoming query"
    description: "Adaptive RAG uses a classifier to assess query complexity and select appropriate strategies: straightforward queries bypass retrieval and use direct generation, simple queries use single-step retrieval, complex queries activate multi-step retrieval with iterative refinement. A smaller language model classifies queries while the main LLM synthesizes responses. This optimizes both computational efficiency and response accuracy by matching resources to query demands."

  - name: "Graph-Based Agent-G Framework"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:449-478)"
    quote: "Agent-G introduces a novel agentic architecture that integrates graph knowledge bases with unstructured document retrieval... employs modular retriever banks, dynamic agent interaction, and feedback loops"
    description: "Agent-G combines structured graph knowledge bases with unstructured document retrieval for enhanced reasoning. Components include a Retriever Bank (modular specialized agents), Critic Module (validates relevance and quality), and Dynamic Agent Interaction (coordinates graph and text retrieval). Feedback loops enable iterative refinement, ensuring high-quality synthesis of structured relationships with contextual document information."

  - name: "GeAR Graph-Enhanced Agent Framework"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:586-621)"
    quote: "GeAR introduces an agentic framework that enhances traditional RAG systems by incorporating graph-based retrieval mechanisms... addresses challenges in multi-hop retrieval scenarios"
    description: "GeAR (Graph-Enhanced Agent for RAG) uses graph expansion to enhance base retrievers, enabling multi-hop retrieval through entity relationships. An agent-based architecture autonomously selects and combines retrieval strategies based on query complexity, deciding when to utilize graph-expanded paths. This supports complex queries requiring reasoning across multiple interconnected entities while maintaining scalable modularity."

  - name: "Agentic Document Workflows (ADW)"
    chunk_ref: "20-Agentic_RAG_Survey (Chunk 2:704-750)"
    quote: "Agentic Document Workflows (ADW) extend traditional RAG paradigms by enabling end-to-end knowledge work automation. These workflows orchestrate complex document-centric processes"
    description: "ADW automates end-to-end document-centric workflows integrating parsing, retrieval, reasoning, and structured outputs. Key capabilities include document parsing and information structuring, state maintenance across multi-step processes, knowledge retrieval from external bases, agentic orchestration applying business rules and multi-hop reasoning, and actionable output generation. Supports enterprise workflows like invoice processing, contract review, and claims analysis."
