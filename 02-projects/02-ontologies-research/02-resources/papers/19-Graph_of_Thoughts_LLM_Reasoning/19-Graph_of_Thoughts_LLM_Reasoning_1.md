<!-- Source: 19-Graph_of_Thoughts_LLM_Reasoning.pdf | Chunk 1/7 -->

#### **Graph of Thoughts: Solving Elaborate Problems with Large Language Models**

**Maciej Besta** [1*] **, Nils Blach** [1*] **, Ales Kubicek** [1] **, Robert Gerstenberger** [1] **,**
**Michał Podstawski** [2] **, Lukas Gianinazzi** [1] **, Joanna Gajda** [3] **, Tomasz Lehmann** [3] **,**
**Hubert Niewiadomski** [3] **, Piotr Nyczyk** [3] **, Torsten Hoefler** [1]

1ETH Zurich, 2Warsaw University of Technology, 3Cledar
bestam@inf.ethz.ch, nils.blach@inf.ethz.ch, htor@inf.ethz.ch



**Abstract**


We introduce Graph of Thoughts (GoT): a framework that
advances prompting capabilities in large language models
(LLMs) beyond those offered by paradigms such as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary
advantage of GoT is the ability to model the information generated by an LLM as an _arbitrary graph_, where units of information (“LLM thoughts”) are vertices, and edges correspond
to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts,
or enhancing thoughts using feedback loops. We illustrate
that GoT offers advantages over state of the art on different
tasks, for example increasing the quality of sorting by 62%
over ToT, while simultaneously reducing costs by _>_ 31%.
We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting
schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both
of which form complex networks.


**Website & code:** https://github.com/spcl/graph-of-thoughts


**1** **Introduction**

Large language models (LLMs) are taking over the world
of AI. Recent years saw a rapid development of models primarily based on the decoder-only Transformer variant [65],
such as GPT [13, 14, 53, 54], PaLM [19], or LLaMA [63].
_Prompt engineering_ is a resource-efficient approach for
solving different LLM tasks. In brief, one includes the task
description within the input sent to an LLM. If this description is appropriately formulated, the LLM solves the task
using its autoregressive token-based mechanism for generating text. Such prompts may contain example tasks with
solutions (few-shot prompting, also referred to as in-context
learning (ICL)), or even no example tasks at all (zero-shot
prompting). In recent years it was shown that this mechanism can be used to solve a broad set of tasks that involve
mathematical, commonsense, or symbolic reasoning.
Chain-of-Thought (CoT) [71] is an approach for prompting, in which one includes the intermediate steps of reasoning within the prompt (intermediate “thoughts”), besides
the task input/output. CoT was shown to significantly improve the capability of LLMs to solve problems without resorting to any model updates. One major improvement over


*Equal contribution



CoT, Self-Consistency with CoT (CoT-SC) [67], is a scheme
where multiple CoTs are generated, and then the best one is
selected as the outcome. More recently, CoT and CoT-SC
were extended with Tree of Thoughts (ToT) [43, 75, 77],
which models the LLM reasoning process with a tree. This
facilitates using different paths of thoughts, and offers novel
capabilities such as backtracking from non-promising outcomes. Unfortunately, the ToT approaches still fundamentally limit the reasoning abilities within a prompt by imposing the rigid tree structure on the thought process.
In this work, we argue that fundamentally more powerful prompting can be achieved by enabling LLM thoughts to
form an arbitrary graph structure. This is motivated by numerous phenomena such as human reasoning, brain structure, or algorithmic execution. When working on a novel
idea, a human would not only follow a chain of thoughts
(as in CoT) or try different separate ones (as in ToT), but
would actually form a more complex network of thoughts.
For example, one could explore a certain chain of reasoning, backtrack and start a new one, then realize that a certain idea from the previous chain could be combined with
the currently explored one, and merge them both into a new
solution, taking advantage of their strengths and eliminating their weaknesses. Similarly, brains form complex networks, with graph-like patterns such as recurrence [28]. Executing algorithms also expose networked patterns, often
represented by Directed Acyclic Graphs. The corresponding _graph-enabled transformations_ bring a promise of more
powerful prompting when applied to LLM thoughts, but they
are not naturally expressible with CoT or ToT.
We observe that these (and many other) thought transformations can be naturally enabled when _modeling the_
_reasoning process of an LLM as a graph_ . For this, we
propose Graph of Thoughts (GoT), an approach that _en-_
_hances LLMs’ capabilities through networked reasoning_
( **contribution #1** ). In GoT, an LLM thought is modeled
as a vertex, while an edge is a dependency between such
thoughts. Using GoT, one can aggregate arbitrary thoughts
by constructing vertices that have more than one incoming edge. Overall, the graph abstraction harnessed by GoT
seamlessly generalizes CoT and ToT to more complex
thought patterns, _without resorting to any model updates_ .
Yet, putting GoT to practice requires solving several design challenges. For example, what is the best graph structure for different tasks? How to best aggregate thoughts to
maximize accuracy and minimize cost? To answer these and


many other questions, we carefully design a modular architecture for implementing GoT ( **contribution #2** ), coming
with two design highlights. First, we enable a _fine-grained_
_control over individual thoughts_ . This enables us to fully
control the ongoing conversation with the LLM, and apply
advanced thought transformations, such as combining most
promising thoughts from the ongoing reasoning into a new
one. Second, we ensure that our architecture can be seamlessly extended with novel thought transformations, patterns
of reasoning (i.e., graphs of thoughts), and LLM models.
This enables rapid prototyping of novel prompting ideas using GoT, while experimenting with different models such as
GPT-3.5, GPT-4, or Llama-2 [64].
We illustrate several use cases for GoT (sorting, keyword
counting for summaries, set operations, document merging)
and we detail how to implement them using the graph-based
paradigm ( **contribution #3** ). We evaluate GoT and show its
advantages over the state of the art ( **contribution #4** ). Overall, we observe that GoT is particularly well-suited for tasks
that can be naturally decomposed into smaller subtasks that
are solved individually and then merged for a final solution.
Here, GoT outperforms other schemes, for example improving upon CoT and ToT by, respectively, _≈_ 70% and _≈_ 62%,
in terms of the quality of sorting, while _simultaneously_ reducing costs by _>_ 31% over ToT.
We qualitatively compare GoT to other prompting
schemes [1] in Table 1. GoT is the only one to enable arbitrary
graph-based thought transformations within a prompt, such
as aggregation, embracing all previously proposed schemes.


**Scheme** **Sc? Mc? Tr? Ag?**


Chain-of-Thought (CoT) [71] ��    -    Self-Consistency with CoT [67] ��    -    Thought decomposition [75] �� ��
Tree-of-Thought (ToT) [43] �� ��
Tree of Thoughts (ToT) [77] �� ��


**Graph of Thoughts (GoT)** �� ��

Table 1: Comparison of prompting schemes, with respect to the supported transformations of thoughts. **“Sc?”** :
single chain of thoughts? **“Mc?”** : multiple chains of
thoughts? **“Tr?”** : tree of thoughts? **“Ag?”** : arbitrary graph
of thoughts? “�”: full support, “�”: partial support, “�”:
no support.


Finally, we propose a new metric for evaluating a prompting strategy, the _volume of a thought_ ( **contribution #5** ).
With this metric, we aim to understand better the differences
between prompting schemes. For a given thought _v_, the volume of _v_ is _the number of LLM thoughts, from which one_
_can reach v using directed edges_ . Intuitively, these are all
the LLM thoughts that have had the potential to contribute


1Note that we do not include a recent scheme called Graph-ofThought [79] because it is not a prompting scheme. While its
name suggests close connections to ToT and CoT, as a fine-tuning
scheme, it resorts to model updates, and is thus outside the focus
of this work. Similarly, the graph-of-thoughts repository [52] does
not enable general graph-based reasoning and harnesses instead
ToT with BFS.



to _v_ . We show that GoT, by incorporating thought transformations such as aggregation, enables thoughts to have fundamentally larger volumes than other schemes.


**2** **Background & Notation**

We first outline background concepts and notation.


**2.1** **Language Models & In-Context Learning**

The **conversation with the LLM** consists of user messages
( _prompts_ ) and LLM replies ( _thoughts_ ). We follow the established notation [77] and we denote a pre-trained language
model (LM) with parameters _θ_ as _pθ_ . Lowercase letters such
as _x, y, z, ..._ indicate LLM thoughts. We purposefully do not
prescribe what is a single “thought”, and instead make it usecase specific. Hence, a single thought can be a paragraph
(e.g., in article summary), a document (e.g., in document
generation), a block of code (e.g., in code debugging or optimization), and so on.
We next describe specific **prompting approaches** .


**Input-Output (IO)** The Input-Output (IO) prompting is a
straightforward approach, in which we use an LLM to turn
an input sequence _x_ into the output _y directly_, without any
intermediate thoughts.


**Chain-of-Thought (CoT)** Second, in Chain-of-Thought
(CoT), one introduces intermediate thoughts _a_ 1 _, a_ 2 _, ..._ between _x_ and _y_ . This strategy was shown to significantly enhance various LM tasks over the plain IO baseline, such as
mathematical puzzles [71] or general mathematical reasoning [24].


**Multiple CoTs** Third, one can generalize CoT into _multi-_
_ple CoTs_ by generating _several_ (independent) _k_ CoTs, and
returning the one with the best output (according to some
prescribed scoring metric). It was introduced by Wang et
al. in the scheme called Self-Consistency with CoT (CoTSC) [67]. This approach enhances CoT because it offers an
opportunity to explore different reasoning paths. However,
it does not offer “local exploration” within a path, such as
backtracking.


**Tree of Thoughts (ToT)** Finally, the Tree of Thoughts
(ToT) scheme was introduced independently by Yao [77]
and Long [43] (where it is referred to as Tree-of-Thought);
it was used implicitly to a certain degree by other schemes
such as thought decomposition [75]. It enhances CoT-SC by
modeling the process or reasoning as a _tree_ of thoughts. A
single tree node represents a partial solution. Based on a
given node, the _thought generator_ constructs a given number
_k_ of new nodes. Then, the _state evaluator_ generates scores
for each such new node. Depending on the use case, the evaluation could be conducted using an LLM itself, or it can harness human scores. Finally, the schedule of extending the
tree is dictated by the utilized search algorithm (for example
BFS or DFS).


**3** **The GoT Framework**

We now detail the GoT framework. We present it in Figure 1,
and compare it to other prompting strategies.



2


score Abandon a chain Output **Key novelty** Output



















Figure 1: Comparison of Graph of Thoughts (GoT) to other prompting strategies.



Formally, GoT can be modeled as a tuple ( _G, T, E, R_ ),
where _G_ is the “LLM reasoning process” (i.e., all the LLM
thoughts within the context, with their relationships), _T_ are
the potential thought transformations, _E_ is an evaluator function used to obtain scores of thoughts, and _R_ is a ranking
function used to select most relevant thoughts.


**3.1** **Reasoning Process**


We model the reasoning process as a directed **graph** _G_ =
( _V, E_ ); _V_ is a set of vertices and _E ⊆_ _V × V_ is a set of
edges. _G_ is directed and thus the edges are a subset of ordered vertex pairs _E ⊆_ _V × V_ . A vertex contains a _solution_
to a problem at hand (be it an initial, intermediate, or a final one). The concrete form of such a thought depends on
the use case; it could be a paragraph (in writing tasks) or a
sequence of numbers (in sorting). A directed edge ( _t_ 1 _, t_ 2)
indicates that thought _t_ 2 has been constructed using _t_ 1 as
“direct input”, i.e., by explicitly instructing the LLM to use
_t_ 1 for generating _t_ 2.
In certain use cases, graph nodes belong to different
_classes_ . For example, in writing tasks, some vertices model
_plans of writing a paragraph_, while other vertices model _the_
_actual paragraphs of text_ . In such cases, GoT embraces a
**heterogeneous graph** _G_ = ( _V, E, c_ ) to model the LLM reasoning, where _c_ maps vertices _V_ into their respective classes
_C_ (in the above case, it would be _C_ = _{plan, par}_ ). Hence,
any vertex _v_ can model different aspects of reasoning.
We associate _G_ with the LLM reasoning process. To advance this process, one applies **thought transformations** to
_G_ . An example of such a transformation is to merge bestscoring (so far) thoughts into a new one. Another example
is to loop over a thought, in order to enhance it. Note that
these transformations strictly extend the set of transformations available in the CoT, CoT-SC, or ToT.



**Graph theory view** **Example sorting task** **Example writing task**
# ... ... ...


# ...








# ...

























**3.2** **Transformations of Thoughts**


GoT enables novel transformations of thoughts thanks to
the graph-based model for reasoning. We refer to them as



Figure 2: Examples of aggregation and generation thought
transformations.


**graph-enabled transformations** . For example, in writing,
one could combine several input articles into one coherent
summary. In sorting, one could merge several sorted subarrays of numbers into a final sorted array. We illustrate examples of aggregation and generation in Figure 2.
Formally, each such transformation can be modeled as
_T_ ( _G, pθ_ ) where _G_ = ( _V, E_ ) is the graph reflecting the
current state of the reasoning, and _pθ_ is the used LLM. _T_
modifies _G_ usually by adding new vertices and their incoming edges. We have _G_ _[′]_ = _T_ ( _G, pθ_ ) = ( _V_ _[′]_ _, E_ _[′]_ ), where
_V_ _[′]_ = ( _V ∪_ _V_ [+] ) _\ V_ _[−]_ and _E_ _[′]_ = ( _E ∪_ _E_ [+] ) _\ E_ _[−]_ . _V_ [+]
and _E_ [+] are new vertices and edges inserted into _G_ to model
the new thoughts and their dependencies, respectively. To
maximize the expressiveness of GoT – we also enable the
user to explicitly _remove_ thoughts, by specifying the corresponding vertices and edges to be removed ( _V_ _[−]_ and _E_ _[−]_, respectively). Here, it is the user’s responsibility to ensure that
the sets _V_ [+] _, E_ [+] _, V_ _[−]_ _,_ and _E_ _[−]_ come with consistent transformations (i.e., for example, that the user does not attempt
to remove a vertex that does not exist). This enables seam


3


less incorporation of schemes where, in order to save space
within the context, one can remove parts of reasoning that
do not promise improvements.
The specific form of _T_ and how it impacts _G_ depends on
a specific transformation. We first detail the primary graphenabled thought transformations, and then proceed to describe how GoT embraces the transformations from the earlier schemes. Unless stated otherwise, _V_ _[−]_ = _E_ _[−]_ = _∅_ .


**Aggregation Transformations** First, with GoT, one can
**aggregate arbitrary thoughts** into new ones, to combine
and reinforce the advantages of these thoughts, while eliminating their disadvantages. In the basic form, in which
only one new vertex is created, _V_ [+] = _{v_ [+] _}_ and _E_ [+] =
_{_ ( _v_ 1 _, v_ [+] ) _, ...,_ ( _vk, v_ [+] ) _}_, where _v_ 1 _, ..., vk_ are the merged _k_
thoughts. More generally, this enables **aggregating reason-**
**ing paths**, i.e., longer chains of thoughts, beyond just individual thoughts. With the graph model, it is simply achieved
by adding outgoing edges from the vertices _v_ 1 _, ..., vk_, modeling final thoughts in several chains, into a single thought
_v_ [+] combining these chains.


**Refining Transformations** Another thought transformation is the **refining** of a current thought _v_ by modifying its
content: _V_ [+] = _{}_ and _E_ [+] = _{_ ( _v, v_ ) _}_ . This loop in the
graph indicates an iterated thought with the same connections as the original thought.


**Generation Transformations** Finally, one can **generate**
**one or more new thoughts based on an existing single**
**thought** _v_ . This class embraces analogous reasoning steps
from earlier schemes, such as ToT or CoT-SC. Formally, we
have _V_ [+] = _{v_ 1 [+] _[, ..., v]_ _k_ [+] _[}]_ [ and] _[ E]_ [+][ =] _[ {]_ [(] _[v, v]_ 1 [+][)] _[, ...,]_ [ (] _[v, v]_ _k_ [+][)] _[}]_ [.]


**3.3** **Scoring & Ranking Thoughts**


Thoughts are scored to understand whether the current solution is good enough. A score is modeled as a general function _E_ ( _v, G, pθ_ ), where _v_ is a thought to be evaluated. We
use the state of the whole reasoning process ( _G_ ) in _E_ for
maximum generality, because – for example – in some evaluation scenarios, scores may be relative to other thoughts.
GoT can also rank thoughts. We model this with a function _R_ ( _G, pθ, h_ ) where _h_ specifies the number of highestranking thoughts in _G_ to be returned by _R_ . While the specific form of _R_ depends on the use case, we most often use a
simple yet effective strategy where _h_ thoughts with the highest scores are returned, i.e., _v_ 1 _, ..., vh_ = _R_ ( _G, pθ, h_ ).
Specific forms of _E_ and _R_ depend on the use case. We discuss the details in Section 5. For example, the score (or rank)
for sorting corresponds to the count of elements correctly
sorted (or incorrectly, when using the error as a score).


**4** **System Architecture & Extensibility**


The GoT architecture consists of a set of interacting modules, see Figure 3 (the blue part). These modules are the
Prompter (prepares the messages for the LLM), the Parser
(extracts information from LLM thoughts), the Scoring
module (verifies and scores the LLM thoughts), and the



Controller (coordinates the entire reasoning process, and decides on how to progress it). The Controller contains two further important elements: the Graph of Operations (GoO) and
the Graph Reasoning State (GRS). GoO is a static structure
that specifies the _graph decomposition of a given task_, i.e.,
it prescribes transformations to be applied to LLM thoughts,
together with their order & dependencies. GRS is a dynamic
structure that maintains the state of the ongoing LLM reasoning process (the history of its thoughts and their states).


**4.1** **Prompter**

The Prompter prepares the prompts to be sent to the LLM.
This module is responsible for the specifics of encoding the
graph structure within the prompt. The GoT architecture enables the user to implement use case specific graph encodings by providing full access to the graph structure.


**4.2** **Parser**

The Parser extracts information from LLM thoughts. For
each such thought, the Parser constructs the _thought state_,
which contains this extracted information. The thought state
is then used to update the GRS accordingly.


**4.3** **Scoring & Validation**

Here, we verify whether a given LLM thought satisfies potential correctness conditions, and then we assign it a score.
Depending on how the score is derived, the module may
consult the LLM. Moreover, depending on the use case, the
score may also be assigned by a human. Finally, use cases
such as sorting use simple local scoring functions.


**4.4** **Controller**

The Controller implements a specific strategy for selecting thoughts from its GRS structure. It also selects what
transformations should be applied to which thoughts, and
then passes this information to the Prompter. It also decides
whether the whole process should be finalized, or whether
the next round of interaction with the LLM should be initiated. In our current design, this is dictated by the execution
plan specified in the GoO.


**4.5** **GoO & GRS**

The user constructs a GoO instance, which prescribes the
execution plan of thought operations. The GoO is a static
structure that is constructed once, before the execution starts.
Each operation object knows its predecessor and successor
operations. Then, during the execution, an instance of the
GRS maintains the continually updated information about
the LLM reasoning process. This includes which operation
has been executed so far, the states of all the generated LLM
thoughts, their validity and scores, and any other relevant
information.
The above elements offer extensible **APIs**, enabling
straightforward implementations of different prompting
schemes. The APIs are outlines in the green part of Figure 3, and detailed in the documentation. We also provide
**examples of prompts** used by these operations and a corresponding GRS in the red part of Figure 3.



4


Figure 3: The system architecture of GoT, and the APIs of respective modules. The user can straightforwardly extend the design
towards new prompting schemes, experiment with novel thought transformations, and plug in different LLMs. The blue part of
the figure contains the architecture overview, the green part lists the API, and the red part contains example prompts together
with a GRS and operations involved.


5


**5** **Example Use Cases**

We now describe several use cases of GoT. We detail one
use case (sorting) and summarize the others.


**5.1** **Sorting**

We focus on the decomposition of the sorting use case and
Graph of Operations, which are central for implementing
and executing any workload within GoT.
We consider sorting numbers 0–9 with duplicates. The
considered LLMs are unable to sort a sequence of such numbers correctly beyond a certain length consistently because
duplicate counts do not match.
In GoT, we employ merge-based sorting: First, one decomposes the input sequence of numbers into subarrays.
Then, one sorts these subarrays individually, and then respectively merges them into a final solution. Figure 4 illustrates this use case together with its graph decomposition.
Here, an LLM thought is a sequence of sorted numbers.
To score an outcome, denote an input sequence with

[ _a_ 1 _, a_ 2 _, ..., an_ ] and an output one with [ _b_ 1 _, b_ 2 _, ..., bm_ ]. We
use the following score that determines “the scope” of errors:


error-scope = _X_ + _Y_

where _p ∈{_ 1 _, ..., m}_, _q ∈{_ 1 _, ..., n}_, and





**Graph of Operations (GoO) for sorting 64 numbers**



































**Details of the highlighted part of the GoO from above**



















_X_ =


_Y_ =



_m−_ 1

- sgn(max( _bi −_ _bi_ +1 _,_ 0)) _,_


_i_ =1


9

- _| |{bp_ : _bp_ = _i}| −|{aq_ : _aq_ = _i}| |_


_i_ =0

























Here, _X_ indicates how many consecutive pairs of numbers are incorrectly sorted. If two numbers _i_ and _i_ + 1
are incorrectly sorted (i.e., _bi > bi_ +1), then the expression
within the summation returns 1, increasing the error score
by one. For two numbers correctly sorted, this expression
amounts to 0. Then, _Y_ determines how well a given output
sequence preserves the frequency of output numbers. Specifically, for each considered number _x_ ( _x ∈{_ 0 _, ...,_ 9 _}_ ), we
obtain the difference between the count of input elements
being equal to _x_, vs. the count of output elements equal
to _x_ . For an output sequence perfectly preserving the frequency of _x_, this would amount to 0. Any single “deviation” in this count, increases the “error scope” by 1. We
then sum this over all considered values of _x_ . When plotting this score, to improve the clarity of plots, we additionally apply clipping min(error-scope _, n_ ), as some baselines
(IO, CoT) result in large numbers of outliers with high error scope. Finally, to use a “positive score” describing “the
scope of correctly sorted” elements, one can use the value
max( _n −_ error-scope _,_ 0).


**5.2** **Set Operations**

Moreover, we also consider set operations, focusing on set
intersection. They have numerous applications (particularly
set intersection) in problems ranging from genome or document comparisons to pattern matching [9–11, 20, 27, 38, 50,



















































Figure 4: An example graph decomposition of the sorting
use case in GoT. All used operations (Generate, Aggregate,
Score, KeepBest) are described in Figure 3.



6


58]. Set intersection of two sets is implemented similarly as
the sorting. The second input set is split into subsets and the
intersection of those subsets with the first input set is determined with the help of the LLM. Afterwards the resulting
intersection sets are aggregated for the final results. For the
evaluation we use different set sizes of 32, 64 and 128 elements and we vary the number of elements found in both
sets to be between 25% and 75%.
Our score indicates the total number of missing or incorrectly included elements in the final intersection. Specifically, denote two input sets with _A_ = [ _a_ 1 _, a_ 2 _, ..., an_ ]
and _B_ = [ _b_ 1 _, b_ 2 _, ..., bn_ ], and the output set with _C_ =

[ _c_ 1 _, c_ 2 _, ..., cm_ ]. Then,


error-scope = _X_ 1 + _X_ 2 + _Xd_
where _X_ 1 = _|C \_ ( _A ∩_ _B_ ) _|_ are the number of elements in _C_
that are not supposed to be there, _X_ 2 = _|_ ( _A∩B_ ) _\C|_ are the
number of elements missing from _C_, and _Xd_ is the number
of duplicates in _C_ (because the LLM expresses the set as a
list in natural language). Finally, to use a “positive score”
describing “the scope of correctly computed” elements, one
can use the value max( _n −_ error-scope _,_ 0).


**5.3** **Keyword Counting**


Keyword counting finds the frequency of keywords in a
given category (countries in our example implementation)
within the input text. GoT splits the input text into multiple
passages, counts the keywords in each passage and aggregates the subresults. The number of passages is configurable
and can also be left to the LLM, making it possible to treat
each sentence as a separate passage. Here, to score a thought,
we first – for each keyword – derive the absolute difference
between the computed count and the correct one. We then
sum all these differences to get the final score.


**5.4** **Document Merging**


Finally, we also provide document merging. Here, the goal
is to generate a new Non-Disclosure Agreement (NDA) document based on several input ones that partially overlap
in terms of their contents. The goal is to ensure minimal
amount of duplication, while maximizing information retention. Document merging is broadly applicable in, e.g., legal
procedures, where multiple sources of information have to
be combined into a single document or article. To score a
solution, we query the LLM for two values (3 times for each
value, and take the average). The first value corresponds to
the solution redundancy (10 indicates no redundancy, 0 implies at least half the information is redundant), the second
value stands for information retention (10 indicates all information is retained, 0 says that none is retained). We compute
the harmonic mean of these values.


**6** **The Latency-Volume Tradeoff**


We now show that GoT improves upon previous prompting
schemes in terms of the tradeoff between latency (number of
hops in the graph of thoughts to reach a given final thought)
and _volume_ . We define volume – for a given thought _t_ - as



_the number of preceding LLM thoughts that could have im-_
_pacted t_ . Formally, the volume of _t_ is the number of thoughts
from which there exists a path to _t_ in the graph of thoughts.
We assume that outputting a single thought costs _O_ (1) time
and fix the total cost to Θ( _n_ ) for each prompting scheme.
The structure of the schemes is as follows. CoT-SC consists of _k_ independent chains originating from a single starting thought. ToT is a complete _k_ -ary tree. Finally, in GoT, a
complete _k_ -ary tree is joined at its leaves with a “mirrored”
_k_ -ary tree of the same size but with its edges reversed.
The analysis is detailed in Table 2. CoT offers a large volume of up to _N_, but at the cost of a high latency of _N_ . CoTSC reduces the latency by a factor of _k_ (which corresponds
to its branching factor), but it simultaneously decreases the
volume by _k_ as well. ToT offers a latency of log _k N_ but
also has low volume. GoT is the only scheme to come with
both a low latency of log _k N_ and a high volume _N_ . This
is enabled by the fact that GoT harnesses aggregations of
thoughts, making it possible to reach the final thought from
any other intermediate thought in the graph decomposition.


**Scheme** **Latency Volume**


Chain-of-Thought (CoT) _N_ _N_
Self-Consistency with CoT (CoT-SC) _N/k_ _N/k_
Tree of Thoughts (ToT) log _k_ _N_ _O_ (log _k_ _N_ )


**Graph of Thoughts (GoT)** log _k_ _N_ _N_
Table 2: Comparison of prompting schemes, with respect
to their fundamental tradeoff between latency and volume.
**GoT offers the best tradeoff.**


**7** **Evaluation**

We show the advantages of GoT over the state of the art. We
focus on comparing GoT to ToT, as it was shown to consistently outperform other schemes. Still, for a broad comparison, we also experiment with IO, CoT, and CoT-SC. As our
analysis results in a large evaluation space, we present representative results and omit data that does not bring relevant
insights (e.g., CoT-SC).


**7.1** **Evaluation Methodology**

We use 100 input samples for each task and comparison
baseline. We set the temperature to 1.0 and use a 4k context size unless stated otherwise. For each experiment, we
fix the numbers of thoughts in respective schemes to achieve
similar costs in each experiment.
**Parameters** We experiment extensively with the branching factor _k_ and the number of levels _L_ to ensure that we
compare GoT to cost-effective and advantageous configurations. We plot two variants of ToT: one with higher _k_
and lower depth (ToT), the other with lower _k_ but higher _L_
(ToT2). We usually aim to achieve a sweet spot in the tradeoff between sparser generation rounds (lower _k_ ) vs. more
rounds (larger _L_ ). Usually more responses per round is more
expensive (e.g., 80 vs. 60 total responses for Figure 7 but $6
vs. $3 costs). We also try different problem sizes _P_ (e.g., in
sorting, _P_ states how many numbers are to be sorted).



7


**32 elements**



**64 elements**



**128 elements**





16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
0



& Appendix 4.8 clipped



16


14


12


10


8


6


4


2





112
104

88
80

64
56
48
40
32
24
16
8
0
IO CoT ToT ToT2 **GoT**



48
44

36
32
28
24
20
16
12
8
4
0
IO CoT ToT ToT2 **GoT**



4.8
4.5
4.2
3.9
3.6
3.3
3.0
2.7
2.4
2.1
1.8
1.5
1.2
0.9
0.6
0.3
0.0















0
IO CoT ToT ToT2 **GoT**



1.6


1.4


1.2


1.0


0.8


0.6


0.4


0.2


0.0



Figure 5: Number of errors and cost in sorting tasks with ChatGPT-3.5. _L_ and _k_ indicate the structure of ToT (see Sections 3.2
and 6).



**Used LLMs** Due to budget restrictions, we focus on GPT3.5. We also experimented with Llama-2, but it was usually
worse than GPT-3.5 and also much slower to run, making it
infeasible to obtain enough samples.


**7.2** **Analysis of GoT’s Advantages**


The results of the analysis are in Figure 5 (sorting), 6 (set
intersection), 7 (keyword counting), and 8 (document merging); see Section 5 for the description of specific use cases.
_Overall, GoT improves the quality of outcomes over all the_
_considered baselines and it reduces inference costs com-_
_pared to ToT_ .
**GoT vs. ToT** GoT improves upon ToT and ToT2 by a
large margin over all the considered problem instances. ToT
usually comes with somewhat higher quality than ToT2, but
simultaneously much higher costs. GoT’s costs are always
lower than ToT, and comparable (in some cases lower, in
others higher) to ToT2. For example, it reduces median error by _≈_ 62%, thereby achieving a higher quality of sorting,
for _P_ = 128 in comparison to ToT while ensuring _>_ 31%
cost reductions. These advantages are due to GoT’s ability to
decompose complex tasks into simpler subtasks, solve these
subtasks independently, and then incrementally merge these
outcomes into the final result.
**GoT vs. IO and CoT** GoT consistently delivers much
higher quality of outcomes than IO/CoT. For example, for
sorting ( _P_ = 64), GoT’s median error is _≈_ 65% and _≈_ 83%
lower than, respectively, CoT and IO. Yet, the costs of GoT
