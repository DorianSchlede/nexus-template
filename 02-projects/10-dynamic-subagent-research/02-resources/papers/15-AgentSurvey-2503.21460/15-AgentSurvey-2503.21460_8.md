<!-- Source: 15-AgentSurvey-2503.21460.pdf | Chunk 8/10 -->

language models through multi-agent debate,” _arXiv preprint_
_arXiv:2305.19118_, 2023.

[81] K. Kim, S. Lee, K.-H. Huang, H. P. Chan, M. Li, and H. Ji, “Can
llms produce faithful explanations for fact-checking? towards
faithful explainable fact-checking via multi-agent debate,” _arXiv_
_preprint arXiv:2402.07401_, 2024.

[82] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch,
“Improving factuality and reasoning in language models through
multiagent debate,” in _ICML_, 2023.

[83] Y. Zhu, S. Qiao, Y. Ou, S. Deng, N. Zhang, S. Lyu, Y. Shen,
L. Liang, J. Gu, and H. Chen, “Knowagent: Knowledge-augmented
planning for llm-based agents,” _arXiv preprint arXiv:2403.03101_,
2024.

[84] S. Qiao, R. Fang, N. Zhang, Y. Zhu, X. Chen, S. Deng, Y. Jiang,
P. Xie, F. Huang, and H. Chen, “Agent planning with world
knowledge model,” _NeurIPS_, vol. 37, pp. 114 843–114 871, 2024.

[85] R. Fang, S. Qiao, and Z. Xi, “Refining guideline knowledge for
agent planning using textgrad,” in _ICKG_ . IEEE, 2024, pp. 102–103.

[86] Q. Zhong, L. Ding, J. Liu, B. Du, and D. Tao, “Self-evolution
learning for discriminative language model pretraining,” in _ACL_
_Findings_, 2023, pp. 4130–4145.

[87] T. Akiba, M. Shing, Y. Tang, Q. Sun, and D. Ha, “Evolutionary optimization of model merging recipes,” _Nature Machine Intelligence_,
pp. 1–10, 2025.

[88] S. Wu, K. Lu, B. Xu, J. Lin, Q. Su, and C. Zhou, “Self-evolved
diverse data sampling for efficient instruction tuning,” _arXiv_
_preprint arXiv:2311.08182_, 2023.

[89] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe,
U. Alon, N. Dziri, S. Prabhumoye, Y. Yang _et al._, “Self-refine:
Iterative refinement with self-feedback,” _NeurIPS_, vol. 36, pp.
46 534–46 594, 2023.

[90] E. Zelikman, Y. Wu, J. Mu, and N. D. Goodman, “Star: Self-taught
reasoner bootstrapping reasoning with reasoning,” in _NeurIPS_,
vol. 1126, 2024.

[91] A. Hosseini, X. Yuan, N. Malkin, A. Courville, A. Sordoni, and
R. Agarwal, “V-star: Training verifiers for self-taught reasoners,”
in _COLM_, 2024.

[92] Y. Weng, M. Zhu, F. Xia, B. Li, S. He, S. Liu, B. Sun, K. Liu,
and J. Zhao, “Large language models are better reasoners with
self-verification,” in _EMNLP Findings_, 2023, pp. 2550–2575.



21


[93] W. Yuan, R. Y. Pang, K. Cho, X. Li, S. Sukhbaatar, J. Xu, and
J. Weston, “Self-rewarding language models,” 2024.

[94] K. Yang, D. Klein, A. Celikyilmaz, N. Peng, and Y. Tian, “Rlcd:
Reinforcement learning from contrastive distillation for lm alignment,” in _ICLR_, 2024.

[95] J.-C. Pang, P. Wang, K. Li, X.-H. Chen, J. Xu, Z. Zhang, and Y. Yu,
“Language model self-improvement by reinforcement learning
contemplation,” in _ICLR_, 2024.

[96] C. Zhang, K. Yang, S. Hu, Z. Wang, G. Li, Y. Sun, C. Zhang,
Z. Zhang, A. Liu, S.-C. Zhu _et al._, “Proagent: building proactive
cooperative agents with large language models,” in _AAAI_, vol. 38,
no. 16, 2024, pp. 17 591–17 599.

[97] H. Ma, T. Hu, Z. Pu, L. Boyin, X. Ai, Y. Liang, and M. Chen,
“Coevolving with the other you: Fine-tuning llm with sequential
cooperative multi-agent reinforcement learning,” _NeurIPS_, vol. 37,
pp. 15 497–15 525, 2024.

[98] C. Ma, Z. Yang, H. Ci, J. Gao, M. Gao, X. Pan, and Y. Yang,
“Evolving diverse red-team language models in multi-round multiagent games,” _arXiv preprint arXiv:2310.00322_, 2023.

[99] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, S. Shi,
and Z. Tu, “Encouraging divergent thinking in large language
models through multi-agent debate,” in _EMNLP_, 2024, pp. 17 889–
17 904.

[100] Z. Gou, Z. Shao, Y. Gong, Y. Yang, N. Duan, W. Chen _et al._, “Critic:
Large language models can self-correct with tool-interactive
critiquing,” in _ICLR_, 2024.

[101] Y. Song, D. Yin, X. Yue, J. Huang, S. Li, and B. Y. Lin, “Trial and
error: Exploration-based trajectory optimization of llm agents,” in
_ACL_, 2024, pp. 7584–7600.

[102] S. Jiang, Y. Wang, and Y. Wang, “Selfevolve: A code evolution framework via large language models,” _arXiv preprint_
_arXiv:2306.02907_, 2023.

[103] X. Huang, W. Liu, X. Chen, X. Wang, H. Wang, D. Lian, Y. Wang,
R. Tang, and E. Chen, “Understanding the planning of llm agents:
A survey,” _arXiv preprint arXiv:2402.02716_, 2024.

[104] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large
language models are zero-shot reasoners,” _NeurIPS_, vol. 35, pp.
22 199–22 213, 2022.

[105] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,
D. Zhou _et al._, “Chain-of-thought prompting elicits reasoning in
large language models,” _NeurIPS_, vol. 35, pp. 24 824–24 837, 2022.

[106] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang,
A. Chowdhery, and D. Zhou, “Self-consistency improves chain
of thought reasoning in language models,” _arXiv preprint_
_arXiv:2203.11171_, 2022.

[107] W. Li and W. Pan, “Enhancing chain-of-thought reasoning in large
language models through text style diversity and prompt fusion,”
in _EIBDCT_, vol. 13181. SPIE, 2024, pp. 226–232.

[108] J. Jiang, Z. Chen, Y. Min, J. Chen, X. Cheng, J. Wang, Y. Tang,
H. Sun, J. Deng, W. X. Zhao _et al._, “Technical report: Enhancing
llm reasoning with reward-guided tree search,” _arXiv preprint_
_arXiv:2411.11694_, 2024.

[109] C. B. Browne, E. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling,
P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton,
“A survey of monte carlo tree search methods,” _IEEE Transactions_
_on Computational Intelligence and AI in games_, vol. 4, no. 1, pp. 1–43,
2012.

[110] H. Guo, Z. Liu, Y. Zhang, and Z. Wang, “Can large language
models play games? a case study of a self-play approach,” _arXiv_
_preprint arXiv:2403.05632_, 2024.

[111] Y. Liu, P. Sun, and H. Li, “Large language models as agents in
two-player games,” _arXiv preprint arXiv:2402.08078_, 2024.

[112] A. R. Laleh and M. N. Ahmadabadi, “A survey on enhancing
reinforcement learning in complex environments: Insights from
human and llm feedback,” _arXiv preprint arXiv:2411.13410_, 2024.

[113] Z. Shen, “Llm with tools: A survey,” _arXiv_ _preprint_
_arXiv:2409.18807_, 2024.

[114] C. Y. Kim, C. P. Lee, and B. Mutlu, “Understanding large-language
model (llm)-powered human-robot interaction,” in _HRI_, 2024, pp.
371–380.

[115] B. Li, Y. Wang, J. Gu, K.-W. Chang, and N. Peng, “Metal: A multiagent framework for chart generation with test-time scaling,”
_arXiv preprint arXiv:2502.17651_, 2025.

[116] S. Guo, C. Deng, Y. Wen, H. Chen, Y. Chang, and J. Wang,
“Ds-agent: Automated data science by empowering large
language models with case-based reasoning,” _arXiv preprint_
_arXiv:2402.17453_, 2024.


[117] Z. Yin, Q. Sun, C. Chang, Q. Guo, J. Dai, X. Huang, and
X. Qiu, “Exchange-of-thought: Enhancing large language model
capabilities through cross-model communication,” _arXiv preprint_
_arXiv:2312.01823_, 2023.

[118] Y. Li, S. Ren, P. Wu, S. Chen, C. Feng, and W. Zhang, “Learning
distilled collaboration graph for multi-agent perception,” _NeurIPS_,
vol. 34, pp. 29 541–29 552, 2021.

[119] Z. Liu, Y. Zhang, P. Li, Y. Liu, and D. Yang, “A dynamic llmpowered agent network for task-oriented agent collaboration,” in
_COLM_, 2024.

[120] Y. Kim, C. Park, H. Jeong, Y. S. Chan, X. Xu, D. McDuff, H. Lee,
M. Ghassemi, C. Breazeal, H. Park _et al._, “Mdagents: An adaptive
collaboration of llms for medical decision-making,” _NeurIPS_,
vol. 37, pp. 79 410–79 452, 2024.

[121] L. Ying, T. Zhi-Xuan, V. Mansinghka, and J. B. Tenenbaum,
“Inferring the goals of communicating agents from actions and
instructions,” in _Proceedings of the AAAI Symposium Series_, vol. 2,
no. 1, 2023, pp. 26–33.

[122] J. Vyas and M. Mercangoz, “Autonomous industrial control using¨
an agentic framework with large language models,” _arXiv preprint_
_arXiv:2411.05904_, 2024.

[123] D. Dell’Anna, N. Alechina, F. Dalpiaz, M. Dastani, and B. Logan,
“Data-driven revision of conditional norms in multi-agent systems,”
_Journal of Artificial Intelligence Research_, vol. 75, pp. 1549–1593, 2022.

[124] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding,
K. Men, K. Yang _et al._, “Agentbench: Evaluating llms as agents,”
_arXiv preprint arXiv:2308.03688_, 2023.

[125] X. Deng, Y. Gu, B. Zheng, S. Chen, S. Stevens, B. Wang, H. Sun,
and Y. Su, “Mind2web: Towards a generalist agent for the web,”
_NeurIPS_, vol. 36, pp. 28 091–28 114, 2023.

[126] G. Yin, H. Bai, S. Ma, F. Nan, Y. Sun, Z. Xu, S. Ma, J. Lu, X. Kong,
A. Zhang _et al._, “Mmau: A holistic benchmark of agent capabilities
across diverse domains,” _arXiv preprint arXiv:2407.18961_, 2024.

[127] K. Gu, R. Shang, R. Jiang, K. Kuang, R.-J. Lin, D. Lyu, Y. Mao,
Y. Pan, T. Wu, J. Yu _et al._, “Blade: Benchmarking language model
agents for data-driven science,” _arXiv preprint arXiv:2408.09667_,
2024.

[128] X. Liu, T. Zhang, Y. Gu, I. L. Iong, Y. Xu, X. Song, S. Zhang,
H. Lai, X. Liu, H. Zhao _et al._, “Visualagentbench: Towards large
multimodal models as visual foundation agents,” _arXiv preprint_
_arXiv:2408.06327_, 2024.

[129] M. Li, S. Zhao, Q. Wang, K. Wang, Y. Zhou, S. Srivastava,
C. Gokmen, T. Lee, E. L. Li, R. Zhang _et al._, “Embodied agent
interface: Benchmarking llms for embodied decision making,”
_NeurIPS_, vol. 37, pp. 100 428–100 534, 2025.

[130] T. Xu, L. Chen, D.-J. Wu, Y. Chen, Z. Zhang, X. Yao, Z. Xie, Y. Chen,
S. Liu, B. Qian _et al._, “Crab: Cross-platfrom agent benchmark
for multi-modal embodied language model agents,” in _NeurIPS_
_Workshop_, 2024.

[131] N. Butt, V. Chandrasekaran, N. Joshi, B. Nushi, and V. Balachandran, “Benchagents: Automated benchmark creation with agent
interaction,” _arXiv preprint arXiv:2410.22584_, 2024.

[132] S. Wang, Z. Long, Z. Fan, Z. Wei, and X. Huang, “Benchmark selfevolving: A multi-agent framework for dynamic llm evaluation,”
_arXiv preprint arXiv:2402.11443_, 2024.

[133] W. Wang, Z. Ma, P. Liu, and M. Chen, “Revisiting benchmark
and assessment: An agent-based exploratory dynamic evaluation
framework for llms,” _arXiv preprint arXiv:2410.11507_, 2024.

[134] M. Wu, T. Zhu, H. Han, C. Tan, X. Zhang, and W. Chen, “Seal-tools:
Self-instruct tool learning dataset for agent tuning and detailed
benchmark,” in _NLPCC_ . Springer, 2024, pp. 372–384.

[135] Z. Guo, Y. Huang, and D. Xiong, “Ctooleval: a chinese benchmark
for llm-powered agent evaluation in real-world api interactions,”
in _ACL Findings_, 2024, pp. 15 711–15 724.

[136] Y. Jiang, K. C. Black, G. Geng, D. Park, A. Y. Ng, and J. H. Chen,
“Medagentbench: Dataset for benchmarking llms as agents in
medical applications,” _arXiv preprint arXiv:2501.14654_, 2025.

[137] Z. Fan, J. Tang, W. Chen, S. Wang, Z. Wei, J. Xi, F. Huang,
and J. Zhou, “Ai hospital: Benchmarking large language models
in a multi-agent medical interaction simulator,” _arXiv preprint_
_arXiv:2402.09742_, 2024.

[138] Y. Ma, C. Cui, X. Cao, W. Ye, P. Liu, J. Lu, A. Abdelraouf, R. Gupta,
K. Han, A. Bera _et al._, “Lampilot: An open benchmark dataset for
autonomous driving with language model programs,” in _CVPR_,
2024, pp. 15 141–15 151.



22


[139] Y. Zhang, Q. Jiang, X. Han, N. Chen, Y. Yang, and K. Ren, “Benchmarking data science agents,” _arXiv preprint arXiv:2402.17168_,
2024.

[140] Y. Huang, J. Luo, Y. Yu, Y. Zhang, F. Lei, Y. Wei, S. He, L. Huang,
X. Liu, J. Zhao _et al._, “Da-code: Agent data science code generation benchmark for large language models,” _arXiv preprint_
_arXiv:2410.07331_, 2024.

[141] B. Huang, Y. Yu, J. Huang, X. Zhang, and J. Ma, “Dcabench: A benchmark for dataset curation agents,” _arXiv preprint_
_arXiv:2406.07275_, 2024.

[142] J. Xie, K. Zhang, J. Chen, T. Zhu, R. Lou, Y. Tian, Y. Xiao, and
Y. Su, “Travelplanner: A benchmark for real-world planning with
language agents,” _arXiv preprint arXiv:2402.01622_, 2024.

[143] Q. Huang, J. Vora, P. Liang, and J. Leskovec, “Benchmarking large
language models as ai research agents,” in _NeurIPS Workshop_,
2023.

[144] J. S. Chan, N. Chowdhury, O. Jaffe, J. Aung, D. Sherburn,
E. Mays, G. Starace, K. Liu, L. Maksin, T. Patwardhan _et al._, “Mlebench: Evaluating machine learning agents on machine learning
engineering,” _arXiv preprint arXiv:2410.07095_, 2024.

[145] M. Andriushchenko, A. Souly, M. Dziemian, D. Duenas, M. Lin,
J. Wang, D. Hendrycks, A. Zou, J. Z. Kolter, M. Fredrikson _et al._,
“Agentharm: Benchmarking robustness of llm agents on harmful
tasks,” in _ICLR_, 2024.

[146] T. Xie, D. Zhang, J. Chen, X. Li, S. Zhao, R. Cao, J. H. Toh, Z. Cheng,
D. Shin, F. Lei _et al._, “Osworld: Benchmarking multimodal agents
for open-ended tasks in real computer environments,” _NeurIPS_,
vol. 37, pp. 52 040–52 094, 2025.

[147] K. Xu, Y. Kordi, T. Nayak, A. Asija, Y. Wang, K. Sanders,
A. Byerly, J. Zhang, B. Van Durme, and D. Khashabi, “Tur [k]
ingbench: A challenge benchmark for web agents,” _arXiv preprint_
_arXiv:2403.11905_, 2024.

[148] R. Kapoor, Y. P. Butala, M. Russak, J. Y. Koh, K. Kamble, W. AlShikh, and R. Salakhutdinov, “Omniact: A dataset and benchmark
for enabling multimodal generalist autonomous agents for desktop and web,” in _ECCV_ . Springer, 2024, pp. 161–178.

[149] J. Yang, S. Liu, H. Guo, Y. Dong, X. Zhang, S. Zhang, P. Wang,
Z. Zhou, B. Xie, Z. Wang _et al._, “Egolife: Towards egocentric life
assistant,” _arXiv preprint arXiv:2503.03803_, 2025.

[150] J. Wang, M. Zerun, Y. Li, S. Zhang, C. Chen, K. Chen, and X. Le,
“Gta: a benchmark for general tool agents,” in _NeurIPS_, 2024.

[151] F. F. Xu, Y. Song, B. Li, Y. Tang, K. Jain, M. Bao, Z. Z. Wang,
X. Zhou, Z. Guo, M. Cao _et al._, “Theagentcompany: benchmarking
llm agents on consequential real world tasks,” _arXiv preprint_
_arXiv:2412.14161_, 2024.

[152] R. Barbarroxa, L. Gomes, and Z. Vale, “Benchmarking large
language models for multi-agent systems: A comparative analysis
of autogen, crewai, and taskweaver,” in _International Conference on_
_Practical Applications of Agents and Multi-Agent Systems_ . Springer,
2024, pp. 39–48.

[153] Z. Li, X. Wu, H. Du, H. Nghiem, and G. Shi, “Benchmark
evaluations, applications, and challenges of large vision language
models: A survey,” _arXiv preprint arXiv:2501.02189_, 2025.

[154] M. Kenney, “Ml research benchmark,” _arXiv_ _preprint_
_arXiv:2410.22553_, 2024.

[155] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,
C. Hesse, S. Jain, V. Kosaraju, W. Saunders, X. Jiang, K. Cobbe,
T. Eloundou, G. Krueger, K. Button, M. Knight, B. Chess, and
J. Schulman, “Webgpt: Browser-assisted question-answering with
human feedback,” 2022.

[156] Y. Qin, Z. Cai, D. Jin, L. Yan, S. Liang, K. Zhu, Y. Lin, X. Han,
N. Ding, H. Wang, R. Xie, F. Qi, Z. Liu, M. Sun, and J. Zhou,
“WebCPM: Interactive web search for Chinese long-form question
answering,” in _ACL_, A. Rogers, J. Boyd-Graber, and N. Okazaki,
Eds. Toronto, Canada: Association for Computational Linguistics,
Jul. 2023, pp. 8968–8988.

[157] K. Zhang, H. Zhang, G. Li, J. Li, Z. Li, and Z. Jin, “Toolcoder:
Teach code generation models to use api search tools,” 2023.

[158] S. Robertson, H. Zaragoza _et al._, “The probabilistic relevance
framework: Bm25 and beyond,” _Foundations and Trends® in_
_Information Retrieval_, vol. 3, no. 4, pp. 333–389, 2009.

[159] B. Lei, Y. Li, and Q. Chen, “Autocoder: Enhancing code large
language model with AIEV-INSTRUCT,” 2024.

[160] J. Gehring, K. Zheng, J. Copet, V. Mella, Q. Carbonneaux, T. Cohen,
and G. Synnaeve, “Rlef: Grounding code llms in execution
feedback with reinforcement learning,” 2025.


[161] X. Wang, Y. Chen, L. Yuan, Y. Zhang, Y. Li, H. Peng, and H. Ji,
“Executable code actions elicit better llm agents,” _ArXiv_, vol.
abs/2402.01030, 2024.

[162] T. Schick, J. Dwivedi-Yu, R. Dess`ı, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom, “Toolformer:
Language models can teach themselves to use tools,” _Advances in_
_Neural Information Processing Systems_, vol. 36, pp. 68 539–68 551,
2023.

[163] B. Paranjape, S. Lundberg, S. Singh, H. Hajishirzi, L. Zettlemoyer,
and M. T. Ribeiro, “Art: Automatic multi-step reasoning and tooluse for large language models,” _arXiv preprint arXiv:2303.09014_,
2023.

[164] Y. Song, W. Xiong, D. Zhu, W. Wu, H. Qian, M. Song, H. Huang,
C. Li, K. Wang, R. Yao, Y. Tian, and S. Li, “Restgpt: Connecting
large language models with real-world restful apis,” 2023.

[165] A. Saha, L. Mandal, B. Ganesan, S. Ghosh, R. Sindhgatta, C. Eberhardt, D. Debrunner, and S. Mehta, “Sequential API function
calling using GraphQL schema,” in _EMNLP_, Y. Al-Onaizan,
M. Bansal, and Y.-N. Chen, Eds., Miami, Florida, USA, Nov. 2024,
pp. 19 452–19 458.

[166] L. Yuan, Y. Chen, X. Wang, Y. R. Fung, H. Peng, and H. Ji, “Craft:
Customizing llms by creating and retrieving from specialized
toolsets,” _arXiv preprint arXiv:2309.17428_, 2023.

[167] C. Qian, C. Xiong, Z. Liu, and Z. Liu, “Toolink: Linking toolkit
creation and using through chain-of-solving on open-source
model,” in _NAACL_, 2024, pp. 831–854.

[168] C. Qian, C. Han, Y. Fung, Y. Qin, Z. Liu, and H. Ji, “CREATOR:
Tool creation for disentangling abstract and concrete reasoning of
large language models,” in _EMNLP Findings_, H. Bouamor, J. Pino,
and K. Bali, Eds., Singapore, Dec. 2023, pp. 6922–6939.

[169] T. Cai, X. Wang, T. Ma, X. Chen, and D. Zhou, “Large language
models as tool makers,” 2024.

[[170] “LangChain,” 1 2023. [Online]. Available: https://github.com/](https://github.com/langchain-ai/langchain)
[langchain-ai/langchain](https://github.com/langchain-ai/langchain)

[[171] “LlamaIndex,” 11 2022. [Online]. Available: https://github.com/](https://github.com/jerryjliu/llama_index)
[jerryjliu/llama index](https://github.com/jerryjliu/llama_index)

[172] “Dify,” 5 2023. [Online]. Available: [https://github.com/](https://github.com/langgenius/dify)
[langgenius/dify](https://github.com/langgenius/dify)

[[173] “Ollama,” 7 2023. [Online]. Available: https://github.com/](https://github.com/ollama/ollama)
[ollama/ollama](https://github.com/ollama/ollama)

[[174] “MCP Agent,” 2 2025. [Online]. Available: https://github.com/](https://github.com/lastmile-ai/mcp-agent)
[lastmile-ai/mcp-agent](https://github.com/lastmile-ai/mcp-agent)

[175] A. Li, Y. Zhou, V. C. Raghuram, T. Goldstein, and M. Goldblum,
“Commercial llm agents are already vulnerable to simple yet
dangerous attacks,” _arXiv preprint arXiv:2502.08586_, 2025.

[176] W. Zhang, K. Tang, H. Wu, M. Wang, Y. Shen, G. Hou, Z. Tan,
P. Li, Y. Zhuang, and W. Lu, “Agent-pro: Learning to evolve
via policy-level reflection and optimization,” in _ACL_, 2024, pp.
5348–5375.

[177] L. Mo, Z. Liao, B. Zheng, Y. Su, C. Xiao, and H. Sun, “A trembling
house of cards? mapping adversarial attacks against language
agents,” _arXiv preprint arXiv:2402.10196_, 2024.

[178] E. Debenedetti, J. Zhang, M. Balunovic, L. Beurer-Kellner, M. Fischer, and F. Tramer, “Agentdojo: A dynamic environment to
evaluate prompt injection attacks and defenses for llm agents,” in
_NeurIPS_, vol. 37, 2024, pp. 82 895–82 920.

[179] C. H. Wu, J. Y. Koh, R. Salakhutdinov, D. Fried, and A. Raghunathan, “Adversarial attacks on multimodal agents,” _arXiv preprint_
_arXiv:2406.12814_, 2024.

[180] L.-b. Ning, S. Wang, W. Fan, Q. Li, X. Xu, H. Chen, and F. Huang,
“Cheatagent: Attacking llm-empowered recommender systems via
llm agent,” in _KDD_, 2024, pp. 2284–2295.

[181] W. Yu, K. Hu, T. Pang, C. Du, M. Lin, and M. Fredrikson,
“Infecting llm agents via generalizable adversarial attack,” in
_NeurIPS Workshop_, 2024.

[182] G. Lin and Q. Zhao, “Large language model sentinel: Llm agent
for adversarial purification,” _arXiv preprint arXiv:2405.20770_, 2024.

[183] S. Chern, Z. Fan, and A. Liu, “Combating adversarial attacks with
multi-agent debate,” _arXiv preprint arXiv:2401.05998_, 2024.

[184] X. Wang, J. Peng, K. Xu, H. Yao, and T. Chen, “Reinforcement
learning-driven llm agent for automated attacks on llms,” in _ACL_
_Findings_, 2024, pp. 170–177.

[185] Y. Dong, Z. Li, X. Meng, N. Yu, and S. Guo, “Jailbreaking
text-to-image models with llm-based agents,” _arXiv preprint_
_arXiv:2408.00523_, 2024.



23


[186] X. Chen, Y. Nie, W. Guo, and X. Zhang, “When llm meets
drl: Advancing jailbreaking efficiency via drl-guided search,” in
_NeurIPS_, 2024.

[187] Z. Lin, W. Ma, M. Zhou, Y. Zhao, H. Wang, Y. Liu, J. Wang, and
L. Li, “Pathseeker: Exploring llm security vulnerabilities with a
reinforcement learning-based jailbreak approach,” _arXiv preprint_
_arXiv:2409.14177_, 2024.

[188] Y. Zeng, Y. Wu, X. Zhang, H. Wang, and Q. Wu, “Autodefense:
Multi-agent llm defense against jailbreak attacks,” _arXiv preprint_
_arXiv:2403.04783_, 2024.

[189] S. Barua, M. Rahman, M. J. Sadek, R. Islam, S. Khaled, and A. Kabir,
“Guardians of the agentic system: Preventing many shots jailbreak
with agentic system,” _arXiv preprint arXiv:2502.16750_, 2025.

[190] Z. Ni, H. Wang, and H. Wang, “Shieldlearner: A new paradigm for
jailbreak attack defense in llms,” _arXiv preprint arXiv:2502.13162_,
2025.

[191] P. Zhu, Z. Zhou, Y. Zhang, S. Yan, K. Wang, and S. Su, “Demonagent: Dynamically encrypted multi-backdoor implantation attack
on llm-based agent,” _arXiv preprint arXiv:2502.12575_, 2025.

[192] W. Yang, X. Bi, Y. Lin, S. Chen, J. Zhou, and X. Sun, “Watch out for
your agents! investigating backdoor threats to llm-based agents,”
_NeurIPS_, vol. 37, pp. 100 938–100 964, 2025.

[193] Y. Wang, D. Xue, S. Zhang, and S. Qian, “Badagent: Inserting
and activating backdoor attacks in llm agents,” in _ACL_, 2024, pp.
9811–9827.

[194] T. Tong, F. Wang, Z. Zhao, and M. Chen, “Badjudge: Backdoor
vulnerabilities of llm-as-a-judge,” in _ICLR_, 2025.

[195] Z. Guo and R. Tourani, “Darkmind: Latent chain-of-thought
backdoor in customized llms,” _arXiv preprint arXiv:2501.18617_,
2025.

[196] Z. Zhou, Z. Li, J. Zhang, Y. Zhang, K. Wang, Y. Liu, and
Q. Guo, “Corba: Contagious recursive blocking attacks on multiagent systems based on large language models,” _arXiv preprint_
_arXiv:2502.14529_, 2025.

[197] P. He, Y. Lin, S. Dong, H. Xu, Y. Xing, and H. Liu, “Red-teaming llm
multi-agent systems via communication attacks,” _arXiv preprint_
_arXiv:2502.14847_, 2025.

[198] M. Yu, S. Wang, G. Zhang, J. Mao, C. Yin, Q. Liu, Q. Wen, K. Wang,
and Y. Wang, “Netsafe: Exploring the topological safety of multiagent networks,” _arXiv preprint arXiv:2410.15686_, 2024.
