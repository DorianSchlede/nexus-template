<!-- Source: 15-AgentSurvey-2503.21460.pdf | Chunk 10/10 -->

[269] A. M. Bran, S. Cox, O. Schilter, C. Baldassari, A. D. White,
and P. Schwaller, “Chemcrow: Augmenting large-language
models with chemistry tools,” 2023. [Online]. Available:
[https://arxiv.org/abs/2304.05376](https://arxiv.org/abs/2304.05376)

[270] A. Ghafarollahi and M. J. Buehler, “Atomagents: Alloy
design and discovery through physics-aware multi-modal
multi-agent artificial intelligence,” 2024. [Online]. Available:
[https://arxiv.org/abs/2407.10022](https://arxiv.org/abs/2407.10022)

[271] D. Kostunin, V. Sotnikov, S. Golovachev, and A. Strube, “Ai
agents for ground-based gamma astronomy,” 2025. [Online].
[Available: https://arxiv.org/abs/2503.00821](https://arxiv.org/abs/2503.00821)

[272] B. Qi, K. Zhang, K. Tian, H. Li, Z.-R. Chen, S. Zeng, E. Hua,
H. Jinfang, and B. Zhou, “Large language models as biomedical
hypothesis generators: A comprehensive evaluation,” 2024.

[[Online]. Available: https://arxiv.org/abs/2407.08940](https://arxiv.org/abs/2407.08940)

[273] Y. Roohani, A. Lee, Q. Huang, J. Vora, Z. Steinhart, K. Huang,
A. Marson, P. Liang, and J. Leskovec, “Biodiscoveryagent: An
ai agent for designing genetic perturbation experiments,” _arXiv_
_preprint arXiv:2405.17631_, 2024.

[274] Z. Wang, Q. Jin, C.-H. Wei, S. Tian, P.-T. Lai, Q. Zhu, C.-P. Day,
C. Ross, and Z. Lu, “Geneagent: Self-verification language agent
for gene set knowledge discovery using domain databases,” 2024.

[[Online]. Available: https://arxiv.org/abs/2405.16205](https://arxiv.org/abs/2405.16205)

[275] M. Xiao, W. Zhang, X. Huang, H. Zhu, M. Wu, X. Li, and Y. Zhou,
“Knowledge-guided biomarker identification for label-free singlecell rna-seq data: A reinforcement learning perspective,” _arXiv_
_preprint arXiv:2501.04718_, 2025.

[276] Y. Sun, Y. Zhang, Y. Si, C. Zhu, Z. Shui, K. Zhang, J. Li,
X. Lyu, T. Lin, and L. Yang, “Pathgen-1.6m: 1.6 million pathology
image-text pairs generation through multi-agent collaboration,”
[2024. [Online]. Available: https://arxiv.org/abs/2407.00203](https://arxiv.org/abs/2407.00203)



25


[277] X. Cai, C. Wang, Q. Long, Y. Zhou, and M. Xiao, “Knowledge hierarchy guided biological-medical dataset distillation for domain
llm training,” _arXiv preprint arXiv:2501.15108_, 2025.

[278] Z. Chen, C. Hu, M. Wu, Q. Long, X. Wang, Y. Zhou, and
M. Xiao, “Genesum: Large language model-based gene summary
extraction,” in _2024 IEEE International Conference on Bioinformatics_
_and Biomedicine (BIBM)_ . IEEE, 2024, pp. 1438–1443.

[279] K. Keshavjee, J. Bosomworth, J. Copen, J. Lai, B. Kucukyazici,
R. Lilani, and A. M. Holbrook, “Best practices in emr implementation: a systematic review,” in _AMIA Annual Symposium Proceedings_,
vol. 2006, 2006, p. 982.

[280] X. Ye, M. Xiao, Z. Ning, W. Dai, W. Cui, Y. Du, and Y. Zhou,
“Needed: Introducing hierarchical transformer to eye diseases
diagnosis,” in _Proceedings of the 2023 SIAM International Conference_
_on Data Mining (SDM)_ . SIAM, 2023, pp. 667–675.

[281] J. Li, Y. Lai, W. Li, J. Ren, M. Zhang, X. Kang, S. Wang, P. Li, Y.-Q.
Zhang, W. Ma _et al._, “Agent hospital: A simulacrum of hospital
with evolvable medical agents,” _arXiv preprint arXiv:2405.02957_,
2024.

[282] W. Yan, H. Liu, T. Wu, Q. Chen, W. Wang, H. Chai, J. Wang,
W. Zhao, Y. Zhang, R. Zhang _et al._, “Clinicallab: Aligning agents
for multi-departmental clinical diagnostics in the real world,”
_arXiv preprint arXiv:2406.13890_, 2024.

[283] H. Yu, J. Zhou, L. Li, S. Chen, J. Gallifant, A. Shi, X. Li,
W. Hua, M. Jin, G. Chen, Y. Zhou, Z. Li, T. Gupte, M.-L. Chen,
Z. Azizi, Y. Zhang, T. L. Assimes, X. Ma, D. S. Bitterman,
L. Lu, and L. Fan, “Aipatient: Simulating patients with ehrs
and llm powered agentic workflow,” 2024. [Online]. Available:
[https://arxiv.org/abs/2409.18924](https://arxiv.org/abs/2409.18924)

[284] N. Sharma, “Cxr-agent: Vision-language models for chest x-ray
interpretation with uncertainty aware radiology reporting,” _arXiv_
_preprint arXiv:2407.08811_, 2024.

[285] A. Fallahpour, J. Ma, A. Munim, H. Lyu, and B. Wang, “Medrax:
Medical reasoning agent for chest x-ray,” 2025. [Online]. Available:
[https://arxiv.org/abs/2502.02673](https://arxiv.org/abs/2502.02673)

[286] R. W. Lee, K. H. Lee, J. S. Yun, M. S. Kim, and H. S. Choi,
“Comparative analysis of m4cxr, an llm-based chest x-ray report
generation model, and chatgpt in radiological interpretation,”
_Journal of Clinical Medicine_, vol. 13, no. 23, p. 7057, 2024.

[287] X. Feng, Y. Luo, Z. Wang, H. Tang, M. Yang, K. Shao, D. Mguni,
Y. Du, and J. Wang, “Chessgpt: Bridging policy learning and
language modeling,” in _NeurIPS_, 2023, pp. 7216–7262.

[288] T. Carta, C. Romac, T. Wolf, S. Lamprier, O. Sigaud, and P.Y. Oudeyer, “Grounding large language models in interactive
environments with online reinforcement learning,” in _ICML_, 2023,
pp. 3676–3713.

[289] A. Zhu, L. Martin, A. Head, and C. Callison-Burch, “Calypso:
Llms as dungeon master’s assistants,” in _AAAI_, 2023, pp. 380–390.

[290] D. Chen, H. Wang, Y. Huo, Y. Li, and H. Zhang, “Gamegpt: Multiagent collaborative framework for game development,” _arXiv_
_preprint arXiv:2310.08067_, 2023.

[291] Y. Sun, Z. Li, K. Fang, C. H. Lee, and A. Asadipour, “Language as
reality: a co-creative storytelling game experience in 1001 nights
using generative ai,” in _AAAI_, 2023, pp. 425–434.

[292] N. Li, C. Gao, M. Li, Y. Li, and Q. Liao, “Econagent: large language model-empowered agents for simulating macroeconomic
activities,” _ACL_, pp. 15 523–15 536, 2024.

[293] Y. Li, Y. Yu, H. Li, Z. Chen, and K. Khashanah, “Tradinggpt:
Multi-agent system with layered memory and distinct characters for enhanced financial trading performance,” _arXiv preprint_
_arXiv:2309.03736_, 2023.

[294] Q. Zhao, J. Wang, Y. Zhang, Y. Jin, K. Zhu, H. Chen, and X. Xie,
“Competeai: Understanding the competition dynamics in large
language model-based agents,” in _ICML_, 2024, pp. 61 092–61 107.

[295] Z. Ma, Y. Mei, and Z. Su, “Understanding the benefits and challenges of using large language model-based conversational agents
for mental well-being support,” in _AMIA Annual Symposium_
_Proceedings_, vol. 2023, 2024, p. 1105.

[296] J. Zhang, X. Xu, N. Zhang, R. Liu, B. Hooi, and S. Deng, “Exploring
collaboration mechanisms for llm agents: A social psychology
view,” in _ACL_, 2024, pp. 14 544–14 607.

[297] G. V. Aher, R. I. Arriaga, and A. T. Kalai, “Using large language
models to simulate multiple humans and replicate human subject
studies,” in _ICML_, 2023, pp. 337–371.

[298] R. Liu, R. Yang, C. Jia, G. Zhang, D. Zhou, A. M. Dai, D. Yang,
and S. Vosoughi, “Training socially aligned language models on
simulated social interactions,” in _ICLR_, 2024.


[299] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li,
“S3: Social-network simulation system with large language modelempowered agents,” _arXiv preprint arXiv:2307.14984_, 2023.

[300] Y. Dong, X. Jiang, Z. Jin, and G. Li, “Self-collaboration code
generation via chatgpt,” _ACM Transactions on Software Engineering_
_and Methodology_, vol. 33, no. 7, pp. 1–38, 2024.

[301] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun,
“Chatdev: Communicative agents for software development,” in
_ACL_, 2024, pp. 15 174–15 186.

[302] A. Zhang, Y. Chen, L. Sheng, X. Wang, and T.-S. Chua, “On
generative agents in recommendation,” in _SIGIR_, 2024, pp. 1807–
1817.

[303] J. Zhang, Y. Hou, R. Xie, W. Sun, J. McAuley, W. X. Zhao, L. Lin,
and J.-R. Wen, “Agentcf: Collaborative learning with autonomous
language agents for recommender systems,” in _WWW_, 2024, pp.
3679–3689.

[304] Z. Wang, Y. Yu, W. Zheng, W. Ma, and M. Zhang, “Macrec: A
multi-agent collaboration framework for recommendation,” in
_SIGIR_, 2024, pp. 2760–2764.

[305] Y. Wang, Z. Jiang, Z. Chen, F. Yang, Y. Zhou, E. Cho, X. Fan,
X. Huang, Y. Lu, and Y. Yang, “Recmind: Large language
model powered agent for recommendation,” _arXiv preprint_
_arXiv:2308.14296_, 2023.

[306] C. Qian, Z. Xie, Y. Wang, W. Liu, Y. Dang, Z. Du, W. Chen, C. Yang,
Z. Liu, and M. Sun, “Scaling large-language-model-based multiagent collaboration,” _arXiv:2406.07155_, 2024.

[307] C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, and
Z. Liu, “Chateval: Towards better llm-based evaluators through
multi-agent debate,” _arXiv preprint arXiv:2308.07201_, 2023.

[308] O. F. Rana and K. Stout, “What is scalability in multi-agent
systems?” in _Proceedings of the fourth international conference on_
_Autonomous agents_, 2000, pp. 56–63.

[309] R. Deters, “Scalable multi-agent systems,” in _Proceedings of the_
_2001 joint ACM-ISCOPE conference on Java Grande_, 2001, p. 182.

[310] G. Verma, R. Kaur, N. Srishankar, Z. Zeng, T. Balch, and
M. Veloso, “Adaptagent: Adapting multimodal web agents with
few-shot learning from human demonstrations,” _arXiv preprint_
_arXiv:2411.13451_, 2024.

[311] Y. Jin, M. Choi, G. Verma, J. Wang, and S. Kumar, “Mm-soc:
Benchmarking multimodal large language models in social media
platforms,” in _ACL Findings_, 2024.

[312] Z. Yao, Z. Tang, J. Lou, P. Shen, and W. Jia, “Velo: A vector
database-assisted cloud-edge collaborative llm qos optimization
framework,” in _ICWS_ . IEEE, 2024, pp. 865–876.

[313] X. Cheng, X. Wang, X. Zhang, T. Ge, S.-Q. Chen, F. Wei, H. Zhang,
and D. Zhao, “xrag: Extreme context compression for retrievalaugmented generation with one token,” in _NeurIPS_, 2024.

[314] Y. Jin, M. Chandra, G. Verma, Y. Hu, M. De Choudhury, and
S. Kumar, “Better to ask in english: Cross-lingual evaluation of
large language models for healthcare queries,” in _WWW_, 2024, pp.
2627–2638.

[315] V. Agarwal, Y. Jin, M. Chandra, M. De Choudhury, S. Kumar, and
N. Sastry, “Medhalu: Hallucinations in responses to healthcare
queries by large language models,” _arXiv:2409.19492_, 2024.

[316] C. Lu, C. Lu, R. T. Lange, J. Foerster, J. Clune, and D. Ha,
“The ai scientist: Towards fully automated open-ended scientific
discovery,” _arXiv preprint arXiv:2408.06292_, 2024.

[317] G. Agrawal, T. Kumarage, Z. Alghamdi, and H. Liu, “Can
knowledge graphs reduce hallucinations in llms?: A survey,” in
_NAACL_, 2024, pp. 3947–3960.

[318] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,
C. Hesse, S. Jain, V. Kosaraju, W. Saunders _et al._, “Webgpt: Browserassisted question-answering with human feedback,” _arXiv preprint_
_arXiv:2112.09332_, 2021.

[319] T. Gao, H. Yen, J. Yu, and D. Chen, “Enabling large language
models to generate text with citations,” in _EMNLP_, 2024.

[320] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang,
A. Chowdhery, and D. Zhou, “Self-consistency improves chain of
thought reasoning in language models,” in _ICLR_, 2023.

[321] S. Zhou, U. Alon, S. Agarwal, and G. Neubig, “Codebertscore:
Evaluating code generation with pretrained models of code,” in
_EMNLP_, 2023, pp. 13 921–13 937.

[322] Z. Wang, S. Zhou, D. Fried, and G. Neubig, “Execution-based
evaluation for open-domain code generation,” in _EMNLP_, 2023,
pp. 1271–1290.



26


[323] K. Zhu, J. Chen, J. Wang, N. Z. Gong, D. Yang, and X. Xie, “Dyval:
Dynamic evaluation of large language models for reasoning tasks,”
in _ICLR_, 2024.

[324] K. Zhu, J. Wang, Q. Zhao, R. Xu, and X. Xie, “Dynamic evaluation
of large language models by meta probing agents,” in _ICML_ .
PMLR, 2024, pp. 62 599–62 617.

[325] X. Yi, J. Yao, X. Wang, and X. Xie, “Unpacking the ethical value
alignment in big models,” _arXiv preprint arXiv:2310.17551_, 2023.

[326] X. Wang, L. Jiang, J. Hernandez-Orallo, D. Stillwell, L. Sun, F. Luo,
and X. Xie, “Evaluating general-purpose ai with psychometrics,”
_arXiv preprint arXiv:2310.16379_, 2023.

[327] Y. Wu, Z. Jiang, A. Khan, Y. Fu, L. Ruis, E. Grefenstette, and
T. Rocktaschel, “Chatarena: Multi-agent language game environ-¨
ments for large language models,” 2023.

[328] J. Yao, X. Yi, Y. Gong, X. Wang, and X. Xie, “Value fulcra: Mapping
large language models to the multidimensional spectrum of basic
human value,” in _NAACL_, 2024, pp. 8754–8777.

[329] V. C. Nguyen, M. Taher, D. Hong, V. K. Possobom, V. T. Gopalakrishnan, E. Raj, Z. Li, H. J. Soled, M. L. Birnbaum, S. Kumar
_et al._, “Do large language models align with core mental health
counseling competencies?” in _NAACL_, 2025.


