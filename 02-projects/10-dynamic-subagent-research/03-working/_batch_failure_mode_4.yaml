---
batch_id: "failure_mode_4"
field: failure_mode
extracted_at: "2025-12-29T00:00:00Z"
chunks_read: 8
patterns_found: 18
---

patterns:
  # From 18-HallucinationSurvey-2509.18970 Chunk 3
  - name: "Information Loss Through Compression"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:22-30)"
    quote: "this process is susceptible to Information Compression issues, where the generated summaries may be overly general, omit crucial details, or introduce distortions"
    description: "Failure mode where memory writing operations compress information excessively, resulting in loss of crucial details. When agents summarize historical information for storage, the abstraction process can introduce distortions or omit key semantic details that are needed for accurate subsequent decisions."

  - name: "Erroneous Message Propagation"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:45-51)"
    quote: "LLMs are prone to the well-known Factuality and Faithfulness Hallucinations, some agents may produce messages containing inaccurate facts, misinterpretations of shared knowledge, or misleading inferences"
    description: "Failure mode in multi-agent communication where messages generated by LLMs contain hallucinated content. This propagates through the system as agents exchange incorrect facts, misinterpretations, or misleading inferences, causing downstream communication hallucinations."

  - name: "Content Redundancy Overload"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:52-55)"
    quote: "Content Redundancy is also an important cause, where agents generate unnecessary or repetitive content that obscures critical signals, increases cognitive load"
    description: "Failure mode where agents generate redundant or repetitive content that obscures critical signals. This increases cognitive load and can lead to redundant task execution steps that manifest as logical errors in the workflow."

  - name: "Uncoordinated Protocol Failure"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:61-65)"
    quote: "Without a unified and effective protocol, agents may 'talk past each other', leading to communication hallucinations"
    description: "Failure mode where lack of unified communication protocols causes agents to misinterpret each other's messages. Agents may encounter information loss and information overload due to asynchronous scheduling, leading to hallucinatory outputs."

  - name: "Message Format Ambiguity"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:72-78)"
    quote: "Current LLM-based agents predominantly rely on the format of natural language which often introduces instruction ambiguity...LLM-based MAS demands a robust Fault-tolerant Design"
    description: "Failure mode where natural language message formats introduce instruction ambiguity. Without structured formats (e.g., JSON) and fault-tolerant design with confirmation conditions and synchronization constraints, agents make erroneous decisions caused by message loss or delays."

  - name: "Network Topology Staleness"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 3:79-97)"
    quote: "When network updates are ineffective, they can induce communication hallucinations due to inconsistent or outdated inter-agent connections"
    description: "Failure mode where network topology updates fail to accurately reflect agents' current relevance or expertise. Messages may be routed to inappropriate recipients, leading to misunderstandings or redundant reasoning across the multi-agent system."

  # From 18-HallucinationSurvey-2509.18970 Chunk 4
  - name: "Hallucinatory Accumulation"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 4:153-160)"
    quote: "agent decision-making is inherently a multi-step and sequential process, in which hallucinations can accumulate and amplify over time...hallucinations may initially appear as minor issues, but their iterative accumulation can ultimately lead to severe consequences"
    description: "Failure mode where small hallucinations compound across multiple agent steps. Minor errors in early steps propagate and amplify through the sequential decision-making process, ultimately leading to severe consequences that are much harder to detect and mitigate than single-step errors."

  - name: "Full-Chain Error Propagation"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 4:170-182)"
    quote: "agent hallucinations are far more complex, involving full-chain error propagation across multiple interdependent components...hallucinations may arise at any stage of the decision-making pipeline and often exhibit complex characteristics"
    description: "Failure mode where errors propagate across the entire agent processing chain. Unlike simple textual generation errors, agent hallucinations involve interdependent components with hallucinatory accumulation and inter-module dependency, making source localization extremely difficult."

  # From 18-HallucinationSurvey-2509.18970 Chunk 8
  - name: "Echo Chamber Effect"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 8:192-205)"
    quote: "Initially, the client states that they require a 'code review'. As the message passes along a chain of agents, the first agent mishears it as 'cold review', the second relays it as 'gold review'"
    description: "Failure mode demonstrating telephone game style message distortion in multi-agent communication. Minor mis-hearings or misinterpretations are amplified through multiple rounds of transmission until the information becomes completely detached from the original meaning."

  - name: "Tool Selection Hallucination"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 8:174-182)"
    quote: "The agent incorrectly calls a non-existent tool named 'get kyoto travel info', whereas the correct tool in the system should be 'recommend tourist spots'"
    description: "Failure mode where agents invent plausible-sounding but non-existent APIs or function names when selecting external tools. This leads to tool selection hallucinations that cause complete task failure when the fabricated tool cannot be executed."

  - name: "Tool Parameter Hallucination"
    chunk_ref: "18-HallucinationSurvey-2509.18970 (Chunk 8:184-190)"
    quote: "the agent selects the correct tool but arbitrarily appends an extra parameter language='English', which is not part of the tool's actual specification"
    description: "Failure mode where even with correct tool selection, the agent hallucinates at the parameter level. Agents may engage in hallucinatory argument extension, adding parameters that are not part of the tool specification, causing calls to fail or produce unintended behavior."

  # From 19-HalMit-2507.15903 Chunk 1
  - name: "Generalization Bound Violation"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:55-58)"
    quote: "Hallucinations typically arise when the generated content significantly exceeds the generalization bounds of the agent. If a generated response lies outside the bound, it is highly likely that this response is hallucinated"
    description: "Failure mode where agent responses exceed the learned generalization boundary. When queries fall outside the agent's domain-specific competence boundary, the agent produces hallucinated responses that are flagged as potential errors requiring mitigation."

  - name: "Domain-Specific Boundary Uncertainty"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:308-316)"
    quote: "the semantic entropy values of agent responses vary substantially across application domains, with noticeable differences in both medians and variances...no universal generalization bound can be established across all domains"
    description: "Failure mode where single threshold-based detection fails due to domain variation. Semantic entropy varies significantly across domains, making fixed thresholds insufficient for detecting hallucinations. High-entropy yet non-hallucinatory responses (and vice versa) require domain-aware detection."

  # From 19-HalMit-2507.15903 Chunk 2
  - name: "Boundary Proximity Detection"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 2:381-405)"
    quote: "If the query closely resembles the retrieved records in the vector base, it is considered near the boundary, and the response corresponding to the input query is flagged as a potential hallucination"
    description: "Failure mode detection via vector database comparison. When input queries are semantically similar to known boundary points stored in the vector database, the response is flagged as potentially hallucinated. Centroid calculation of similar items enables detection of queries beyond the generalization bound."

  # From 22-PROV-AGENT-2508.02866 Chunk 1
  - name: "Error Propagation Through Agent Chain"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:21-25)"
    quote: "agents can hallucinate or reason incorrectly, propagating errors when one agent's output becomes another's input. Thus, assuring that agents' actions are transparent, traceable, reproducible, and reliable is critical"
    description: "Failure mode where hallucinated outputs from one agent become inputs for subsequent agents. Without provenance tracking, errors propagate through the workflow chain, compounding mistakes and making it difficult to assess the correctness of final results."

  - name: "Iterative Decision Loop Corruption"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:439-445)"
    quote: "because the agent relies on an LLM, there is a risk of hallucinated or incorrect outputs. Since each decision influences the next in this iterative loop, a single error may propagate across layers, potentially compromising downstream outputs"
    description: "Failure mode in iterative agentic workflows where decisions at iteration i influence iteration i+1. A single hallucinated decision propagates across subsequent layers, potentially corrupting all downstream outputs and requiring provenance tracking to identify the error source."

  # From 22-PROV-AGENT-2508.02866 Chunk 2
  - name: "Surprising Decision Traceability"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 2:111-122)"
    quote: "Given that a hallucination was identified when the agent was deciding on the scores for layer 2, after identifying the unexpected Agent_Decision_2, the query traces back to Agent_Tool_2"
    description: "Failure mode remediation pattern via provenance query. When a surprising/hallucinated agent decision is identified, the system traces back through the tool invocation and LLM interaction to retrieve the corresponding prompt and response for root cause analysis."

  # From 24-EffectiveCollab-2412.05449 Chunk 3
  - name: "Payload Corruption During Transmission"
    chunk_ref: "24-EffectiveCollab-2412.05449 (Chunk 3:200-217)"
    quote: "Reduces the likelihood of payload corruption during agent-to-agent transmission...Maintains formatting and structure of the payload across agent communications"
    description: "Failure mode where payloads (especially code blocks) are corrupted during agent-to-agent transmission. Without payload referencing mechanisms, large content blocks may lose formatting, structure, or become corrupted, requiring expensive token regeneration and degrading goal success rates by up to 23%."
