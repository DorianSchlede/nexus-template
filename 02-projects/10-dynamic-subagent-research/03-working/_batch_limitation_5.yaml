---
batch_id: "limitation_5"
field: limitation
extracted_at: "2025-12-29T12:00:00Z"
chunks_read: 9
patterns_found: 18
---

patterns:
  # From 19-HalMit-2507.15903 (Chunks 1-4)
  - name: "Black-Box Access Limitation"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:23-24)"
    quote: "the related approaches either depend on white-box access to LLMs or fail to accurately identify hallucinations"
    description: "Existing hallucination detection approaches have a fundamental limitation requiring white-box access to LLM internal states, which is not feasible for commercial, closed-source models. This prevents their application to large-scale commercial systems."

  - name: "Vacuous Bounds at Billion-Parameter Scale"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:60-61)"
    quote: "these bounds tend to become vacuous at the scale of billion-parameter models"
    description: "Theoretical generalization bounds derived for deep learning models become vacuous and non-applicable when applied to billion-parameter LLMs, limiting their utility for hallucination detection in modern large-scale agents."

  - name: "Semantic Space Complexity Limitation"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:63-64)"
    quote: "Given the vastness of the semantic space, the tightness of the existing generalization bounds remains difficult to establish"
    description: "The vast semantic space of natural language makes it extremely challenging to establish tight generalization bounds, limiting the precision of hallucination detection methods."

  - name: "Single Metric Threshold Insufficiency"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:318-322)"
    quote: "relying solely on a fixed threshold is insufficient. The presence of high-entropy yet potentially non-hallucinatory responses"
    description: "Semantic entropy alone with a fixed threshold is insufficient for hallucination detection due to outliers - high-entropy responses that are not hallucinations and vice versa, requiring more nuanced detection methods."

  - name: "Domain-Specific Bound Requirement"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:87-88)"
    quote: "Due to the complexity of the semantic space, deriving a universal generalization bound across all domains is extremely challenging"
    description: "No universal generalization bound can be established across all domains - hallucination patterns vary significantly across application domains, necessitating per-domain and per-agent boundary modeling."

  - name: "Local Loop Trap in Bound Exploration"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:92-94)"
    quote: "The bound exploration process may deviate from the true boundary and become trapped in local loops"
    description: "The generalization bound exploration can get trapped in local loops rather than converging to the true boundary, requiring sophisticated fractal sampling and reinforcement learning to accelerate convergence."

  - name: "Poorly Calibrated Confidence Estimates"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 1:71-76)"
    quote: "these black-box/gray-box approaches allow hallucination monitoring through output text or associated confidence scores, they are degraded by limited knowledge of LLMs and often poorly calibrated confidence estimates"
    description: "Black-box and gray-box approaches relying on output confidence scores suffer from poor calibration, leading to inaccurate hallucination monitoring and reduced effectiveness."

  - name: "White-Box Method Complexity and Computational Demand"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 4:50-53)"
    quote: "Requiring the access to internal states of LLMs to detect hallucinations, these methods not only suffer from high complexity and computational demand but also may not be feasible for commercial LLM software"
    description: "White-box hallucination detection methods analyzing internal model states have prohibitive computational complexity and are infeasible for commercial closed-source LLM systems."

  - name: "Slangy Dialogue Sensitivity"
    chunk_ref: "19-HalMit-2507.15903 (Chunk 3:175-178)"
    quote: "The only exception is the New York City topic, where SelfCheckGPT outperforms our method... This may be due to the miscellaneous slangy dialogues on this topic"
    description: "HalMit performs less well on topics with miscellaneous slangy dialogues (e.g., New York City), where alternative methods like SelfCheckGPT may be better suited."

  # From 22-PROV-AGENT-2508.02866 (Chunks 1-2)
  - name: "Hallucination Propagation in Agent Chains"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:21-23)"
    quote: "agents can hallucinate or reason incorrectly, propagating errors when one agent's output becomes another's input"
    description: "A critical limitation of agentic workflows is error propagation - when an agent hallucinates or reasons incorrectly, these errors cascade through the workflow as outputs become inputs to downstream agents, compounding inaccuracies."

  - name: "Non-Deterministic Workflow Behavior"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:80-84)"
    quote: "agentic workflows are non-deterministic, shaped by near real-time data, adaptive decisions, and evolving interactions"
    description: "Unlike traditional deterministic workflows, agentic workflows exhibit non-deterministic behavior with dynamic, cyclic patterns where agent outputs inform subsequent decisions, making provenance tracking and reproducibility challenging."

  - name: "Disconnected Agent Metadata"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:161-163)"
    quote: "these data are typically isolated from the rest of the workflow. This disconnection hinders the contextualization of agent interactions or understanding their downstream impact"
    description: "MCP-based agent frameworks record prompts and responses in isolation from the broader workflow, limiting the ability to contextualize agent interactions and trace their downstream impact."

  - name: "Traditional Provenance Model Inadequacy"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 1:165-168)"
    quote: "Existing provenance techniques lack explicit representations of key agent artifacts and their integration with the workflow. They typically model workflows as static graphs, missing the semantics needed to capture agentic behavior"
    description: "Existing provenance systems model workflows as static graphs and lack semantics for representing agent artifacts, dynamic decisions, and model-driven reasoning, limiting their applicability to agentic workflows."

  - name: "Iterative Error Propagation Risk"
    chunk_ref: "22-PROV-AGENT-2508.02866 (Chunk 2:42-45)"
    quote: "because the agent relies on an LLM, there is a risk of hallucinated or incorrect outputs. Since each decision influences the next in this iterative loop, a single error may propagate across layers"
    description: "In iterative agentic workflows with feedback loops, a single LLM hallucination or incorrect output can propagate across all subsequent iterations, potentially compromising all downstream outputs."

  # From 24-EffectiveCollab-2412.05449 (Chunks 1-3)
  - name: "Single-Agent Regression on Complex Tasks"
    chunk_ref: "24-EffectiveCollab-2412.05449 (Chunk 2:344-348)"
    quote: "In the single-agent setting, we observe an absolute regression of up to 37%. MAC allows each specialist agent to be provided with instructions for the specific subset of tasks... This specialized task assignment may not be achievable by a single agent"
    description: "Single agents exhibit significant performance regression (up to 37%) on complex tasks compared to multi-agent collaboration, struggling to manage the multitude of instructions required for complex tasks and showing more hallucination in tool parameters."

  - name: "Multi-Agent Latency Overhead"
    chunk_ref: "24-EffectiveCollab-2412.05449 (Chunk 2:391-396)"
    quote: "The Software domain consistently demonstrates higher latency metrics across all settings, with user-perceived turn latency reaching 168.73s compared to 31.46s for Travel"
    description: "Multi-agent collaboration introduces significant latency overhead, especially in complex domains like Software Development where user-perceived latency can reach 168.73 seconds per session - much higher than simpler domains."

  - name: "Benchmarking Complexity with Multiple Agents"
    chunk_ref: "24-EffectiveCollab-2412.05449 (Chunk 1:123-128)"
    quote: "Benchmarking single AI agents is already difficult and increasing the number of agents to benchmark only complicates the problem"
    description: "Multi-agent system evaluation is inherently more complex than single-agent benchmarking, as success definitions become unclear and multiple correct trajectories may exist that are not captured in ground truth."

  - name: "Static Evaluation Assumption Flaw"
    chunk_ref: "24-EffectiveCollab-2412.05449 (Chunk 1:366-371)"
    quote: "Prior single-agent benchmarking is more static where user inputs and follow-up responses are pre-defined... In reality, there may be multiple trajectories that enable the agent to fulfill user requests. If those trajectories are not captured in the gold-truth, then the agent is incorrectly penalized"
    description: "Static benchmarking that assumes single correct trajectory incorrectly penalizes agents that achieve goals through alternative valid paths, limiting evaluation accuracy for dynamic multi-agent systems."
