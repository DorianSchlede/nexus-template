<!-- Source: 18-Multi-Agent_Architecture_Taxonomy_LLM.pdf | Chunk 2/4 -->

task-management activity [77, 51, 41].


**–** `Task-Creation Agent` : Generating new tasks, which optionally also includes deriving tasks
by breaking down complex tasks.

**–** `Task-Prioritization Agent` : Assigning urgency or importance to tasks, which includes to
resolve the dependencies between the tasks.

**–** `Task-Execution Agent` : Ensuring efficient task completion.

    - `Domain Role Agents` : These agents are domain-specific experts. They excel in specialized roles
within the application domain [59], collaborating with peer role agents when needed. Examples
encompass roles in the software-development process, such as project manager, software architect,
developer, or QA engineer [28, 41].

    - `Technical Agents` : These agents are tech-savvies, typically tasked with interfacing with technical
platforms or development tools. Exemplary technical agents are represented by the `SQL Agent` for
database interactions or the `Python Agent` for developing Python scripts [14, 28].


An essential distinction to note is the variability in agent memory reliance. While some agents harness the
power of memory or an action log, e.g., for reflecting or planning tasks, others function devoid of these
recollections. Specifically, for technical aspects or actions that demand an unprejudiced or unbiased lens,
agents without memories are often preferred.


M **Concepts of Multi-Agent Collaboration.** As detailed above, each `Task-Management Activity`
involves a set of multiple collaborating `Agents` with different roles and competencies as well as driven by the
reasoning capabilities of utilized large language models (LLMs). This reasoning power enables the agents to
reflect, plan and process the assigned tasks [85, 59] as well as to interact with other agents [28]. In particular,
the `Agents` execute different kinds of `Actions` which in sum aim at achieving the user-prompted `Goal` . In
particular, the following sub-types of `Action` performed by the `Agents` can be distinguished:


    - `DecomposeTask` : Breaking down a task into multiple sub-tasks, optionally ordering and prioritizing
the tasks.

    - `Create Task` : Defining and generating new tasks.

    - `DelegateTask` : Delegating a task to another agent, addressed as `Receiver` .

    - `ExecuteTask` : Actually executing a given task.

    - `EvaluateResult` : Assessing the outcomes of a task.

    - `MergeResult` : Integrating or combining two or more task results.


Thereby, each `Action` can be part of another `Action`, which are, however, performed in the context of a certain
phase of the `Task-Management Activity` (see Fig. 4). Furthermore, each `Action` can include multiple
interactions with an LLM. The LLM’s reasoning capabilities are employed in multiple directions within an
`Action`, such as for reflecting memories and instructions, observing existing results, planning steps and/or
weighing options to proceed [85, 59, 28]. For this purpose, an `Agent Prompt` generated by an `Agent` and
triggered within a certain `Action` is send to and then processed by the LLM, which generates a `Response`
informing and/or guiding the next steps within the triggering action. An action might also include `Context`
`Utilization` . Before the LLM receives the `Agent Prompt`, it may undergo `Prompt Augmentation` [72].
This process can integrate additional specifics like the aspects or parts of the agent’s `Role` or `Memory`,


10


`Context Information` (e.g., data excerpts) acquired from previous `Context Utilization`, or chosen
`Prompt Templates` prepared and/or adapted for certain kinds of actions [14]. Such agent-driven _prompt_
_engineering_ is pivotal for LLM-powered multi-agent systems.


Direct collaborations involving two or more agents typically rely on prompt-driven communication sequences
or cycles. For instance, a `Delegate Task` action directed at a `receiver` agent might convey information,
place a request, initiate a query, or suggest a potential course of action. Subsequently, the `Evaluate Result`
action provides feedback by validating or refuting, and agreeing or disagreeing with the presented results [93].
A `Communication Protocol` provides a structured framework and methodology for agents’ collaboration,
guiding the execution of specific `Actions` by establishing rules and mechanisms for message exchanges
within the multi-agent network [73, 39, 93]. For instance, in LLM-powered multi-agent systems, the following
distinct protocols are observable, each built upon the basic mechanisms of an interplay between instruction
and execution, with optional subsequent result evaluation:


    - _Strict finite processes_ or execution chains with predefined action sequences, interactions between
predefined agents, and typically having a well-defined endpoint, which might represent the production
of a specific output or artefact [28].


    - _Dialogue cycles_ characterized by alternating `DelegateTask` and `ExecuteTask` actions between two
agents, creating a feedback loop of instruction and execution [41].


    - _Multi-cycle process frameworks_ with interactions between generic agent types, allowing for greater
dynamism in agent interactions [77, 51].


In all these exemplary cases, dedicated `Agent Types` are defined and coupled with the corresponding types
of `Action` . Further details are discussed in Section 5.2.


C **Concepts of Context Interaction.** For executing the task-related actions, the LLM-powered agents are
able to leverage specialized competencies and further information provided by additional `Context` which can
be distinguished into `Tools`, `Data`, and `Foundation Models` [70] (see Fig. 4).


    - `Tools` in terms of contextual resources for multi-agent systems can be categorized into the following
distinct groups:


**–** `Search and Analysis Tools` : These tools offer specialized capabilities for probing and
analyzing data, allowing agents to derive insights from vast information pools efficiently; such
as search engines for the web.

**–** `Execution Tools` : These are responsible for interfacing with and executing tasks within other
environments, like software applications, ensuring seamless operation across platforms.

**–** `Reasoning Tools` : Enhancing the capacity for logical thought, these tools bolster reasoning
capabilities in specialized areas such as computational intelligence. For instance, platforms like
WOLFRAM ALPHA empower agents with advanced computational skills.

**–** `Development Tools` : Tailored for software development endeavors, these tools streamline the
process of coding, debugging, and deploying solutions within the multi-agent framework.

**–** `Communication Tools` : These facilitate interactions with external entities by supporting
functionalities like sending and receiving emails, ensuring agents can effectively communicate
outside their native environments.


    - `Data` types in multi-agent architectures encompass:


**–** `Structured Text Data` : This refers to data that adheres to a defined model or schema, such
as data found in traditional relational databases. It offers predictability and is easily queryable.

**–** `Unstructured Text Data` : This data lacks a pre-defined model. An example is content found
within PDF documents. For optimal processing by LLMs, unstructured text is typically stored
in vector databases like PINECONE or CHROMA. These databases support semantic searches
through vector embeddings, bridging the gap between structured and unstructured data [47, 31].

**–** `Multimodal Data` : Beyond just text, this category encapsulates various formats including
videos, pictures, and audio. Specialized tools are employed to extract textual information from
these formats, making them amenable to processing by LLMs.

**–** `Domain-specific Data` : This data is tailored for particular sectors or areas of expertise.
Examples include proprietary company data or external data sources specific to fields like law or
medicine.


11


    - `Foundation Models` refer to expansive machine learning models trained on vast amounts of data.
These models are versatile, suitable for addressing a variety of tasks across different modalities such
as language, vision, and audio/speech, as well as combinations thereof [9]. Based on their modalities,
we categorize them as follows:


**–** `Natural Language Processing (NLP) Models` : These focus primarily on understanding
and generating human language. `LLMs` fall under this category of `NLP Models` . While there are
general-purpose LLMs available, specialized models tailored to specific domains and tasks also
exist, having been trained on corresponding niche data sets.

**–** `Computer Vision Models` : Aimed at processing and understanding images or videos.

**–** `Audio Models` : Specialized in processing and interpreting audio signals, including speech.

**–** `Multimodal Models` : Designed to handle multiple types of data simultaneously, combining
aspects of `NLP`, `Vision`, and `Audio` .


The machine learning landscape shows a multitude of specialized foundation models, with Large
Language Models (LLMs) standing out prominently [100]. Platforms like HUGGING FACE even
offer access to numerous models provided by the global machine learning community.


Access to LLMs, as well as associated resources such as tools, foundation models, and external data resources,
is typically facilitated through Application Programming Interfaces (APIs) [60]. The access details for these
APIs are integrated into the `Interaction Layer` . For instance, these details might be housed within a
dedicated `Library` module for streamlined interfacing (see above). Moreover, multiple of these contextual
resources can be combined within a single `Action` . For example, a certain expert tool could employ a selected
foundation model to analyze a given dataset. Finally, `Context Utilization` might involve the creation
or modification of `Artefacts` . Beyond mere artefact manipulation, this utilization can manifest as external
`Impact`, such as initiating external processes in other software applications or triggering workflows that
influence broader systems.


B **Concepts of Balancing Autonomy and Alignment.** Autonomy and alignment represent _cross-cutting_
_concerns_ [35], influencing various architectural concepts and mechanisms. Nevertheless, they also distinctly
materialize in specific concepts within our ontology model. _Alignment_, on the one hand, primarily manifests through the implementation of dedicated `Alignment Techniques` by the `System Architect` into the
system architecture of the `Interaction Layer` . These techniques might include foundational infrastructural approaches or procedural controls for system components, framed as constraints, rules, or limitations.
Moreover, alignment can be expressed by the `System User` . The user-prompted `Goal` can be further refined
pre-runtime through supplementary `Preferences` provided by the `Human User` via the `User Interface` .
In addition, real-time adaptability can be offered by multi-agent systems, necessitating instantaneous system
responsiveness. A more in-depth exploration of this is available in Section 4.1.2. However, apart from the
alignment achieved within the interaction layer by the multi-agent system, which our taxonomy addresses,
there also exist alignment methodologies specifically tailored for the employed LLMs or foundation models

[3, 92]. _Autonomy_, on the other hand, primarily surfaces from the capability of the multi-agent system to fulfill
the designated `Goal` autonomously through self-organized strategy and task execution. Not only do individual
collaborative intelligent `Agents` utilize the `LLM` for reflecting, planning, or performing reasoning-intensive
actions pertinent to their roles, but the overarching organization of the `Task-Management Activity`, along
with other infrastructural or dynamic elements, might also be directed in a self-organized manner, steered
by LLM-powered `Agents` . Further details on this can be found in Section 4.1.1. Navigating the complex
interplay between autonomy and alignment presents an ongoing challenge for LLM-powered multi-agent
systems. Striking the right balance is crucial to ensure an efficient and effective task-execution process that
faithfully accomplishes the user-defined `Goal` .


In the following Section 4, we explain how our taxonomy addresses these challenges of analyzing and
balancing the interplay between autonomy and alignment across architectural aspects and viewpoints.


**4** **Multi-Dimensional Taxonomy**


In this section, we introduce the system of our multi-dimensional taxonomy, engineered to methodically
analyze the interplay between autonomy and alignment across architectures of autonomous LLM-powered
multi-agent systems. The taxonomy weaves three crucial dimensions, i.e. levels of autonomy, levels of
alignment as well as architectural viewpoints. Together, they form a three-dimensional matrix, serving as a
comprehensive repository of architectural design options (see Fig. 1).


12


Section 4.1 delves into the complexities of the interplay between autonomy and alignment, exploring how the
synergies of different levels of autonomy and alignment can characterize a system’s dynamics. Subsequently,
Section 4.2, underscores the importance of incorporating architectural viewpoints into the taxonomic system.
Rather than applying the autonomy-alignment matrix flatly, we propose analyzing each architectural viewpoint
as well as further inherent architectural characteristics individually. Such a viewpoint-focused approach allows
for a deeper and more nuanced understanding of the systems, reflecting the complexity of their architectural
design and resulting dynamics. Finally, in Section 4.3, we unify these components, mapping the autonomyalignment dimensions and levels onto the identified architectural viewpoints, thus introducing a third dimension
into our taxonomy. Furthermore, we distinguish architectural aspects inherent to these viewpoints and specify
corresponding level criteria for both autonomy and alignment.


This framework provides a comprehensive classification of autonomous LLM-powered multi-agent systems,
revealing distinct insights into the complexities arising from the interplay of interdependent architectural
aspects. Each aspect is characterized by its levels of autonomy and alignment, influencing the systems’
behavior, interactions, composition, and interaction with contextual resources.


**4.1** **Interplay between Autonomy and Alignment**


Autonomy and alignment, as interdependent and interplaying concepts, have their roots in management
sciences and organizational behavior, playing integral roles in the ways teams and systems function [49, 57]. In
these fields, autonomy typically refers to the degree of discretion employees or teams possess over their tasks,
while alignment denotes the degree to which these tasks correspond to the organization’s overall objectives.


When shifting focus to the AI landscape, the interplay between autonomy and alignment remains pivotal

[67, 10]. AI systems, by nature, operate with varying degrees of independence and are often designed to
accomplish tasks that are multifaceted, interconnected, and potentially beyond the capabilities of individual
human operators. However, complete autonomy can pose risks. If the goals of an AI system deviate from
those of its human supervisors, it could lead to unforeseen consequences or uncontrollable side effects.
Therefore, controlling the level of autonomy is crucial to maintain the balance between operational efficiency
and safety. As such, understanding and defining the bounds of autonomy and alignment becomes vital to
appropriately guide system behavior and prevent unwanted consequences, especially when dealing with
autonomous multi-agent systems powered by LLMs.


In order to efficiently address the characteristics of current and forthcoming autonomous LLM-powered
multi-agent systems, we adopt a pragmatic and technical perspective on both autonomy and alignment. In
the following sections, we explain this perspective and elaborate in detail on the dimensions and levels of
autonomy and alignment applied by our taxonomy. Table 1 gives an overview of the employed levels and the
resulting spectrum of potential combinations.











|L2: Real-time|3 User-Supervised|6 User-Collaborative|9 User-Responsive|
|---|---|---|---|
|**L2: Real-time**<br>|Automation|Adaptation|Adaptation|
|**L1: User-Guided**|2 User-Guided|5 User-Guided|8 User-Guided|
|**L1: User-Guided**|Automation|Adaptation|Adaptation|
|**L0: Integrated**|1 Rule-Driven Automa-|4 Pre-Confgured|7 Bounded Autonomy|


tion



Adaptation



Table 1: Matrix showcasing the interplay between gradations of alignment ( _vertical_ ) and autonomy ( _horizontal_ )
in the context of LLM-powered multi-agent architectures. Each cell signifies a unique combination of autonomy
and alignment levels. Refer to Sections 4.1.1 and 4.1.2 for details on the applied levels. Section 4.1.3 provides
details on the resulting matrix combinations.


**4.1.1** **Autonomy**


The degree of autonomy refers to the extent to which an AI system can make decisions and act independently
of rules and mechanisms defined by humans. For LLM-powered multi-agent systems, this translates to a
system’s proficiency in addressing the goals or tasks specified by the user in a self-organizing manner, adapting
and re-calibrating to the complexities of a given situation. Autonomous multi-agent systems are _by nature_


13


striving for this end-to-end automatic goal completion and task management from a user perspective. While
automation often gets conflated with autonomy, it’s essential to differentiate the two. Automation pertains
to tasks being carried out without human input [12, 29], while autonomy pertains to _decisions about tasks_
being made without human intervention [21, 58, 6]. In the domain of LLM-powered multi-agent systems,
we look beyond mere task automation, focusing on how these systems internally manage their dynamics to
fulfill user objectives. Our taxonomy, therefore, distinguishes systems on a spectrum of autonomy. Drawing
from the triadic interplay illustrated in Fig. 3, on the one end of the spectrum, we see systems that heavily
rely on predefined rules and frameworks, set by their human system architects. While they may execute tasks
autonomously, their decision-making process is constrained within a fixed set of parameters ( _low autonomy_ ).
On the other hand, we encounter systems characterized by their ability for self-organisation and dynamic
self-adaptation. Rather than relying on hard-coded mechanisms, they harness the power of LLMs to interpret,
decide, and act, making them more adaptable to changing situations ( _high autonomy_ ).


**Autonomy Levels.** The levels of autonomy, represented on the x-axis in our matrix (see Fig. 1 and Table
1), articulate the degree of agency of the LLM-powered agents in making decisions regarding the system
operation independently from predefined and automated mechanisms.


**L0: Static Autonomy**  - At this foundational level, systems are primarily automated, relying heavily
on the rules, conditions, and mechanisms embedded by system architects. The systems follow
defined rules and predetermined mechanisms. This, however, includes some degree of flexibility
resulting from rule-based options and alternatives. Anyway, the agents in these systems, are not
empowered to modify rules during runtime. For instance, their function here is limited to the
effective execution of assigned tasks. Depending on the alignment level, this results in Rule-Driven
Automation, User-Guided Automation, or User-Supervised Automation (see Table 1).

**L1: Adaptive Autonomy**  - Evolving from the static level, systems at this stage possess the capability to
adapt their behavior within a structure and procedural guidelines established by the system architects.
The LLM-powered agents are capable of adjusting the system’s operations within this provided
framework (such as flexible infrastructures and protocols) due to the needs of the given application
scenarios, but not beyond. Depending on the alignment level, this leads to Pre-Configured Adaptation,
User-Guided Adaptation, or User-Collaborative Adaptation.

**L2: Self-Organizing Autonomy**  - At this highest level of autonomy, LLM-powered agents emerge as
the principal actors, capable of self-organization, actively learning and dynamically tailoring their
operations in real-time based on environmental cues and experiences. The autonomy lies not in
being independent from user intervention, but in being independent of architect-defined rules and
mechanisms. However, this might also include highly generic infrastructures that are modifiable by
the LLM-powered agents and thus allow self organisation. Depending on the alignment level, this
results in Bounded Autonomy, User-Guided Autonomy, or User-Responsive Autonomy.


These levels of autonomy not only apply to the system as a whole, but to architectural viewpoints and involved
architectural characteristics (see Section 4.3).


**4.1.2** **Alignment**


In the context of AI, the term alignment traditionally refers to the challenge of ensuring that an AI system’s
behavior aligns with human intentions, values or goals. This intricate problem, often framed as the _control_
_problem_, is a cornerstone of AI safety discourse [10, 65]. However, when viewed through a practical
lens, especially in the context of autonomous LLM-powered multi-agent systems, the alignment paradigm
acquires a more interactive, user-centric perspective [1]. Here, alignment techniques can be seen as a detailed
calibration of conditions tied to user-specified objectives or complex tasks. This includes preferences, policies,
constraints, and boundaries which collectively steer or regulate the system’s trajectory towards achieving its
set targets. Importantly, within this framework, alignment is not seen as counter to autonomy. Instead, it acts
to complement and refine it, being applicable across various levels of autonomy.


It is also important to note that these alignment aspects are focused on the agent-interaction layer and do
not, or at least only indirectly, concern the utilized large language models (LLMs) [3, 92] or other contextual
resources, such as foundation models. However, the agent-interaction layer extends alignment possibilities
by integrating rules and mechanisms to control agent interactions, for example, by incorporating real-time
monitoring via _interceptors_ [4]. Such measures, as delineated by [40, 27] enable precise control over agent
interactions as well as their interactions with LLMs and contextual resources, ensuring that they adhere to
predetermined conditions and behaviors. Moreover, employing methodologies like _design by contract_ [46]


14


further augments this control. Through this paradigm, software components’ formal, verifiable specifications,
or _contracts_, can delineate conditions for agent interactions, especially when they engage with foundational
resources like LLMs. Such contracts can specify acceptable behaviors, constraints, and criteria, ensuring the
system behaves reliably and as intended. While foundational models like LLMs have their inherent challenges,
the agent-interaction layer introduces a distinct dimension of complexity. It is imperative to ensure both are
seamlessly and securely integrated, ensuring alignment across all levels of the system.


For our taxonomy, we combine two important dimensions of alignment: its origin and timing, reflecting the
dynamic tension between automated alignment mechanisms and human customization, as illustrated in Fig. 3.
The origin delves into who dictates the alignment, the system architect or the system user. Meanwhile, timing
refers to when the alignment is specified, encompassing phases like pre-deployment, post-deployment but prior
to runtime, or even during runtime. Autonomous LLM-powered multi-agent systems strive for achieving a goal
or accomplishing a task prompted by the system user. Given this user-centric model, the alignment techniques
that are integrated into the system architecture might address generic aspects, which are not directly related
to the nuances and characteristics of specific user goals. To address this, we’ve categorized alignment into
levels. The base level, or _low alignment level_, signifies alignment that’s already embedded into the system’s
design by the system architects. This intrinsic alignment sets broad behavioral boundaries without focusing on
specific user preferences. On the other hand, the _high alignment levels_ are more adaptable and centered around
user-specified alignment. Here, users have the flexibility to set their preferences either before the system enters
its runtime or, ultimately, during its active operation. This dynamic range ensures a tighter fit to user objectives,
all however built upon mechanisms integrated into the system architecture.


**Alignment Levels.** The levels of alignment, represented on the y-axis in our matrix (see Fig. 1 and Table 1),
measure the degree to which users of the system can influence or adjust the system’s behavior.


**L0: Integrated Alignment**   - At this foundational level, the alignment techniques are built directly into the
system’s architecture. In such system, alignment mechanisms are static and rule-driven, and cannot be
altered by the users. Depending on the autonomy level, this results in Rule-Driven Automation, PreConfigured Adaptation, or Bounded Autonomy, where user interaction with the system’s alignment is
not provided (see Table 1).


**L1: User-Guided Alignment**  - Evolving from the previous level, the User-Guided Alignment offers
a degree of customization. This level empowers users by allowing them to set or adjust specific
alignment parameters, such as conditions, rules, or boundaries, before the system starts its operation.
These interactions are primarily facilitated via user interfaces designed to capture user preferences
in a structured manner. Depending on the autonomy level, this results in User-Guided Automation,
User-Guided Adaptation, or User-Guided Autonomy.


**L2: Real-Time Responsive Alignment**  - The highest level of alignment is represented by means to
adjust the system’s behavior in real-time. Thanks to integrated real-time monitoring mechanisms,
the system can actively solicit user feedback user decisions at critical junctures or decision points.
This responsiveness enables a high level of collaboration in terms of ongoing feedback between the
user and the system. Depending on the autonomy level, this results in User-Supervised Automation,
User-Collaborative Adaptation, or User-Responsive Autonomy.


The hierarchical alignment structure mirrors the challenges commonly faced in software development, especially as visualized by the _cone of uncertainty_ [8]. This cone depicts how uncertainties, predominant in the
early stages of a project, gradually diminish as developers gain better clarity. Transferred to the alignment
of LLM-powered multi-agent systems, initial alignment challenges are approached with a broad brushstroke
by system architects. Their main focus is to ensure foundational system functionality. At this juncture, the
specificity of user-driven tasks, with their unique nuances and intricacies, will hardly be anticipated by system
architects. In turn, a user-guided, pre-runtime alignment allows users to specify preferences and limitations
based on a more concrete understanding of possible challenges associated to a given task. However, even
at this stage, it is barely possible for the user to anticipate all alignment challenges. Factors like ambiguous
prompts, incomplete task specifications, or, in general, unclear expectations, can inadvertently steer the system
off course resulting in unintended outcomes and uncontrollable side effects. Thus, once the system is in
operation, such deviations from user’s intentions might first become obvious to the user during runtime and
require adjustment in real-time. This allows the system to re-align based on immediate user feedback.


These levels of alignment not only apply to the system as a whole, but to architectural viewpoints and involved
architectural characteristics (see Section 4.3).


15


**4.1.3** **Combinations of Autonomy and Alignment**


By combining these two dimensions in our matrix (see Table 1), we provide a comprehensive view of the
interplay between diverse gradations of autonomy and alignment within LLM-powered multi-agent systems. As
illustrated in Fig. 5, departing from static and rule-driven system configurations ( _automation_ ), this autonomyalignment matrix captures the progression of dynamism and responsibilities as we move along the axes. On
the y-axis, alignment levels represent the gradation of human users’ involvement—from integrated systems
where the user’s role is passive (L0), to real-time responsive setups demanding active participation (L2). On
the y-axis, the autonomy levels signify the evolving capabilities of LLM-powered agents, progressing from
static behaviors (L0) to adaptive (L1) and, ultimately, self-organizing mechanisms (L2). This matrix structure
reflects the triadic interplay and dynamic tensions illustrated in Fig. 3. As we delve deeper into the matrix, the
challenge becomes evident: ensuring balance between the evolving responsibilities of LLM-powered agents
and the goals and intentions by the human users, ultimately resulting in a dynamic collaboration between
agents and humans.



**Alignment**


L2


L1


L0



_**Balance**_



user-responsive
autonomy


user-guided
adaptation


rule-driven
automation



L0



L1 L2


|9<br>5<br>1|Col2|Col3|
|---|---|---|
||||
||||
||||
||||
||||



**Automation** **Autonomy**



Figure 5: Interplay between autonomy and alignment: balancing evolving levels of dynamism and responsibilities of both LLM-powered agents ( _autonomy_ ) and human users ( _alignment_ ).


In the following, we detail the resulting nine combinations provided in Table 1.


1 **Rule-Driven Automation (L0 Autonomy/L0 Alignment)** : In this configuration, both autonomy and
alignment are at the lowest levels. Such system operates based on scripted mechanisms and fixed
conditions defined by the system architects. The alignment aspects are integrated into the system
during the development stage. At this level, the behavior can not be affected by the user, neither
pre-runtime or during runtime. However, this _balanced_ setup is ideal for repetitive, well-defined tasks
that require minimal variability or adaptability.


2 **User-Guided Automation (L0 Autonomy/L1 Alignment)** : Here, while the autonomy of the system
remains at the lowest level, users can guide the system’s behavior within predefined parameters
before runtime. The user can not make real-time adjustments, but can influence the system’s behavior
within the predefined structure. It allows a certain level of customization without granting complete
control, which can be ideal for scenarios where user expertise can refine the operation but the task
management remains static.


3 **User-Supervised Automation (L0 Autonomy/L2 Alignment)** : This configuration allows the user
to supervise and make real-time adjustments to the system, despite the system’s autonomy level
remaining at the lowest. The user has more control over the system’s behavior, being able to guide
and correct it as necessary in real-time. This configuration is suitable for tasks requiring real-time
user feedback and supervision, but where the processes themselves are performed in a pre-scripted
manner.


4 **Pre-Configured Adaptation (L1 Autonomy/L0 Alignment)** : At this level combination, the multiagent system can adapt its behavior within certain predefined parameters, but the alignment aspects
are still integrated into the system during the development stage, with no room for adjustments by
the user during runtime. This allows the agents to handle a greater variety of scenarios than strictly
rule-driven systems, while still maintaining a clear boundary on its behavior set by the predefined
parameters.


5 **User-Guided Adaptation (L1 Autonomy/L1 Alignment)** : Here, the system can adapt its operations
within predefined parameters, and the user can also guide the system’s behavior within a predefined
structure. It offers a _balanced_ mix of system adaptation and user guidance. This combination


16


can be useful when the tasks or environment have some level of unpredictability that requires the
LLM-powered agents to adapt within predefined bounds, and where the user’s guidance can inform
the system’s decisions.


6 **User-Collaborative Adaptation (L1 Autonomy/L2 Alignment)** : This configuration allows the
system to adapt its operations and also be responsive to real-time user adjustments. It offers a dynamic
interaction between the user and the agents. This configuration is well-suited to environments that are
unpredictable and require the system to adapt and respond quickly to the user’s real-time instructions.


7 **Bounded Autonomy (L2 Autonomy/L0 Alignment)** : Here, the multi-agent system can self-organize
and learn from the environment, but the alignment is integrated during the development stage and
cannot be adjusted by users during runtime. This provides the system with a great degree of flexibility
to handle complex tasks and environments, while still adhering to a defined set of limitations and
constraints specified by the system architect.


8 **User-Guided Autonomy (L2 Autonomy/L1 Alignment)** : At this level, while the system can selforganize and learn from the environment, the user can guide the system’s behavior within predefined
parameters. This system configuration leverages the agents’ self-organizing abilities while allowing
user guidance pre-runtime. It combines the strengths of autonomous decision making and learning,
with the assurance of user-specified boundaries.


9 **User-Responsive Autonomy (L2 Autonomy/L2 Alignment)** : This is the highest level of autonomy
and alignment, where the LLM-powered agents can self-organize, learn from the environment and
user’s real-time adjustments. It offers a _balanced_ collaborative environment between the user and the
agents, being ideal for complex, unpredictable environments where both autonomous strategy and
action as well as real-time user-responsiveness are needed.


In the following sections, we explore how the autonomy-alignment matrix can be applied within the context
of architectural viewpoints and further architectural aspects inherent to these viewpoints on autonomous
LLM-powered multi-agent systems.


**4.2** **Architectural Viewpoints**


Architectural viewpoints are a structured means to analyze and assess complex systems from diverse perspectives focusing on selected aspects and layers of an architecture [4, 16]. Central to these viewpoints is the
consideration of stakeholder concerns, which inform and determine the highlighted aspects and their interrelations in each viewpoint. Providing a combined multi-perspective analysis, viewpoints serve as an effective
framework to examine the structures and dynamics of software architectures. For our taxonomy, we leverage
viewpoints on autonomous LLM-powered multi-agent systems. Rather than mapping the autonomy-alignment
taxonomy flatly onto the system, which oversimplifies the multi-faceted nature of these systems, analyzing
each architectural viewpoint individually offers a tailored lens, enabling to comprehend the role and impact of
autonomy and alignment within the system. Each viewpoint reveals distinct insights into the system’s behavior,
internal interactions, composition, and context interaction, leading to a more nuanced and comprehensive
classification [64].






|Functional G<br>Viewpoint<br>Goal-driven<br>Task Mgmt.|Col2|Development A<br>Viewpoint<br>Agent<br>Composition|Col4|
|---|---|---|---|
|||||
|**Multi-Agent**<br>**Collaboration**<br>_Process_<br>_Viewpoint_<br>M|**Multi-Agent**<br>**Collaboration**<br>_Process_<br>_Viewpoint_<br>M|**Context**<br>**Interaction**<br>_Physical_<br>_Viewpoint_<br>C|**Context**<br>**Interaction**<br>_Physical_<br>_Viewpoint_<br>C|
|**Multi-Agent**<br>**Collaboration**<br>_Process_<br>_Viewpoint_<br>M||||



Figure 6: Architectural viewpoints oriented to the _4+1 view model of software architecture_ [38] applied to
autonomous LLM-powered multi-agent systems.


17


**4.2.1** **Applied Viewpoints**


For our taxonomy, we orient to Kruchten’s renowned _4+1 view model of software architecture_ [38], an
established standard viewpoint model for software architecture, adapting it to suit the architectural characteristics of LLM-powered multi-agent systems (see Section 3). Our taxonomy encompasses the following four
architectural viewpoints on these systems (refer to Fig. 6):


G **Goal-driven Task Management** _(Functional Viewpoint)_ : Kruchten’s functional viewpoint refers to
the system’s visible functionalities as experienced by its users [38]. In the context of autonomous
LLM-powered multi-agent systems, we see `Goal-driven Task Management` as a manifestation of
this functional viewpoint. It entails the system’s capabilities and mechanisms to decompose userprompted goals or complex tasks into smaller, more manageable tasks, and subsequently, orchestrate
task execution, combine the results, and deliver the final result forming the response for the user (see
Figs. 2 and 4).


A **Agent Composition** _(Development Viewpoint)_ : According to Kruchten, the development viewpoint
is primarily focusing on the system’s software architecture, the breakdown into components, and
their organization [38]. In our context, we interpret this as `Agent Composition`, focusing on the
system’s internal composition, particularly the assembly and constellation of agents. It includes the
types and roles of agents, their memory usage, the relationships between agents (see Figs. 2 and 4).


M **Multi-Agent Collaboration** _(Process Viewpoint)_ : Kruchten’s process viewpoint concerns the dynamic aspects of a system, specifically the system procedures and interactions between components

[38]. We apply this to the `Multi-Agent Collaboration` in our model, emphasizing the collaborative task execution and interactions among agents. This encompasses the application of
communication protocols, the dynamics of actions management, such as the actual task execution,
mutual task delegation, as well as the evaluation and merging of task results on agent level, as well as
the management of communication components such as prompts and prompt templates (see Figs. 2
and 4).


C **Context Interaction** _(Physical Viewpoint)_ : According to Kruchten, the physical viewpoint involves
the system’s mapping to physical resources [38]. We extend this to `Context Interaction`, focusing
on the system’s interaction with the external environment. It includes how the system acquires,
integrates, and utilizes contextual resources such as external data, expert tools, and further foundation
models as well as the organized distribution and utilization of contextual resources within the agent
network (see Figs. 2 and 4).


**4.2.2** **Viewpoint Interdependencies**


To effectively design and understand autonomous LLM-powered multi-agent systems, it’s essential to recognize
the relationships and interdependencies between architectural components and viewpoints [99, 64]. Fig. 6
illustrates these interrelated architectural viewpoints for multi-agent architectures. The figure includes _use_
dependencies between the viewpoints, denoted as dotted lines indicating the directions of usage [55]. These
dependencies arise from the interconnected nature of these viewpoints, as they collectively shape the behavioral
features provided by the system, here expressed in terms of the `Goal-driven Task Management` viewpoint.


The interplay between architectural viewpoints is notably influenced by the autonomy levels of the systems.
With regard to the levels of autonomy, we can distinguish the following two types of dependencies between
architectural viewpoints, i.e., _availability-driven dependencies_ for low-autonomy systems and _requirements-_
_driven dependencies_ for high-autonomy systems. Fig. 7 illustrates the two types in a simplified manner. For
further details on dependencies between architectural aspects inherent to the viewpoints, also see the feature
diagram in Fig. 8.


**Availability-driven Dependencies (Low-Autonomy System).** For low-autonomy multi-agent systems, as
depicted in Fig. 7 (a), the architecture operates predominantly under pre-established automation. In these
systems, functionality largely relies on pre-configured rules and mechanisms. Thus, the functionality of such
multi-agent system is contingent upon the predefined capabilities of the system processes, which are defined
by the structure of the system and the resources available.


    - In such systems, `Goal-driven Task Management` depends on all other dimensions, as it represents
the culmination of the system’s operations in terms of the key functionality as perceived by the user.
The capabilities regarding the decomposition and orchestration of task execution towards completing


18


**Availability-driven Dependencies**



**Requirements-driven Dependencies**



















«relies on capabilities of» «adapts capabilities to»


|Low-Autonomy<br>Multi-Agent System<br>Goal-driven Multi-Agent Agent Context<br>Task Mgmt. Collaboration Composition Interaction<br>«relies on capabilities of»|Col2|Col3|
|---|---|---|
|Goal-driven<br>Task Mgmt.|Context<br>Interaction|Context<br>Interaction|
||||


|High-Autonomy<br>Multi-Agent System<br>Goal-driven Multi-Agent Agent Context<br>Task Mgmt. Collaboration Composition Interaction<br>«adapts capabilities to»|Col2|Col3|
|---|---|---|
|Goal-driven<br>Task Mgmt.|Context<br>Interaction|Context<br>Interaction|
||||



**(a)**



**(b)**



Figure 7: Types of dependencies distinguished by different levels of autonomy provided by LLM-powered
multi-agent architectures.


the prompted task are essentially influenced by the predefined composition and constellation of
agents (such as competencies, roles, types, and network), their scripted mode of collaboration for
task execution, and the rule-based integration and utilization of contextual resources.

    - In turn, `Multi-Agent Collaboration` derives its operational modus from the foundational structures established by the `Agent Composition` and `Context Interaction` . The mode of collaboration for task execution among agents is dictated by predefined characteristics and competencies
(types, roles) of the agents involved and their relationships and organization as network ( `Agent`
`Composition` ), as well as by the accessibility in terms of the effective integration and utilization of
contextual information, tools and models to execute the given tasks ( `Context Interaction` ).

    - Finally, `Agent Composition` also relies on the availability of contextual resources (Context Interaction). The types and number of agents needed in the system as well as their roles and competencies
are directly influenced by the contextual environment (e.g., the availability, accessibility, and quality
of data, foundation models, and expert tools) used by the system and how they are utilized within the
task-management activity.


**Requirements-driven Dependencies (High-Autonomy System).** In turn, high-autonomy multi-agent systems,
illustrated in Fig. 7 (b), have the ability to self-organize. In these systems, the architectural infrastructure and
dynamics as well as the context interaction are self-organizing and thus capable of adapting their capabilities
to the needs and requirements set by a given goal. Thus, compared to systems with low autonomy, there is an
inverse dependency relationship.


   - In highly-autonomous multi-agent systems, the user-prompted goal delineates the requirements,
charting the course for the entire architectural edifice of the system. All other viewpoints adapt to
the envisioned functional behavior expressed as `Goal-driven Task Management` . Based on the
complexity of the goal, its decomposition into tasks and their distribution, the other architectural
aspects inherent to the three further viewpoints undergo adaptations to fit the needs of the given
situation.

    - In addition, `Agent Composition`, encompassing agents’ roles, types, and their memory usage,
as well as `Context Interaction`, including the integration and utilization of resources, adapt
to the requirements set by the modes of collaboration to tackle the assigned tasks, including the
communication protocol ( `Multi-Agent Collaboration` ).

    - Finally, also `Agent Composition` sets the requirement for the adaptation of `Context`
`Interaction` . The specific roles of agents within the system mandate particular resource integration. For instance, an agent with analytical responsibilities might necessitate the inclusion of
specific data streams or computational tools.


**Intertwined Dependencies (Mixed Autonomy Levels).** The two distinguished types, availability-driven
and requirements-driven dependencies, address the challenge of interconnected architectural viewpoints in an
illustrative, but simplified manner. On the one hand, the viewpoints of a multi-agent system might provide
different autonomy levels; on the other hand, also the aspects or mechanisms within a viewpoint might be on


19


different levels of autonomy. Both cases result in _intertwined dependencies_ . It is important to note that the
autonomy levels set for one viewpoint or aspects can have an impact on others viewpoints or aspects due to
their interconnected nature (see above). The intertwined dependencies might prove risky. They can introduce
complexities and unpredictabilities, potentially jeopardizing system efficiency and effectiveness. It underscores
the necessity of incorporating robust control mechanisms to navigate and manage these interdependencies,
which is illustrated by the following illustrative example.


**Example.** Consider a practical scenario where an autonomous LLM-powered multi-agent system is operating
in the following dynamic environment:


    - **Decomposition Dynamics** : Within the `Goal-driven Task Management` viewpoint, tasks are
dynamically decomposed into sub-tasks based on user requirements, and this decomposition operates
with a L2 autonomy level, which signifies a self-organizing manner.


    - **Agent Collaboration Dynamics** : Similarly, the `Multi-Agent Collaboration` viewpoint, which
encompasses how agents collaborate for task execution, operates on the same L2 autonomy. Agents
decide on-the-fly how to interact, delegate tasks, and merge results.


    - **Contextual Interaction Limitation** : Contrasting the above, the `Context Interaction` viewpoint
is constrained by L0 autonomy level. Here, the system’s access and interaction with the external
environment (contextual resources) are limited by predefined rules. The system cannot autonomously
decide to reach out to new resources or modify the way it interacts with existing ones.


Given these conditions, a potential issue arises: As tasks are decomposed and agents plan their collaborations,
they might, based on their L2 autonomy, decide to utilize certain contextual resources. However, when it’s
time to access these resources, they might find them inaccessible due to the L0 constraints in the `Context`
`Interaction` viewpoint. This discrepancy in autonomy levels can cause operational dead-ends. For instance,
an agent might anticipate using an external data source to complete its task, but the L0 constraints prevent it
from accessing that source, leaving the task incomplete.


Such issues highlight the importance of having robust control mechanisms in place that can preemptively
identify and mitigate these discrepancies, ensuring smooth system operations.


For a detailed illustration of dependencies between viewpoint-specific aspects, refer to Section 4.3.2.


**4.3** **Interplay of Autonomy and Alignment in the System Architecture**


As already illustrated, both autonomy and alignment serve as _cross-cutting concerns_ [35] impacting the
operational efficiency of various architectural aspects across LLM-powered multi-agent systems. Thus, in
the following, we map our matrix of autonomy and alignment levels onto the architectural viewpoints. This
projection crafts a three-dimensional matrix, offering a prism through which these systems can be analyzed and
categorized (also see Fig. 1). In Section 4.3.1, we give systematic overview of the resulting viewpoint-specific
combinations of autonomy and alignment levels. Section 4.3.2 details the architectural aspects associated to
these viewpoints and specifies corresponding level criteria that establish the foundation for the taxonomic
classification.


**4.3.1** **Mapping Autonomy-Alignment Levels to Viewpoints**


Table 2 showcases the interplay of autonomy, alignment, and the distinct architectural viewpoints. It applies
the autonomy-alignment matrix, as illustrated in Table 1, to the identified architectural viewpoints inherent to
autonomous LLM-powered multi-agent systems. Each cell in this matrix signifies a unique architectural design
choice, representing a distinct system configuration. The architectural viewpoints ( _horizontal_ ; see Section
4.2) are categorized into `Goal-driven Task Management`, which highlights the system’s functionalities;
`Agent Composition`, emphasizing its intrinsic structure; `Multi-Agent Collaboration`, denoting the
dynamics of agent interactions; and `Context Interaction`, detailing the system’s rapport with its external
environment in terms of data and tools. Alongside these viewpoints, the nine combinations of autonomy and
alignment levels ( _vertical_ ; see Section 4.1) describe the system’s behavior. Autonomy ranges from `Static`
to `Self-Organizing`, determining the system’s degree of self-organization. Meanwhile, alignment varies
from `Integrated` to `Real-Time Responsive`, capturing the depth of human influence over the system’s
operations. Combining these dimensions results in 36 system architectural design options available for
configuring multi-agent systems.


20


**Autonomy:** Self
|1|Rule-Driven Automa-|Rule-driven task man-|Rule-driven agent|Rule-driven collabora-|Rule-driven interac-|
|---|---|---|---|---|---|
|1|**tion:**<br>Static & Inte-<br>grated (L0 & L0)|agement.|composition<br>and<br>constellation.|tion protocols.|tion protocols.|
|2|**User-Guided**<br>**Au-**<br><br>|User-guided task man-<br>|User-guided<br>agent<br><br>|User-guided collabora-<br>|User-guided<br>context<br>|
|2|**tomation:**<br>Static &<br>User-Guided<br>(L0<br>&<br>L1)|agement.|composition<br>and<br>constellation.|tion protocols.|tion protocols.|
|3|**User-Supervised**<br><br>|Task management ad-<br>|Agent<br>composition<br>|Agent<br>collaboration<br>|Context<br>integration<br><br><br>|
|3|**Automation:**<br>Static<br>& Real-Time Respon-<br>sive (L0 & L2)|justed during runtime.|and constellation ad-<br>justed during runtime.|adjusted during run-<br>time.|adjusted during run-<br>time.|
|4|**Pre-Confgured**<br>|Adaptive<br>task<br>man-<br>|Adaptive agent com-<br>|Adaptive collaboration<br>|Pre-integrated<br>adap-<br><br><br>|
|4|**Adaptation:** Adaptive<br>& Integrated (L1 & L0)|agement with prede-<br>fned options.|position and constel-<br>lation with predefned<br>fexibility.|protocols.|protocols.|
|5|**User-Guided Adapta-**<br>|User-adjusted<br>adap-<br><br><br>|User-adjusted<br>adap-<br>|User-adjusted<br>adap-<br>|User-adjusted<br>adap-<br>|
|5|**tion:** Adaptive & User-<br>Guided (L1 & L1)|tive<br>task<br>manage-<br>ment.|tive agent composition<br>and constellation.|tive collaboration.|tive collaboration.|
|6|**User-Collaborative**<br>|Adaptive<br>task<br>man-<br>|Adaptive agent com-<br>|Adaptive collaboration<br>|Adaptive context inte-<br>|
|6|**Adaptation:** Adaptive<br>& Real-Time Respon-<br>sive (L1 & L2)|agement adjusted dur-<br>ing runtime.|position and constel-<br>lation adjusted during<br>runtime.|adjusted during run-<br>time.|adjusted during run-<br>time.|
|7|**Bounded Autonomy:**<br>|Task management or-<br><br><br>|Agents self-organize<br>|Collaboration strategy<br>|Agents select from a<br>|
|7|Self-Organizing & Inte-<br>grated (L2 & L0)|ganically<br>based<br>on<br>current needs.|based on current sce-<br>nario.|evolves organically.|evolves organically.|
|8|**User-Guided Auton-**<br>|User-guided<br>self-<br><br>|User-guided<br>agent<br>|User-guided collabora-<br>|User-guided<br>self-<br><br>|
|8|**omy:** Self-Organizing<br>& User-Guided (L2 &<br>L1)|organizing<br>task<br>management.|self-organization.|tion evolution.|tion evolution.|
|9|**User-Responsive**<br><br>|Self-organizing<br>task<br>|Agent<br>self-<br>|Collaboration<br>evolu-<br>|Self-organized selec-<br>|

Organizing & RealTime Responsive (L2
& L2)



management adjusted
during runtime.



organization adjusted
during runtime.



tion adjusted during
runtime.



tion from contextual resources adjusted during runtime.



Table 2: Mapping autonomy and alignment levels ( _vertical_, #1–9 resulting from Table 1) to architectural
viewpoints ( _horizontal_ ) on autonomous LLM-powered multi-agent systems resulting in 36 viewpoint-specific
system configurations. A detailed explanation of the autonomy and alignment levels is provided in Section 4.1.
For an overview of the applied viewpoints, refer to Section 4.2.


In the following Section 4.3.2, we explore further viewpoint-specific aspects and their interdependencies, in
order to derive level criteria for the taxonomic classification.


**4.3.2** **Viewpoint-specific Aspects and Level Criteria**


As outlined above, architectural viewpoints provide means to analyze certain aspects and aspect relations of
the system’s architecture in a multi-perspective manner [64]. Drawing from the domain-ontology model (Fig.
4), we now systematize the viewpoint-specific aspects employed in our taxonomy. Subsequently, we specify
level criteria for autonomy and alignment corresponding to each aspect. Furthermore, we outline the main
interdependencies among these aspects.


Fig. 8 gives an overview of our taxonomy’s characteristics, structured through a feature diagram [5, 69].
Employed predominantly in software engineering, feature diagrams visually express feature models, which
aim to organize the hierarchical structure as well as dependencies among system features.


In particular, Fig. 8 (a) structures the viewpoint-specific taxonomic structure. Each of the four integrated
viewpoints provides a certain combination of autonomy and alignment levels. As illustrated in Figs. 8 (b–e),
this structure is refined by viewpoint-specific aspects and their interdependencies in terms of requirementsdriven dependencies ( _adapts-to_ ), presuming a high-autonomy system configuration, as discussed in Section
4.2.2. These dependencies suggest that the capabilities of a dependent aspect evolve in line with the needs
and stipulations of the aspect it points to. In turn, also these viewpoint-specific aspects can be assessed by the
autonomy and alignment levels, resulting in a more nuanced taxonomic classification.


21


Figure 8: Feature diagram showcasing the taxonomic structure. Each viewpoint integrates autonomy and
alignment levels **(a)** . The diagram further illustrates viewpoint-specific aspects and mechanisms **(b–e)** alongside
the _adapts-to_ dependencies among them.


Across the four distinct viewpoints, a total of 12 characteristic aspects are identified (as illustrated in Fig.
8). Each of these aspects can be assessed and classified by its corresponding autonomy and alignment
levels, yielding 9 possible configuration options per aspect (detailed in Table 1). Thus, given the viewpoints
_V_ 1 _, V_ 2 _, V_ 3 _, V_ 4 with respective aspect counts _A_ 1 = _A_ 2 = 3, _A_ 3 = 4, and _A_ 4 = 2, and a level count _L_ = 3 for
both autonomy and alignment, we define:



_TA_ =



4

- _Ai,_ (Total Aspects) (1)


_i_ =1



_SC_ = _L_ [2] _,_ (Single Configuration Options per Aspect) (2)
_TSC_ = _TASC,_ (Total Single Configuration Options) (3)

_TCC_ = ( _L_ [2] ) _[A]_ [1][+] _[A]_ [2][+] _[A]_ [3][+] _[A]_ [4] = _SC_ _[T][A]_ _[.]_ (Total Combined Configurations) (4)


Using the provided values, we find _TSC_ = 108 and _TCC_ = 9 [12] _≈_ 282 _×_ 10 [9] .
